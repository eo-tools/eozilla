{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Eozilla","text":"<p>Eozilla is a suite of tools for workflow orchestration systems and OGC API - Processes implementation.</p> <p>Eozilla has been developed to cloudify satellite data processor applications and  run them in the cloud.</p> <p>Note: this project and its documentation are still in an early development stage.</p>"},{"location":"#features","title":"Features","text":"<p>The Eozilla suite of tools comprises:</p> <ul> <li>Procodile: A simple Python framework for registering and executing processes.</li> <li>Appligator: An EO application bundler and transformer.    (Currently limited to generating Airflow DAGs.)</li> <li>Wraptile: A fast and lightweight HTTP server that implements OGC API - Processes    for various workflow processing backends, such Airflow or a local executor.</li> <li>Cuiman: A Python client including API, GUI, and CLI for servers    compliant with OGC API - Processes.</li> <li>Gavicore: Common pydantic data models and utilities for the packages above.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>The <code>eozilla</code> package installs all components of Eozilla.</p> <pre><code>pip install eozilla\n</code></pre> <p>However, your use case might require only a subset of Eozilla components. Install just</p> <ul> <li><code>procodile</code> if you develop processor applications,</li> <li><code>appligator</code> if you deploy your processor applications,</li> <li><code>wraptile</code> if you are an OGC API - Processes service provider,</li> <li><code>cuiman</code> if you need a client to operate with an OGC API - Processes service.</li> </ul> <p>The easiest way to test Eozilla is in a separate Python environment. We use the pixi here, but you could do the same with <code>pip</code>, <code>conda</code>, or <code>mamba</code>:</p> <pre><code>mkdir eozilla-test\ncd eozilla-test\n\npixi init\npixi add python\npixi add --pypi eozilla\npixi shell\n\npython -c \"import eozilla; print(eozilla.__version__)\"\n\ncuiman --help\nappligator --help\nwraptile --help\n</code></pre> <p>We currently package Eozilla only as pip packages distributed via PyPI, but we will publish <code>conda-forge</code> packages soon.</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>Large parts of the work in the Eozilla project have been made possible by the ESA DTE-S2GOS project, where we cloudify a set of EO scene simulator applications. The ESA Sen4CAP project, where we cloudify various Sentinel-based data processors, gave us the impulse to create Eozilla as a set of reusable, standalone packages. Hopefully Eozilla can support and will be supported by other future projects.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>This chapter is currently just a collection of design diagrams. Perhaps it will be of interest to some.</p> <p>Note, should the following diagram code not render, copy it  into the mermaid editor.</p>"},{"location":"architecture/#overview","title":"Overview","text":""},{"location":"architecture/#eozilla-package-dependencies","title":"Eozilla package dependencies","text":"<pre><code>---\nconfig:\n    class:\n        hideEmptyMembersBox: false\n    theme: default\n---\nclassDiagram\ndirection TD\n    class appligator {\n    }\n    class cuiman {\n    }\n    class gavicore {\n    }\n    class procodile {\n    }\n    class wraptile {\n    }\n    cuiman ..&gt; gavicore : uses\n    appligator ..&gt; gavicore : uses\n    appligator ..&gt; procodile : uses (opt.)\n    procodile ..&gt; gavicore : uses\n    wraptile ..&gt; gavicore : uses\n    wraptile ..&gt; procodile : uses (opt.)\n</code></pre>"},{"location":"architecture/#core-classes","title":"Core classes","text":"<pre><code>---\nconfig:\n    class:\n        hideEmptyMembersBox: true\n    theme: default\n---\nclassDiagram\n    direction TD\n    namespace cuiman {\n        class api.AsyncClient\n        class api.Client\n        class gui.Client\n        class cli\n    }\n    namespace gavicore {\n        class models\n        class service.Service\n        class models.ProcessRequest\n        class ExecutionRequest\n    }\n    namespace wraptile {\n        class server\n        class routes\n        class services.local.LocalService\n        class services.airflow.AirflowService\n    }\n    namespace procodile {\n        class JobContext\n        class Process\n        class ProcessRegistry\n        class cli.new_cli\n    }\n    namespace appligator {\n        class airflow.gen_dag\n    }\n\n    cli ..&gt; api.Client : uses\n    cli ..&gt; ExecutionRequest\n    gui.Client --|&gt; api.Client : inherits\n    api.Client ..&gt; service.Service : uses\n    api.AsyncClient ..&gt; service.Service : uses\n    service.Service ..&gt; models : uses\n    services.local.LocalService --|&gt; service.Service : implements\n    services.airflow.AirflowService --|&gt; service.Service : implements\n    routes ..&gt; service.Service : uses\n    server ..&gt; routes : uses\n    server ..&gt; services.local.LocalService : can run with\n    server ..&gt; services.airflow.AirflowService : can run with\n    services.local.LocalService ..&gt; ProcessRegistry : uses\n    airflow.gen_dag ..&gt; ProcessRegistry : uses\n    ProcessRegistry *--&gt; Process: holds\n    Process ..&gt; JobContext : uses\n    cli.new_cli ..&gt; ExecutionRequest : uses\n    models *-- models.ProcessRequest\n    ExecutionRequest --|&gt; models.ProcessRequest\n\n    note for gui.Client \"will later inherit from AsyncClient\"\n\n</code></pre>"},{"location":"architecture/#eozilla-cuiman-client-gui","title":"Eozilla Cuiman Client - GUI","text":"<p>Given here is the design used in package <code>cuiman.gui.component</code>. The package contains the code to generate widgets and panels from the  JSON schema <code>gavicore.models.InputDescription</code> instances contained in a <code>gavicore.models.ProcessDescription</code> instance.</p> <p>The <code>ComponentContainer</code> maps every <code>InputDescription</code> to a visual  <code>Component</code> that is created for a given JSON schema.  </p> <pre><code>---\nconfig:\n  class:\n    hideEmptyMembersBox: true\n  layout: elk\n---\nclassDiagram\ndirection LR\n    class models.InputDescription {\n      title\n      description\n      schema\n    }\n    class ComponentContainer {\n        \\_\\_init\\_\\_(input_descriptions)\n      get_components()\n      get_viewables()\n    }\n    ComponentContainer ..&gt; ComponentFactoryRegistry : use\n    ComponentContainer o--&gt; models.InputDescription : 1..n by name\n    ComponentContainer o--&gt; Component : 1..n\n    ComponentFactory ..&gt; Component : create\n    ComponentFactoryRegistry *--&gt; ComponentFactory\n</code></pre> <p>A suitable <code>ComponentFactory</code> is selected for a given JSON schema and will create the <code>Component</code> when it is needed. The possible <code>ComponentFactory</code> instances are registered in a  <code>ComponentFactoryRegistry</code> singleton.</p> <pre><code>---\nconfig:\n  class:\n    hideEmptyMembersBox: true\n  layout: dagre\n---\nclassDiagram\ndirection TB\n    class panel.viewable.Viewable {\n        \\_\\_panel\\_\\_()\n    }\n    class Component {\n        viewable\n        json_codec\n        _get_value_()\n        _set_value_(val)\n        _watch_value_(cb)\n    }\n    class WidgetComponent {\n    }\n    class ComponentFactory {\n        _accept_(schema)\n        _create_component_(schema)\n    }\n    class ComponentFactoryRegistry {\n      register_factory(factory, type, format)\n      find_factory(schema)\n    }\n    class ComponentFactoryBase {\n        type\n        format\n        accept(schema)\n    }\n    class BooleanCF {\n    }\n    class IntegerCF {\n    }\n    class NumberCF {\n    }\n    class StringCF {\n    }\n    class DateCF {\n    }\n    class BboxCF {\n    }\n    Component &lt;|-- WidgetComponent\n    Component --&gt; panel.viewable.Viewable : 1 \n    ComponentFactory ..&gt; Component : create\n    ComponentFactoryRegistry *--&gt; ComponentFactory : 0..N\n    ComponentFactory &lt;|-- ComponentFactoryBase\n    ComponentFactoryBase &lt;|-- BooleanCF\n    ComponentFactoryBase &lt;|-- IntegerCF\n    ComponentFactoryBase &lt;|-- NumberCF\n    ComponentFactoryBase &lt;|-- StringCF\n    ComponentFactoryBase &lt;|-- DateCF\n    ComponentFactoryBase &lt;|-- BboxCF\n</code></pre>"},{"location":"architecture/#eozilla-gavicore","title":"Eozilla Gavicore","text":"<p>Given here is the design used in package <code>gavicore.service</code>.</p> <pre><code>classDiagram\ndirection TB\n    class Service {\n        get_conformance()\n        get_capabilities()\n        get_processes()\n        get_process(process_id)\n        execute_process(process_id, process_request)\n        get_jobs()\n        get_job(job_id)\n        get_job_result(job_id)\n    }\n    class ProcessList {\n    }\n    class ProcessSummary {\n        process_id\n    }\n    class ProcessDescription {\n    }\n    class ProcessRequest {\n        inputs\n        outputs\n        response\n        subscriber\n    }\n    class JobList {\n    }\n    class JobInfo {\n        process_id\n        job_id\n        status\n        progress\n    }\n    class JobResult {\n    }\n    class InputDescription {\n        schema\n    }\n    class Description {\n        title\n        description\n    }\n    ProcessList *--&gt; ProcessSummary : 0 .. N \n    ProcessSummary --|&gt; Description\n    ProcessDescription --|&gt; ProcessSummary\n    ProcessDescription *--&gt; InputDescription : 0 .. N by name\n    ProcessDescription *--&gt; OutputDescription : 0 .. N by name\n    InputDescription --|&gt; Description\n    OutputDescription --|&gt; Description\n    JobList *--&gt; JobInfo : 0 .. N \n    Service ..&gt; ProcessList : obtain\n    Service ..&gt; ProcessDescription : obtain\n    Service ..&gt; JobList : obtain\n    Service ..&gt; JobInfo : obtain\n    Service ..&gt; JobResult : obtain   \n    Service ..&gt; ProcessRequest : use      \n</code></pre>"},{"location":"architecture/#code-generation","title":"Code generation","text":"<pre><code>---\nconfig:\n  theme: default\n---\nflowchart LR\n    openapi@{ shape: lean-r, label: \"OpenAPI.yaml\" }\n    sync_client@{ shape: stadium, label: \"cuiman.api.Client\" }\n    async_client@{ shape: stadium, label: \"cuiman.api.AsyncClient\" }\n    models@{ shape: stadium, label: \"gavicore.models.*\" }\n    service@{ shape: stadium, label: \"gavicore.service.Service\" }\n    routes@{ shape: stadium, label: \"wraptile.routes\" }\n    openapi --&gt; generate\n    generate --&gt; gen-client\n    generate --&gt; gen-common\n    generate --&gt; gen-server\n    gen-client --&gt; sync_client\n    gen-client --&gt; async_client\n    gen-common --&gt; models\n    gen-common --&gt; service\n    gen-server --&gt; routes\n</code></pre> <p>Generating Airflow DAGs:</p> <pre><code>---\nconfig:\n  theme: default\n---\nflowchart LR\n    local_service@{ shape: stadium, label: \"wraptile.services.local.testing:service\" }\n    dags@{ shape: stadium, label: \"eozilla-airflow/dags\" }\n    local_service --&gt; gen-dags\n    gen-dags --&gt; dags\n</code></pre>"},{"location":"contributing/","title":"Contributing to the project","text":""},{"location":"contributing/#changelog","title":"Changelog","text":"<p>You can find the complete changelog  here. </p>"},{"location":"contributing/#reporting","title":"Reporting","text":"<p>If you have suggestions, ideas, feature requests, or if you have identified a malfunction or error, then please  post an issue. </p>"},{"location":"contributing/#contributions","title":"Contributions","text":"<p>The Eozilla project welcomes contributions of any form as long as you  respect our  code of conduct and follow our  contribution guide.</p> <p>If you'd like to submit code or documentation changes, we ask you to provide a  pull request (PR)  here.  For code and configuration changes, your PR must be linked to a  corresponding issue. </p>"},{"location":"contributing/#development","title":"Development","text":""},{"location":"contributing/#setup","title":"Setup","text":"<p>Before you start, make sure you have pixi installed.</p> <p>Checkout sources</p> <pre><code>git clone https://github.com/eo-tools/eozilla.git\ncd ./eozilla\n</code></pre> <p>Create a new Python environment and activate it:</p> <pre><code>pixi install \npixi shell\n</code></pre>"},{"location":"contributing/#running-the-eozilla-server-with-a-local-test-service","title":"Running the Eozilla server with a local test service","text":"<p>Run local test server</p> <pre><code>wraptile run -- wraptile.services.local.testing:service\n</code></pre> <p>The dev mode is useful if you are changing server code:</p> <pre><code>wraptile dev wraptile.services.local.testing:service\n</code></pre> <p>Run the Eozilla client Python API</p> <pre><code>from cuiman import Client\n\nclient = Client()\nclient.get_processes()\nclient.get_jobs()\n</code></pre> <p>Run Eozilla client GUI (in Jupyter notebooks)</p> <pre><code>from cuiman.gui import Client\n\nclient = Client()\nclient.show()\nclient.show_jobs()\n</code></pre> <p>Run Eozilla client CLI</p> <pre><code>$ cuiman --help\n</code></pre>"},{"location":"contributing/#formatting-linting","title":"Formatting &amp; Linting","text":"<pre><code>pixi run isort .\npixi run ruff format \npixi run ruff check\n</code></pre>"},{"location":"contributing/#testing-coverage","title":"Testing &amp; Coverage","text":"<pre><code>pixi run test\npixi run coverage\n</code></pre>"},{"location":"contributing/#version-syncing","title":"Version syncing","text":"<p>Before a release increase version number in root <code>pyproject.toml</code> then synchronize versions in workspaces <code>tools/pyproject.toml</code> using </p> <pre><code>pixi run sync-versions\n</code></pre>"},{"location":"contributing/#code-generation","title":"Code generation","text":"<p>Some code is generated (see respective file headers) from an OpenAPI specification in <code>tools/openapi.yaml</code>.  If this file is changed, code need to be regenerated: </p> <pre><code>pixi run generate\n</code></pre> <p>This will generate Eozilla's</p> <ul> <li>pydantic models in <code>gavicore/src/gavicore/models.py</code>  (uses datamodel-code-generator)</li> <li>client implementation in <code>cuiman/src/cuiman/client.py</code> and CLI documentation <code>docs/cli.md</code></li> <li>server routes in <code>wraptile/src/wraptile/routes.py</code> and the    service interface in <code>wraptile/src/wraptile/service.py</code></li> </ul>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>The Eozilla documentation is built using the  mkdocs tool.</p> <p>With repository root as current working directory:</p> <pre><code>mkdocs build\nmkdocs serve\nmkdocs gh-deploy\n</code></pre> <p>The documentations of all Eozilla CLIs are generated. After changing any CLI code, always update their respective  documentation by running</p> <pre><code>pixi run gen-cli-docs\n</code></pre> <p>Which will output something like the following: <pre><code>Pixi task (gen-cli-docs): python -m tools.gen_cli_docs\nDocs saved to: eozilla/docs/cuiman/cli.md\nDocs saved to: eozilla/docs/wraptile/cli.md\nDocs saved to: eozilla/docs/procodile/cli.md\nDocs saved to: eozilla/docs/appligator/cli.md\n</code></pre></p>"},{"location":"contributing/#license","title":"License","text":"<p>The Eozilla project is open source made available under the terms and  conditions of the Apache 2.0 license.</p>"},{"location":"appligator/cli/","title":"Appligator CLI","text":"<p>Generate various application formats from your processes.</p> <p>WARNING: This tool is under development and subject to change anytime.</p> <p>Currently, it expects a process registry as input, which must be provided in form a Python module path plus an attribute path separated by a colon: \"my.module.path:my.registry_obj\". The type of the registry must be <code>procodile.ProcessRegistry</code>. In the future the tool will be able to handle other input types.</p> <p>It is also currently limited to generating DAGs for Airflow 3+. The plan is to extend it to also output Docker images with or without metadata such as the OGC CWL standard (= EOAP).</p> <p>Usage:</p> <pre><code>$ main [OPTIONS] [PROCESS_REGISTRY_SPEC]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[PROCESS_REGISTRY_SPEC]</code>: Process registry specification. For example 'wraptile.services.local.testing:service.process_registry'.</li> </ul> <p>Options:</p> <ul> <li><code>--dags-folder PATH</code>: An Airflow DAGs folder to which to write the outputs.  [default: C:\\Users\\norma\\Projects\\eozilla\\eozilla-airflow\\dags]</li> <li><code>--image-name TEXT</code>: Name of the Docker image which is created from your workflow and required packages that Airflow will use for running the workflows in the registry.  [default: appligator_workflow_image:v1]</li> <li><code>--version / --no-version</code>: Show version and exit.  [default: no-version]</li> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"appligator/introduction/","title":"Appligator Overview","text":"<p>Eozilla Appligator is tool that transforms (often bundles) your workflows so  they can be recognized and executed by specific workflow orchestrators. </p> <p>Workflow orchestrator specific transformers will be provided as  plugins. The default bundler outputs the  OGC Earth Observation Application Package (EOAP) format.</p>"},{"location":"appligator/usage/","title":"Appligator Usage","text":"<p>Coming soon...</p>"},{"location":"cuiman/api/","title":"# Cuiman API Reference","text":"<p>The Cuiman Python API is provided by the <code>cuiman</code> package.</p> <p>The <code>Client</code> class provides a synchronous API. If you want an asynchronous version, use the <code>AsyncClient</code> class instead. It provides the same interface, but using asynchronous server calls.</p> <p>Both clients return their configuration as a  <code>ClientConfig</code> object.</p> <p>Methods of the <code>Client</code> and <code>AsyncClient</code>  may raise a <code>ClientError</code> if a server call fails. </p>"},{"location":"cuiman/api/#cuiman.Client","title":"<code>cuiman.Client</code>","text":"<p>               Bases: <code>ClientMixin</code></p> <p>The client API for the web service (synchronous mode).</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Optional[ClientConfig]</code> <p>Optional client configuration object. If given, other configuration arguments are ignored.</p> <code>None</code> <code>config_path</code> <code>Optional[str]</code> <p>Optional path of the configuration file to be loaded</p> <code>None</code> <code>api_url</code> <code>Optional[str]</code> <p>The service URL of the OGC API - Processes.</p> <code>None</code> <code>config_kwargs</code> <code>Any</code> <p>Configuration settings as keyword arguments.</p> <code>{}</code> Source code in <code>cuiman\\src\\cuiman\\api\\client.py</code> <pre><code>class Client(ClientMixin):\n    \"\"\"\n    The client API for the web service (synchronous mode).\n\n    Args:\n      config: Optional client configuration object. If given,\n        other configuration arguments are ignored.\n      config_path: Optional path of the configuration file to be loaded\n      api_url: The service URL of the OGC API - Processes.\n      config_kwargs: Configuration settings as keyword arguments.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        config: Optional[ClientConfig] = None,\n        config_path: Optional[str] = None,\n        api_url: Optional[str] = None,\n        _debug: bool = False,\n        _transport: Optional[Transport] = None,\n        **config_kwargs: Any,\n    ):\n        self._config = ClientConfig.create(\n            config=config,\n            config_path=config_path,\n            api_url=api_url,\n            **config_kwargs,\n        )\n        if not self._config.api_url:\n            raise ValueError(\"Required setting 'api_url' not configured\")\n        self._transport = (\n            HttpxTransport(\n                api_url=self._config.api_url,\n                headers=self._config.auth_headers,\n                return_type_map=self._config.return_type_map,\n                debug=_debug,\n            )\n            if _transport is None\n            else _transport\n        )\n\n    @property\n    def config(self) -&gt; ClientConfig:\n        return self._config\n\n    def _repr_json_(self):\n        # noinspection PyProtectedMember\n        return self.config._repr_json_()\n\n    def get_capabilities(self, **kwargs: Any) -&gt; Capabilities:\n        \"\"\"\n        The landing page provides links to the:\n          * The OpenAPI-definition (no fixed path),\n          * The Conformance statements (path /conformance),\n          * The processes metadata (path /processes),\n          * The endpoint for job monitoring (path /jobs).\n\n        For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n        Section\n        7.2](https://docs.ogc.org/is/18-062r2/18-062r2.html#sc_landing_page).\n\n        Returns:\n          Capabilities: The landing page provides links to the API definition\n            (link relations `service-desc` and `service-doc`),\n            the Conformance declaration (path `/conformance`,\n            link relation `http://www.opengis.net/def/rel/ogc/1.0/conformance`),\n            and to other resources.\n\n        Raises:\n          ClientError: If the call to the web service fails\n            with a status code != `2xx`.\n\n            - `500`: A server error occurred.\n        \"\"\"\n        return self._transport.call(\n            TransportArgs(\n                path=\"/\",\n                method=\"get\",\n                return_types={\"200\": Capabilities},\n                error_types={\"500\": ApiError},\n                extra_kwargs=kwargs,\n            )\n        )\n\n    def get_conformance(self, **kwargs: Any) -&gt; ConformanceDeclaration:\n        \"\"\"\n        A list of all conformance classes, specified in a standard, that the\n        server conforms to.\n\n        | Conformance class | URI |\n        |-----------|-------|\n        |Core|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/core|\n        |OGC Process Description|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/ogc-process-description|\n        |JSON|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/json|\n        |HTML|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/html|\n        |OpenAPI Specification 3.0|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/oas30|\n        |Job list|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/job-list|\n        |Callback|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/callback|\n        |Dismiss|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/dismiss|\n\n        For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n        Section 7.4](https://docs.ogc.org/is/18-062r2/18-\n        062r2.html#sc_conformance_classes).\n\n\n        Returns:\n          ConformanceDeclaration: The URIs of all conformance classes supported\n            by the server. To support \"generic\" clients that want\n            to access multiple OGC API - Processes implementations - and\n            not \"just\" a specific API / server, the server declares\n            the conformance classes it implements and conforms to.\n\n        Raises:\n          ClientError: If the call to the web service fails\n            with a status code != `2xx`.\n\n            - `500`: A server error occurred.\n        \"\"\"\n        return self._transport.call(\n            TransportArgs(\n                path=\"/conformance\",\n                method=\"get\",\n                return_types={\"200\": ConformanceDeclaration},\n                error_types={\"500\": ApiError},\n                extra_kwargs=kwargs,\n            )\n        )\n\n    def get_processes(self, **kwargs: Any) -&gt; ProcessList:\n        \"\"\"\n        The list of processes contains a summary of each process the OGC API -\n        Processes offers, including the link to a more detailed description of\n        the process.\n\n        For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n        Section\n        7.9](https://docs.ogc.org/is/18-062r2/18-062r2.html#sc_process_list).\n\n\n        Returns:\n          ProcessList: Information about the available processes\n\n        Raises:\n          ClientError: If the call to the web service fails\n            with a status code != `2xx`.\n        \"\"\"\n        return self._transport.call(\n            TransportArgs(\n                path=\"/processes\",\n                method=\"get\",\n                return_types={\"200\": ProcessList},\n                extra_kwargs=kwargs,\n            )\n        )\n\n    def get_process(self, process_id: str, **kwargs: Any) -&gt; ProcessDescription:\n        \"\"\"\n        The process description contains information about inputs and outputs\n        and a link to the execution-endpoint for the process. The Core does not\n        mandate the use of a specific process description to specify the\n        interface of a process. That said, the Core requirements class makes the\n        following recommendation:\n\n        Implementations **should** consider supporting the OGC process\n        description.\n\n        For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n        Section 7.10](https://docs.ogc.org/is/18-062r2/18-\n        062r2.html#sc_process_description).\n\n        Args:\n          process_id:\n          kwargs: Optional keyword arguments that may be\n            used by the underlying transport.\n\n        Returns:\n          ProcessDescription: A process description.\n\n        Raises:\n          ClientError: If the call to the web service fails\n            with a status code != `2xx`.\n\n            - `404`: The requested URI was not found.\n        \"\"\"\n        return self._transport.call(\n            TransportArgs(\n                path=\"/processes/{processID}\",\n                method=\"get\",\n                path_params={\"processID\": process_id},\n                return_types={\"200\": ProcessDescription},\n                error_types={\"404\": ApiError},\n                extra_kwargs=kwargs,\n            )\n        )\n\n    def execute_process(\n        self, process_id: str, request: ProcessRequest, **kwargs: Any\n    ) -&gt; JobInfo:\n        \"\"\"\n        Create a new job.\n\n        For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n        Section\n        7.11](https://docs.ogc.org/is/18-062r2/18-062r2.html#sc_create_job).\n\n        Args:\n          process_id:\n          kwargs: Optional keyword arguments that may be\n            used by the underlying transport.\n          request: Mandatory request JSON\n\n        Returns:\n          JobInfo: Started asynchronous execution. Created job.\n\n        Raises:\n          ClientError: If the call to the web service fails\n            with a status code != `2xx`.\n\n            - `404`: The requested URI was not found.\n            - `500`: A server error occurred.\n        \"\"\"\n        return self._transport.call(\n            TransportArgs(\n                path=\"/processes/{processID}/execution\",\n                method=\"post\",\n                path_params={\"processID\": process_id},\n                request=request,\n                return_types={\"201\": JobInfo},\n                error_types={\"404\": ApiError, \"500\": ApiError},\n                extra_kwargs=kwargs,\n            )\n        )\n\n    def get_jobs(self, **kwargs: Any) -&gt; JobList:\n        \"\"\"\n        List available jobs.\n\n        For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n        Section 11](https://docs.ogc.org/is/18-062r2/18-062r2.html#sc_job_list).\n\n\n        Returns:\n          JobList: A list of jobs for this process.\n\n        Raises:\n          ClientError: If the call to the web service fails\n            with a status code != `2xx`.\n\n            - `404`: The requested URI was not found.\n        \"\"\"\n        return self._transport.call(\n            TransportArgs(\n                path=\"/jobs\",\n                method=\"get\",\n                return_types={\"200\": JobList},\n                error_types={\"404\": ApiError},\n                extra_kwargs=kwargs,\n            )\n        )\n\n    def get_job(self, job_id: str, **kwargs: Any) -&gt; JobInfo:\n        \"\"\"\n        Show the status of a job.\n\n        For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n        Section 7.12](https://docs.ogc.org/is/18-062r2/18-\n        062r2.html#sc_retrieve_status_info).\n\n        Args:\n          job_id: Local identifier of a job\n          kwargs: Optional keyword arguments that may be\n            used by the underlying transport.\n\n        Returns:\n          JobInfo: The status of a job.\n\n        Raises:\n          ClientError: If the call to the web service fails\n            with a status code != `2xx`.\n\n            - `404`: The requested URI was not found.\n            - `500`: A server error occurred.\n        \"\"\"\n        return self._transport.call(\n            TransportArgs(\n                path=\"/jobs/{jobId}\",\n                method=\"get\",\n                path_params={\"jobId\": job_id},\n                return_types={\"200\": JobInfo},\n                error_types={\"404\": ApiError, \"500\": ApiError},\n                extra_kwargs=kwargs,\n            )\n        )\n\n    def dismiss_job(self, job_id: str, **kwargs: Any) -&gt; JobInfo:\n        \"\"\"\n        Cancel a job execution and removes it from the jobs list.\n\n        For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n        Section 13](https://docs.ogc.org/is/18-062r2/18-062r2.html#Dismiss).\n\n        Args:\n          job_id: Local identifier of a job\n          kwargs: Optional keyword arguments that may be\n            used by the underlying transport.\n\n        Returns:\n          JobInfo: Information about the job.\n\n        Raises:\n          ClientError: If the call to the web service fails\n            with a status code != `2xx`.\n\n            - `404`: The requested URI was not found.\n            - `500`: A server error occurred.\n        \"\"\"\n        return self._transport.call(\n            TransportArgs(\n                path=\"/jobs/{jobId}\",\n                method=\"delete\",\n                path_params={\"jobId\": job_id},\n                return_types={\"200\": JobInfo},\n                error_types={\"404\": ApiError, \"500\": ApiError},\n                extra_kwargs=kwargs,\n            )\n        )\n\n    def get_job_results(self, job_id: str, **kwargs: Any) -&gt; JobResults:\n        \"\"\"\n        List available results of a job. In case of a failure, list errors\n        instead.\n\n        For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n        Section 7.13](https://docs.ogc.org/is/18-062r2/18-\n        062r2.html#sc_retrieve_job_results).\n\n        Args:\n          job_id: Local identifier of a job\n          kwargs: Optional keyword arguments that may be\n            used by the underlying transport.\n\n        Returns:\n          JobResults: The results of a job.\n\n        Raises:\n          ClientError: If the call to the web service fails\n            with a status code != `2xx`.\n\n            - `404`: The requested URI was not found.\n            - `500`: A server error occurred.\n        \"\"\"\n        return self._transport.call(\n            TransportArgs(\n                path=\"/jobs/{jobId}/results\",\n                method=\"get\",\n                path_params={\"jobId\": job_id},\n                return_types={\"200\": JobResults},\n                error_types={\"404\": ApiError, \"500\": ApiError},\n                extra_kwargs=kwargs,\n            )\n        )\n\n    def close(self):\n        \"\"\"Close this client.\"\"\"\n        if self._transport is not None:\n            self._transport.close()\n</code></pre>"},{"location":"cuiman/api/#cuiman.Client.get_capabilities","title":"<code>get_capabilities(**kwargs)</code>","text":"The landing page provides links to the <ul> <li>The OpenAPI-definition (no fixed path),</li> <li>The Conformance statements (path /conformance),</li> <li>The processes metadata (path /processes),</li> <li>The endpoint for job monitoring (path /jobs).</li> </ul> <p>For more information, see OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1 Section 7.2.</p> <p>Returns:</p> Name Type Description <code>Capabilities</code> <code>Capabilities</code> <p>The landing page provides links to the API definition (link relations <code>service-desc</code> and <code>service-doc</code>), the Conformance declaration (path <code>/conformance</code>, link relation <code>http://www.opengis.net/def/rel/ogc/1.0/conformance</code>), and to other resources.</p> <p>Raises:</p> Type Description <code>ClientError</code> <p>If the call to the web service fails with a status code != <code>2xx</code>.</p> <ul> <li><code>500</code>: A server error occurred.</li> </ul> Source code in <code>cuiman\\src\\cuiman\\api\\client.py</code> <pre><code>def get_capabilities(self, **kwargs: Any) -&gt; Capabilities:\n    \"\"\"\n    The landing page provides links to the:\n      * The OpenAPI-definition (no fixed path),\n      * The Conformance statements (path /conformance),\n      * The processes metadata (path /processes),\n      * The endpoint for job monitoring (path /jobs).\n\n    For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n    Section\n    7.2](https://docs.ogc.org/is/18-062r2/18-062r2.html#sc_landing_page).\n\n    Returns:\n      Capabilities: The landing page provides links to the API definition\n        (link relations `service-desc` and `service-doc`),\n        the Conformance declaration (path `/conformance`,\n        link relation `http://www.opengis.net/def/rel/ogc/1.0/conformance`),\n        and to other resources.\n\n    Raises:\n      ClientError: If the call to the web service fails\n        with a status code != `2xx`.\n\n        - `500`: A server error occurred.\n    \"\"\"\n    return self._transport.call(\n        TransportArgs(\n            path=\"/\",\n            method=\"get\",\n            return_types={\"200\": Capabilities},\n            error_types={\"500\": ApiError},\n            extra_kwargs=kwargs,\n        )\n    )\n</code></pre>"},{"location":"cuiman/api/#cuiman.Client.get_conformance","title":"<code>get_conformance(**kwargs)</code>","text":"<p>A list of all conformance classes, specified in a standard, that the server conforms to.</p> Conformance class URI Core http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/core OGC Process Description http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/ogc-process-description JSON http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/json HTML http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/html OpenAPI Specification 3.0 http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/oas30 Job list http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/job-list Callback http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/callback Dismiss http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/dismiss <p>For more information, see OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1 Section 7.4.</p> <p>Returns:</p> Name Type Description <code>ConformanceDeclaration</code> <code>ConformanceDeclaration</code> <p>The URIs of all conformance classes supported by the server. To support \"generic\" clients that want to access multiple OGC API - Processes implementations - and not \"just\" a specific API / server, the server declares the conformance classes it implements and conforms to.</p> <p>Raises:</p> Type Description <code>ClientError</code> <p>If the call to the web service fails with a status code != <code>2xx</code>.</p> <ul> <li><code>500</code>: A server error occurred.</li> </ul> Source code in <code>cuiman\\src\\cuiman\\api\\client.py</code> <pre><code>def get_conformance(self, **kwargs: Any) -&gt; ConformanceDeclaration:\n    \"\"\"\n    A list of all conformance classes, specified in a standard, that the\n    server conforms to.\n\n    | Conformance class | URI |\n    |-----------|-------|\n    |Core|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/core|\n    |OGC Process Description|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/ogc-process-description|\n    |JSON|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/json|\n    |HTML|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/html|\n    |OpenAPI Specification 3.0|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/oas30|\n    |Job list|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/job-list|\n    |Callback|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/callback|\n    |Dismiss|http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/dismiss|\n\n    For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n    Section 7.4](https://docs.ogc.org/is/18-062r2/18-\n    062r2.html#sc_conformance_classes).\n\n\n    Returns:\n      ConformanceDeclaration: The URIs of all conformance classes supported\n        by the server. To support \"generic\" clients that want\n        to access multiple OGC API - Processes implementations - and\n        not \"just\" a specific API / server, the server declares\n        the conformance classes it implements and conforms to.\n\n    Raises:\n      ClientError: If the call to the web service fails\n        with a status code != `2xx`.\n\n        - `500`: A server error occurred.\n    \"\"\"\n    return self._transport.call(\n        TransportArgs(\n            path=\"/conformance\",\n            method=\"get\",\n            return_types={\"200\": ConformanceDeclaration},\n            error_types={\"500\": ApiError},\n            extra_kwargs=kwargs,\n        )\n    )\n</code></pre>"},{"location":"cuiman/api/#cuiman.Client.get_processes","title":"<code>get_processes(**kwargs)</code>","text":"<p>The list of processes contains a summary of each process the OGC API - Processes offers, including the link to a more detailed description of the process.</p> <p>For more information, see OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1 Section 7.9.</p> <p>Returns:</p> Name Type Description <code>ProcessList</code> <code>ProcessList</code> <p>Information about the available processes</p> <p>Raises:</p> Type Description <code>ClientError</code> <p>If the call to the web service fails with a status code != <code>2xx</code>.</p> Source code in <code>cuiman\\src\\cuiman\\api\\client.py</code> <pre><code>def get_processes(self, **kwargs: Any) -&gt; ProcessList:\n    \"\"\"\n    The list of processes contains a summary of each process the OGC API -\n    Processes offers, including the link to a more detailed description of\n    the process.\n\n    For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n    Section\n    7.9](https://docs.ogc.org/is/18-062r2/18-062r2.html#sc_process_list).\n\n\n    Returns:\n      ProcessList: Information about the available processes\n\n    Raises:\n      ClientError: If the call to the web service fails\n        with a status code != `2xx`.\n    \"\"\"\n    return self._transport.call(\n        TransportArgs(\n            path=\"/processes\",\n            method=\"get\",\n            return_types={\"200\": ProcessList},\n            extra_kwargs=kwargs,\n        )\n    )\n</code></pre>"},{"location":"cuiman/api/#cuiman.Client.get_process","title":"<code>get_process(process_id, **kwargs)</code>","text":"<p>The process description contains information about inputs and outputs and a link to the execution-endpoint for the process. The Core does not mandate the use of a specific process description to specify the interface of a process. That said, the Core requirements class makes the following recommendation:</p> <p>Implementations should consider supporting the OGC process description.</p> <p>For more information, see OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1 Section 7.10.</p> <p>Parameters:</p> Name Type Description Default <code>process_id</code> <code>str</code> required <code>kwargs</code> <code>Any</code> <p>Optional keyword arguments that may be used by the underlying transport.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>ProcessDescription</code> <code>ProcessDescription</code> <p>A process description.</p> <p>Raises:</p> Type Description <code>ClientError</code> <p>If the call to the web service fails with a status code != <code>2xx</code>.</p> <ul> <li><code>404</code>: The requested URI was not found.</li> </ul> Source code in <code>cuiman\\src\\cuiman\\api\\client.py</code> <pre><code>def get_process(self, process_id: str, **kwargs: Any) -&gt; ProcessDescription:\n    \"\"\"\n    The process description contains information about inputs and outputs\n    and a link to the execution-endpoint for the process. The Core does not\n    mandate the use of a specific process description to specify the\n    interface of a process. That said, the Core requirements class makes the\n    following recommendation:\n\n    Implementations **should** consider supporting the OGC process\n    description.\n\n    For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n    Section 7.10](https://docs.ogc.org/is/18-062r2/18-\n    062r2.html#sc_process_description).\n\n    Args:\n      process_id:\n      kwargs: Optional keyword arguments that may be\n        used by the underlying transport.\n\n    Returns:\n      ProcessDescription: A process description.\n\n    Raises:\n      ClientError: If the call to the web service fails\n        with a status code != `2xx`.\n\n        - `404`: The requested URI was not found.\n    \"\"\"\n    return self._transport.call(\n        TransportArgs(\n            path=\"/processes/{processID}\",\n            method=\"get\",\n            path_params={\"processID\": process_id},\n            return_types={\"200\": ProcessDescription},\n            error_types={\"404\": ApiError},\n            extra_kwargs=kwargs,\n        )\n    )\n</code></pre>"},{"location":"cuiman/api/#cuiman.Client.execute_process","title":"<code>execute_process(process_id, request, **kwargs)</code>","text":"<p>Create a new job.</p> <p>For more information, see OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1 Section 7.11.</p> <p>Parameters:</p> Name Type Description Default <code>process_id</code> <code>str</code> required <code>kwargs</code> <code>Any</code> <p>Optional keyword arguments that may be used by the underlying transport.</p> <code>{}</code> <code>request</code> <code>ProcessRequest</code> <p>Mandatory request JSON</p> required <p>Returns:</p> Name Type Description <code>JobInfo</code> <code>JobInfo</code> <p>Started asynchronous execution. Created job.</p> <p>Raises:</p> Type Description <code>ClientError</code> <p>If the call to the web service fails with a status code != <code>2xx</code>.</p> <ul> <li><code>404</code>: The requested URI was not found.</li> <li><code>500</code>: A server error occurred.</li> </ul> Source code in <code>cuiman\\src\\cuiman\\api\\client.py</code> <pre><code>def execute_process(\n    self, process_id: str, request: ProcessRequest, **kwargs: Any\n) -&gt; JobInfo:\n    \"\"\"\n    Create a new job.\n\n    For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n    Section\n    7.11](https://docs.ogc.org/is/18-062r2/18-062r2.html#sc_create_job).\n\n    Args:\n      process_id:\n      kwargs: Optional keyword arguments that may be\n        used by the underlying transport.\n      request: Mandatory request JSON\n\n    Returns:\n      JobInfo: Started asynchronous execution. Created job.\n\n    Raises:\n      ClientError: If the call to the web service fails\n        with a status code != `2xx`.\n\n        - `404`: The requested URI was not found.\n        - `500`: A server error occurred.\n    \"\"\"\n    return self._transport.call(\n        TransportArgs(\n            path=\"/processes/{processID}/execution\",\n            method=\"post\",\n            path_params={\"processID\": process_id},\n            request=request,\n            return_types={\"201\": JobInfo},\n            error_types={\"404\": ApiError, \"500\": ApiError},\n            extra_kwargs=kwargs,\n        )\n    )\n</code></pre>"},{"location":"cuiman/api/#cuiman.Client.get_jobs","title":"<code>get_jobs(**kwargs)</code>","text":"<p>List available jobs.</p> <p>For more information, see OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1 Section 11.</p> <p>Returns:</p> Name Type Description <code>JobList</code> <code>JobList</code> <p>A list of jobs for this process.</p> <p>Raises:</p> Type Description <code>ClientError</code> <p>If the call to the web service fails with a status code != <code>2xx</code>.</p> <ul> <li><code>404</code>: The requested URI was not found.</li> </ul> Source code in <code>cuiman\\src\\cuiman\\api\\client.py</code> <pre><code>def get_jobs(self, **kwargs: Any) -&gt; JobList:\n    \"\"\"\n    List available jobs.\n\n    For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n    Section 11](https://docs.ogc.org/is/18-062r2/18-062r2.html#sc_job_list).\n\n\n    Returns:\n      JobList: A list of jobs for this process.\n\n    Raises:\n      ClientError: If the call to the web service fails\n        with a status code != `2xx`.\n\n        - `404`: The requested URI was not found.\n    \"\"\"\n    return self._transport.call(\n        TransportArgs(\n            path=\"/jobs\",\n            method=\"get\",\n            return_types={\"200\": JobList},\n            error_types={\"404\": ApiError},\n            extra_kwargs=kwargs,\n        )\n    )\n</code></pre>"},{"location":"cuiman/api/#cuiman.Client.get_job","title":"<code>get_job(job_id, **kwargs)</code>","text":"<p>Show the status of a job.</p> <p>For more information, see OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1 Section 7.12.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Local identifier of a job</p> required <code>kwargs</code> <code>Any</code> <p>Optional keyword arguments that may be used by the underlying transport.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>JobInfo</code> <code>JobInfo</code> <p>The status of a job.</p> <p>Raises:</p> Type Description <code>ClientError</code> <p>If the call to the web service fails with a status code != <code>2xx</code>.</p> <ul> <li><code>404</code>: The requested URI was not found.</li> <li><code>500</code>: A server error occurred.</li> </ul> Source code in <code>cuiman\\src\\cuiman\\api\\client.py</code> <pre><code>def get_job(self, job_id: str, **kwargs: Any) -&gt; JobInfo:\n    \"\"\"\n    Show the status of a job.\n\n    For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n    Section 7.12](https://docs.ogc.org/is/18-062r2/18-\n    062r2.html#sc_retrieve_status_info).\n\n    Args:\n      job_id: Local identifier of a job\n      kwargs: Optional keyword arguments that may be\n        used by the underlying transport.\n\n    Returns:\n      JobInfo: The status of a job.\n\n    Raises:\n      ClientError: If the call to the web service fails\n        with a status code != `2xx`.\n\n        - `404`: The requested URI was not found.\n        - `500`: A server error occurred.\n    \"\"\"\n    return self._transport.call(\n        TransportArgs(\n            path=\"/jobs/{jobId}\",\n            method=\"get\",\n            path_params={\"jobId\": job_id},\n            return_types={\"200\": JobInfo},\n            error_types={\"404\": ApiError, \"500\": ApiError},\n            extra_kwargs=kwargs,\n        )\n    )\n</code></pre>"},{"location":"cuiman/api/#cuiman.Client.dismiss_job","title":"<code>dismiss_job(job_id, **kwargs)</code>","text":"<p>Cancel a job execution and removes it from the jobs list.</p> <p>For more information, see OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1 Section 13.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Local identifier of a job</p> required <code>kwargs</code> <code>Any</code> <p>Optional keyword arguments that may be used by the underlying transport.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>JobInfo</code> <code>JobInfo</code> <p>Information about the job.</p> <p>Raises:</p> Type Description <code>ClientError</code> <p>If the call to the web service fails with a status code != <code>2xx</code>.</p> <ul> <li><code>404</code>: The requested URI was not found.</li> <li><code>500</code>: A server error occurred.</li> </ul> Source code in <code>cuiman\\src\\cuiman\\api\\client.py</code> <pre><code>def dismiss_job(self, job_id: str, **kwargs: Any) -&gt; JobInfo:\n    \"\"\"\n    Cancel a job execution and removes it from the jobs list.\n\n    For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n    Section 13](https://docs.ogc.org/is/18-062r2/18-062r2.html#Dismiss).\n\n    Args:\n      job_id: Local identifier of a job\n      kwargs: Optional keyword arguments that may be\n        used by the underlying transport.\n\n    Returns:\n      JobInfo: Information about the job.\n\n    Raises:\n      ClientError: If the call to the web service fails\n        with a status code != `2xx`.\n\n        - `404`: The requested URI was not found.\n        - `500`: A server error occurred.\n    \"\"\"\n    return self._transport.call(\n        TransportArgs(\n            path=\"/jobs/{jobId}\",\n            method=\"delete\",\n            path_params={\"jobId\": job_id},\n            return_types={\"200\": JobInfo},\n            error_types={\"404\": ApiError, \"500\": ApiError},\n            extra_kwargs=kwargs,\n        )\n    )\n</code></pre>"},{"location":"cuiman/api/#cuiman.Client.get_job_results","title":"<code>get_job_results(job_id, **kwargs)</code>","text":"<p>List available results of a job. In case of a failure, list errors instead.</p> <p>For more information, see OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1 Section 7.13.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Local identifier of a job</p> required <code>kwargs</code> <code>Any</code> <p>Optional keyword arguments that may be used by the underlying transport.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>JobResults</code> <code>JobResults</code> <p>The results of a job.</p> <p>Raises:</p> Type Description <code>ClientError</code> <p>If the call to the web service fails with a status code != <code>2xx</code>.</p> <ul> <li><code>404</code>: The requested URI was not found.</li> <li><code>500</code>: A server error occurred.</li> </ul> Source code in <code>cuiman\\src\\cuiman\\api\\client.py</code> <pre><code>def get_job_results(self, job_id: str, **kwargs: Any) -&gt; JobResults:\n    \"\"\"\n    List available results of a job. In case of a failure, list errors\n    instead.\n\n    For more information, see [OGC API\u2009\u2014\u2009Processes\u2009\u2014\u2009Part 1\n    Section 7.13](https://docs.ogc.org/is/18-062r2/18-\n    062r2.html#sc_retrieve_job_results).\n\n    Args:\n      job_id: Local identifier of a job\n      kwargs: Optional keyword arguments that may be\n        used by the underlying transport.\n\n    Returns:\n      JobResults: The results of a job.\n\n    Raises:\n      ClientError: If the call to the web service fails\n        with a status code != `2xx`.\n\n        - `404`: The requested URI was not found.\n        - `500`: A server error occurred.\n    \"\"\"\n    return self._transport.call(\n        TransportArgs(\n            path=\"/jobs/{jobId}/results\",\n            method=\"get\",\n            path_params={\"jobId\": job_id},\n            return_types={\"200\": JobResults},\n            error_types={\"404\": ApiError, \"500\": ApiError},\n            extra_kwargs=kwargs,\n        )\n    )\n</code></pre>"},{"location":"cuiman/api/#cuiman.Client.close","title":"<code>close()</code>","text":"<p>Close this client.</p> Source code in <code>cuiman\\src\\cuiman\\api\\client.py</code> <pre><code>def close(self):\n    \"\"\"Close this client.\"\"\"\n    if self._transport is not None:\n        self._transport.close()\n</code></pre>"},{"location":"cuiman/api/#cuiman.ClientConfig","title":"<code>cuiman.ClientConfig</code>","text":"<p>               Bases: <code>AuthConfig</code>, <code>BaseSettings</code></p> <p>Client configuration.</p> <p>Parameters:</p> Name Type Description Default <code>api_url</code> <p>a URL pointing to a service compliant with the OCG API - Processes.</p> required Source code in <code>cuiman\\src\\cuiman\\api\\config.py</code> <pre><code>class ClientConfig(AuthConfig, BaseSettings):\n    \"\"\"Client configuration.\n\n    Args:\n        api_url: a URL pointing to a service compliant with\n            the OCG API - Processes.\n    \"\"\"\n\n    model_config = SettingsConfigDict(\n        env_prefix=\"EOZILLA_\",\n        extra=\"forbid\",\n    )\n\n    default_config: ClassVar[\"ClientConfig\"]\n    \"\"\"\n    Default instance. \n    Used to create pre-configured instances of this class.\n    Designed to be overridden by library clients.\n    \"\"\"\n\n    default_path: ClassVar[Path]\n    \"\"\"\n    Name of the configuration's local default path. \n    Used for configuration persistence in `~/.&lt;config_name&gt;/`.\n    Designed to be overridden by library clients.\n    \"\"\"\n\n    return_type_map: ClassVar[dict[type, type]] = {}\n    \"\"\"\n    A mapping from a hard-coded client return type to a \n    custom return type. The hard-coded return type is usually a \n    model class from `gavicore.models`. The custom return type \n    typically extends the model class.  \n    Designed to be configured by library clients.\n    The default mapping is empty.\n    \"\"\"\n\n    api_url: Annotated[Optional[str], Field(title=\"Process API URL\")] = None\n    \"\"\"\n    The URL of the server that provides a web API compliant with\n    OGC API - Processes, Part 1 - Core.\n    \"\"\"\n\n    def _repr_json_(self):\n        return self.model_dump(mode=\"json\", by_alias=True), dict(\n            root=\"Client configuration:\"\n        )\n\n    @classmethod\n    def create(\n        cls,\n        *,\n        config: Optional[\"ClientConfig\"] = None,\n        config_path: Optional[Path | str] = None,\n        **config_kwargs,\n    ) -&gt; \"ClientConfig\":\n        # 0. from defaults\n        config_dict = cls.default_config.to_dict()\n\n        # 1. from file\n        file_config = cls.from_file(config_path=config_path)\n        if file_config is not None:\n            _update_if_not_none(config_dict, file_config.to_dict())\n\n        # 2. from env\n        env_config = cls()\n        _update_if_not_none(config_dict, env_config.to_dict())\n\n        # 3. from config\n        if config is not None:\n            _update_if_not_none(config_dict, config.to_dict())\n\n        # 4. from kwargs\n        _update_if_not_none(config_dict, config_kwargs)\n\n        return cls.new_instance(**config_dict)\n\n    @classmethod\n    def from_file(\n        cls, config_path: Optional[str | Path] = None\n    ) -&gt; Optional[\"ClientConfig\"]:\n        config_path_: Path = cls.normalize_config_path(config_path)\n        if not config_path_.exists():\n            return None\n        with config_path_.open(\"rt\") as stream:\n            # Note, we may switch TOML\n            config_dict = yaml.safe_load(stream)\n        return cls.new_instance(**config_dict)\n\n    def write(self, config_path: Optional[str | Path] = None) -&gt; Path:\n        config_path = self.normalize_config_path(config_path)\n        config_path.parent.mkdir(exist_ok=True)\n        with config_path.open(\"wt\") as stream:\n            yaml.dump(\n                self.model_dump(mode=\"json\", by_alias=True, exclude_none=True), stream\n            )\n        return config_path\n\n    @classmethod\n    def normalize_config_path(cls, config_path) -&gt; Path:\n        return (\n            config_path\n            if isinstance(config_path, Path)\n            else (Path(config_path) if config_path else cls.default_path)\n        )\n\n    @classmethod\n    def new_instance(\n        cls,\n        **kwargs: Any,\n    ) -&gt; \"ClientConfig\":\n        config_cls = type(ClientConfig.default_config)\n        assert issubclass(config_cls, ClientConfig)\n        return config_cls(**kwargs)\n\n    def to_dict(self):\n        return self.model_dump(\n            mode=\"json\",\n            by_alias=True,\n            exclude_none=True,\n            exclude_defaults=True,\n            exclude_unset=True,\n        )\n\n    # noinspection PyMethodParameters\n    @field_validator(\"api_url\")\n    def validate_api_url(cls, v: str | None) -&gt; str | None:\n        return None if v is None or v == \"\" else str(HttpUrl(v))\n\n    # noinspection PyUnusedLocal\n    @classmethod\n    def accept_process(\n        cls, process_summary: ProcessSummary, **filter_kwargs: Any\n    ) -&gt; bool:\n        \"\"\"\n        Predicate function that is used to filter the list of processes.\n        The function is intended to be overridden by subclasses in order to allow\n        for evaluating the given `process_summary` in an application-specific way.\n        This includes the using custom fields in the given\n        [ProcessSummary][gavicore.models.ProcessSummary] instance.\n\n        Applications may use the [extend_model()][gavicore.util.model.extend_model]\n        function to enhance existing model classes by their custom fields.\n\n        The default implementation unconditionally returns `True`.\n\n        Args:\n            process_summary: A process summary.\n            filter_kwargs: Implementation specific arguments passed\n                by a user of this class.\n\n        Returns:\n            `True` to accept the given process, otherwise `False`.\n        \"\"\"\n        return True\n\n    # noinspection PyUnusedLocal\n    @classmethod\n    def accept_input(\n        cls,\n        process_description: ProcessDescription,\n        input_name: str,\n        input_description: InputDescription,\n        **filter_kwargs: Any,\n    ) -&gt; bool:\n        \"\"\"\n        Predicate function that is used to filter the list of inputs of a process.\n        The function is intended to be overridden by subclasses in order to allow\n        for evaluating the given `input_description` in an application-specific way.\n        This includes the using custom fields in the given\n        [InputDescription][gavicore.models.InputDescription] instance.\n\n        Applications may use the [extend_model()][gavicore.util.model.extend_model]\n        function to enhance existing model classes by their custom fields.\n\n        The default implementation unconditionally returns `True`.\n\n        Args:\n            process_description: The process description.\n            input_name: The input's name.\n            input_description: A description of an\n                input of the given `process_description`.\n            filter_kwargs: Implementation specific arguments passed\n                by a user of this class.\n\n        Returns:\n            `True` to accept the given input, otherwise `False`.\n        \"\"\"\n        return True\n\n    # noinspection PyUnusedLocal\n    @classmethod\n    def is_advanced_input(\n        cls,\n        process_description: ProcessDescription,\n        input_name: str,\n        input_description: InputDescription,\n    ) -&gt; bool:\n        \"\"\"\n        Experimental method, do not use!\n\n        Designed to be overridden by a custom `ClientConfig` class\n        from which an instance will be assigned to `ClientConfig.default_config`\n        to become effective.\n\n        The default implementations checks if the given `input_description`\n        has `additionalParameters`, and if so, if a parameter with name\n        `\"level\"` has value `[\"advanced\"]` (a list!).\n\n        Args:\n            process_description: The process description.\n            input_name: The input's name.\n            input_description: A description of an\n                input of the given `process_description`.\n\n        Returns:\n            `True` if the input is advanced\n            (e.g. for advanced process users only).\n        \"\"\"\n        additional_parameters = input_description.additionalParameters\n        if additional_parameters:\n            parameters = additional_parameters.parameters\n            if parameters:\n                for p in parameters:\n                    if p.name == \"level\" and p.value == [\"advanced\"]:\n                        return True\n        return False\n</code></pre>"},{"location":"cuiman/api/#cuiman.ClientConfig.default_config","title":"<code>default_config</code>  <code>class-attribute</code>","text":"<p>Default instance.  Used to create pre-configured instances of this class. Designed to be overridden by library clients.</p>"},{"location":"cuiman/api/#cuiman.ClientConfig.default_path","title":"<code>default_path</code>  <code>class-attribute</code>","text":"<p>Name of the configuration's local default path.  Used for configuration persistence in <code>~/.&lt;config_name&gt;/</code>. Designed to be overridden by library clients.</p>"},{"location":"cuiman/api/#cuiman.ClientConfig.return_type_map","title":"<code>return_type_map = {}</code>  <code>class-attribute</code>","text":"<p>A mapping from a hard-coded client return type to a  custom return type. The hard-coded return type is usually a  model class from <code>gavicore.models</code>. The custom return type  typically extends the model class. Designed to be configured by library clients. The default mapping is empty.</p>"},{"location":"cuiman/api/#cuiman.ClientConfig.api_url","title":"<code>api_url = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The URL of the server that provides a web API compliant with OGC API - Processes, Part 1 - Core.</p>"},{"location":"cuiman/api/#cuiman.ClientConfig.accept_process","title":"<code>accept_process(process_summary, **filter_kwargs)</code>  <code>classmethod</code>","text":"<p>Predicate function that is used to filter the list of processes. The function is intended to be overridden by subclasses in order to allow for evaluating the given <code>process_summary</code> in an application-specific way. This includes the using custom fields in the given [ProcessSummary][gavicore.models.ProcessSummary] instance.</p> <p>Applications may use the [extend_model()][gavicore.util.model.extend_model] function to enhance existing model classes by their custom fields.</p> <p>The default implementation unconditionally returns <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>process_summary</code> <code>ProcessSummary</code> <p>A process summary.</p> required <code>filter_kwargs</code> <code>Any</code> <p>Implementation specific arguments passed by a user of this class.</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> to accept the given process, otherwise <code>False</code>.</p> Source code in <code>cuiman\\src\\cuiman\\api\\config.py</code> <pre><code>@classmethod\ndef accept_process(\n    cls, process_summary: ProcessSummary, **filter_kwargs: Any\n) -&gt; bool:\n    \"\"\"\n    Predicate function that is used to filter the list of processes.\n    The function is intended to be overridden by subclasses in order to allow\n    for evaluating the given `process_summary` in an application-specific way.\n    This includes the using custom fields in the given\n    [ProcessSummary][gavicore.models.ProcessSummary] instance.\n\n    Applications may use the [extend_model()][gavicore.util.model.extend_model]\n    function to enhance existing model classes by their custom fields.\n\n    The default implementation unconditionally returns `True`.\n\n    Args:\n        process_summary: A process summary.\n        filter_kwargs: Implementation specific arguments passed\n            by a user of this class.\n\n    Returns:\n        `True` to accept the given process, otherwise `False`.\n    \"\"\"\n    return True\n</code></pre>"},{"location":"cuiman/api/#cuiman.ClientConfig.accept_input","title":"<code>accept_input(process_description, input_name, input_description, **filter_kwargs)</code>  <code>classmethod</code>","text":"<p>Predicate function that is used to filter the list of inputs of a process. The function is intended to be overridden by subclasses in order to allow for evaluating the given <code>input_description</code> in an application-specific way. This includes the using custom fields in the given [InputDescription][gavicore.models.InputDescription] instance.</p> <p>Applications may use the [extend_model()][gavicore.util.model.extend_model] function to enhance existing model classes by their custom fields.</p> <p>The default implementation unconditionally returns <code>True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>process_description</code> <code>ProcessDescription</code> <p>The process description.</p> required <code>input_name</code> <code>str</code> <p>The input's name.</p> required <code>input_description</code> <code>InputDescription</code> <p>A description of an input of the given <code>process_description</code>.</p> required <code>filter_kwargs</code> <code>Any</code> <p>Implementation specific arguments passed by a user of this class.</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> to accept the given input, otherwise <code>False</code>.</p> Source code in <code>cuiman\\src\\cuiman\\api\\config.py</code> <pre><code>@classmethod\ndef accept_input(\n    cls,\n    process_description: ProcessDescription,\n    input_name: str,\n    input_description: InputDescription,\n    **filter_kwargs: Any,\n) -&gt; bool:\n    \"\"\"\n    Predicate function that is used to filter the list of inputs of a process.\n    The function is intended to be overridden by subclasses in order to allow\n    for evaluating the given `input_description` in an application-specific way.\n    This includes the using custom fields in the given\n    [InputDescription][gavicore.models.InputDescription] instance.\n\n    Applications may use the [extend_model()][gavicore.util.model.extend_model]\n    function to enhance existing model classes by their custom fields.\n\n    The default implementation unconditionally returns `True`.\n\n    Args:\n        process_description: The process description.\n        input_name: The input's name.\n        input_description: A description of an\n            input of the given `process_description`.\n        filter_kwargs: Implementation specific arguments passed\n            by a user of this class.\n\n    Returns:\n        `True` to accept the given input, otherwise `False`.\n    \"\"\"\n    return True\n</code></pre>"},{"location":"cuiman/api/#cuiman.ClientConfig.is_advanced_input","title":"<code>is_advanced_input(process_description, input_name, input_description)</code>  <code>classmethod</code>","text":"<p>Experimental method, do not use!</p> <p>Designed to be overridden by a custom <code>ClientConfig</code> class from which an instance will be assigned to <code>ClientConfig.default_config</code> to become effective.</p> <p>The default implementations checks if the given <code>input_description</code> has <code>additionalParameters</code>, and if so, if a parameter with name <code>\"level\"</code> has value <code>[\"advanced\"]</code> (a list!).</p> <p>Parameters:</p> Name Type Description Default <code>process_description</code> <code>ProcessDescription</code> <p>The process description.</p> required <code>input_name</code> <code>str</code> <p>The input's name.</p> required <code>input_description</code> <code>InputDescription</code> <p>A description of an input of the given <code>process_description</code>.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input is advanced</p> <code>bool</code> <p>(e.g. for advanced process users only).</p> Source code in <code>cuiman\\src\\cuiman\\api\\config.py</code> <pre><code>@classmethod\ndef is_advanced_input(\n    cls,\n    process_description: ProcessDescription,\n    input_name: str,\n    input_description: InputDescription,\n) -&gt; bool:\n    \"\"\"\n    Experimental method, do not use!\n\n    Designed to be overridden by a custom `ClientConfig` class\n    from which an instance will be assigned to `ClientConfig.default_config`\n    to become effective.\n\n    The default implementations checks if the given `input_description`\n    has `additionalParameters`, and if so, if a parameter with name\n    `\"level\"` has value `[\"advanced\"]` (a list!).\n\n    Args:\n        process_description: The process description.\n        input_name: The input's name.\n        input_description: A description of an\n            input of the given `process_description`.\n\n    Returns:\n        `True` if the input is advanced\n        (e.g. for advanced process users only).\n    \"\"\"\n    additional_parameters = input_description.additionalParameters\n    if additional_parameters:\n        parameters = additional_parameters.parameters\n        if parameters:\n            for p in parameters:\n                if p.name == \"level\" and p.value == [\"advanced\"]:\n                    return True\n    return False\n</code></pre>"},{"location":"cuiman/api/#cuiman.ClientError","title":"<code>cuiman.ClientError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised if a web API call failed.</p> <p>The failure can have several reasons such as</p> <ul> <li>the request failed with a status code that is not 2xx, or</li> <li>the received JSON response is not parsable.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The error message</p> required <code>api_error</code> <code>ApiError</code> <p>The details describing the error that occurred on the server or the details that describe a non-expected response from the server.</p> required Source code in <code>cuiman\\src\\cuiman\\api\\exceptions.py</code> <pre><code>class ClientError(Exception):\n    \"\"\"Raised if a web API call failed.\n\n     The failure can have several reasons such as\n\n    - the request failed with a status code that is not 2xx, or\n    - the received JSON response is not parsable.\n\n    Args:\n        message: The error message\n        api_error: The details describing the error that occurred on the server\n            or the details that describe a non-expected response from the server.\n    \"\"\"\n\n    def __init__(self, message: str, api_error: ApiError):\n        super().__init__(message)\n        self.api_error = api_error\n</code></pre>"},{"location":"cuiman/cli/","title":"Cuiman CLI","text":"<p>The <code>cuiman</code> tool is a shell client for any web services  compliant with OGC API - Processes, Part 1: Core Standard.</p> <p><code>cuiman</code> can be used to get the available processes, get process  details, execute processes, and manage the jobs originating from the latter. It  herewith resembles the core functionality of the OGC API - Processes, Part 1. For details see https://ogcapi.ogc.org/processes/.</p> <p>You can use shorter command name aliases, e.g., use command name <code>vr</code> for <code>validate-request</code>, or <code>lp</code> for <code>list-processes</code>.</p> <p>The tool's exit codes are as follows:</p> <ul> <li><code>0</code> - normal exit</li> <li><code>1</code> - user errors, argument errors</li> <li><code>2</code> - remote API errors </li> <li><code>3</code> - local network transport errors</li> </ul> <p>If the <code>--traceback</code> flag is set, the original Python exception traceback will be shown and the exit code will always be <code>1</code>.  Otherwise, only the error message is shown.</p> <p>Usage:</p> <pre><code>$ cuiman [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--version</code>: Show version and exit.</li> <li><code>--traceback, --tb</code>: Show server exception traceback, if any.</li> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>configure</code>: Configure the client tool.</li> <li><code>list-processes</code>: List available processes.</li> <li><code>get-process</code>: Get process details.</li> <li><code>create-request</code>: Create an execution request (template) for...</li> <li><code>validate-request</code>: Validate a process execution request.</li> <li><code>execute-process</code>: Execute a process in asynchronous mode.</li> <li><code>list-jobs</code>: List all jobs.</li> <li><code>get-job</code>: Get job details.</li> <li><code>dismiss-job</code>: Cancel a running or delete a finished job.</li> <li><code>get-job-results</code>: Get job results.</li> </ul>"},{"location":"cuiman/cli/#cuiman-configure","title":"<code>cuiman configure</code>","text":"<p>Configure the client tool.</p> <p>Usage:</p> <pre><code>$ cuiman configure [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--api-url TEXT</code>: The URL of a service complying to the OGC API - Processes.</li> <li><code>-a, --auth-type TEXT</code>: The authorisation method for the API (none|basic|token|login|api-key).</li> <li><code>--auth-url TEXT</code>: The URL of the authorisation service for the API</li> <li><code>-u, --username TEXT</code>: Username.</li> <li><code>-p, --password TEXT</code>: Password.</li> <li><code>-t, --token TEXT</code>: Access token.</li> <li><code>--use-bearer</code>: Use bearer token?</li> <li><code>--token-header TEXT</code>: Access token header</li> <li><code>-c, --config PATH</code>: Client configuration file.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cuiman/cli/#cuiman-list-processes","title":"<code>cuiman list-processes</code>","text":"<p>List available processes.</p> <p>Usage:</p> <pre><code>$ cuiman list-processes [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-c, --config PATH</code>: Client configuration file.</li> <li><code>-f, --format [simple|json|yaml]</code>: Output format.  [default: yaml]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cuiman/cli/#cuiman-get-process","title":"<code>cuiman get-process</code>","text":"<p>Get process details.</p> <p>Usage:</p> <pre><code>$ cuiman get-process [OPTIONS] PROCESS_ID\n</code></pre> <p>Arguments:</p> <ul> <li><code>PROCESS_ID</code>: Process identifier.  [required]</li> </ul> <p>Options:</p> <ul> <li><code>-c, --config PATH</code>: Client configuration file.</li> <li><code>-f, --format [simple|json|yaml]</code>: Output format.  [default: yaml]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cuiman/cli/#cuiman-create-request","title":"<code>cuiman create-request</code>","text":"<p>Create an execution request (template) for a given process.</p> <p>The generated template comprises generated default values for all inputs. Note that they might not necessarily be valid. The generated template request may serve as a starting point for the actual, valid execution request.</p> <p>Usage:</p> <pre><code>$ cuiman create-request [OPTIONS] [PROCESS_ID]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[PROCESS_ID]</code>: Process identifier.</li> </ul> <p>Options:</p> <ul> <li><code>-d, --dotpath</code>: Input names use dot-path notion to encode nested values, e.g., <code>-i scene.colors.bg=red</code>.</li> <li><code>-c, --config PATH</code>: Client configuration file.</li> <li><code>-f, --format [simple|json|yaml]</code>: Output format.  [default: yaml]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cuiman/cli/#cuiman-validate-request","title":"<code>cuiman validate-request</code>","text":"<p>Validate a process execution request.</p> <p>The execution request to be validated may be read from a file given by <code>--request</code>, or from <code>stdin</code>, or from the <code>process_id</code> argument with zero, one, or more <code>--input</code> (or <code>-i</code>) options.</p> <p>The <code>process_id</code> argument and any given <code>--input</code> options will override settings with the same name found in the given request file or <code>stdin</code>, if any.</p> <p>Usage:</p> <pre><code>$ cuiman validate-request [OPTIONS] [PROCESS_ID]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[PROCESS_ID]</code>: Process identifier.</li> </ul> <p>Options:</p> <ul> <li><code>-d, --dotpath</code>: Input names use dot-path notion to encode nested values, e.g., <code>-i scene.colors.bg=red</code>.</li> <li><code>-i, --input [NAME=VALUE]...</code>: Process input value.</li> <li><code>-r, --request PATH</code>: Execution request file. Use <code>-</code> to read from &lt;stdin&gt;.</li> <li><code>-f, --format [simple|json|yaml]</code>: Output format.  [default: yaml]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cuiman/cli/#cuiman-execute-process","title":"<code>cuiman execute-process</code>","text":"<p>Execute a process in asynchronous mode.</p> <p>The execution request to be submitted may be read from a file given by <code>--request</code>, or from <code>stdin</code>, or from the <code>process_id</code> argument with zero, one, or more <code>--input</code> (or <code>-i</code>) options.</p> <p>The <code>process_id</code> argument and any given <code>--input</code> options will override settings with same name found in the given request file or <code>stdin</code>, if any.</p> <p>Usage:</p> <pre><code>$ cuiman execute-process [OPTIONS] [PROCESS_ID]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[PROCESS_ID]</code>: Process identifier.</li> </ul> <p>Options:</p> <ul> <li><code>-d, --dotpath</code>: Input names use dot-path notion to encode nested values, e.g., <code>-i scene.colors.bg=red</code>.</li> <li><code>-i, --input [NAME=VALUE]...</code>: Process input value.</li> <li><code>-s, --subscriber [NAME=URL]...</code>: Process subscriber URL.</li> <li><code>-r, --request PATH</code>: Execution request file. Use <code>-</code> to read from &lt;stdin&gt;.</li> <li><code>-c, --config PATH</code>: Client configuration file.</li> <li><code>-f, --format [simple|json|yaml]</code>: Output format.  [default: yaml]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cuiman/cli/#cuiman-list-jobs","title":"<code>cuiman list-jobs</code>","text":"<p>List all jobs.</p> <p>Usage:</p> <pre><code>$ cuiman list-jobs [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-c, --config PATH</code>: Client configuration file.</li> <li><code>-f, --format [simple|json|yaml]</code>: Output format.  [default: yaml]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cuiman/cli/#cuiman-get-job","title":"<code>cuiman get-job</code>","text":"<p>Get job details.</p> <p>Usage:</p> <pre><code>$ cuiman get-job [OPTIONS] JOB_ID\n</code></pre> <p>Arguments:</p> <ul> <li><code>JOB_ID</code>: Job identifier.  [required]</li> </ul> <p>Options:</p> <ul> <li><code>-c, --config PATH</code>: Client configuration file.</li> <li><code>-f, --format [simple|json|yaml]</code>: Output format.  [default: yaml]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cuiman/cli/#cuiman-dismiss-job","title":"<code>cuiman dismiss-job</code>","text":"<p>Cancel a running or delete a finished job.</p> <p>Usage:</p> <pre><code>$ cuiman dismiss-job [OPTIONS] JOB_ID\n</code></pre> <p>Arguments:</p> <ul> <li><code>JOB_ID</code>: Job identifier.  [required]</li> </ul> <p>Options:</p> <ul> <li><code>-c, --config PATH</code>: Client configuration file.</li> <li><code>-f, --format [simple|json|yaml]</code>: Output format.  [default: yaml]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cuiman/cli/#cuiman-get-job-results","title":"<code>cuiman get-job-results</code>","text":"<p>Get job results.</p> <p>Usage:</p> <pre><code>$ cuiman get-job-results [OPTIONS] JOB_ID\n</code></pre> <p>Arguments:</p> <ul> <li><code>JOB_ID</code>: Job identifier.  [required]</li> </ul> <p>Options:</p> <ul> <li><code>-c, --config PATH</code>: Client configuration file.</li> <li><code>-f, --format [simple|json|yaml]</code>: Output format.  [default: yaml]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cuiman/configuration/","title":"Cuiman Configuration","text":"<p>The <code>cuiman</code> configuration settings may be passed in a couple of ways  to the Python API and CLI clients. The different ways also have different  precedence.</p>"},{"location":"cuiman/configuration/#passing-configuration","title":"Passing Configuration","text":"<p>In the following list of configuration methods, a setting of a subsequent  entry overrides that of a previous one.</p> <ol> <li>Default settings hard-coded into the <code>cuiman.ClientConfig</code> class.</li> <li>Settings loaded from a given or the default configuration file passed as <code>config_path</code>.</li> <li>Settings loaded from environment variables prefixed with <code>EOZILLA_</code>.</li> <li>Settings from another configuration object of type <code>cuiman.ClientConfig</code> passes as <code>config</code>.</li> <li>Settings from keyword arguments passed directly to the client passed as <code>config_kwargs</code>.</li> </ol> <p>This list is implemented in the class method <code>create()</code> of the  <code>cuiman.api.ClientConfig</code> class. </p> <p>Note that applications using <code>cuiman</code> under the hood may customize the  configuration, see Cuiman Customization. </p>"},{"location":"cuiman/configuration/#configuration-files","title":"Configuration Files","text":"<pre><code>from cuiman import Client\n\nclient = Client(config_path=\"./my-config.json\")\n</code></pre> <p>Configuration files have either YAML or JSON format.</p> <p>JSON:</p> <pre><code>{\n    \"api_url\": \"https://anolis.api.org/process-api/v1\", \n    \"auth_type\": \"token\",\n    \"token\": \"ab989e20-d58609a9-8d4c\",\n    \"use_bearer\": true\n}\n</code></pre> <p>YAML:</p> <pre><code>api_url: \"https://anolis.api.org/process-api/v1\" \nauth_type: token\ntoken: ab989e20-d58609a9-8d4c\nuse_bearer: true\n</code></pre>"},{"location":"cuiman/configuration/#environment-variables","title":"Environment Variables","text":"<p>All configuration parameters can be passed as environment variables using the uppercase parameter name prefixed by <code>EOZILLA_</code>.</p> <p>With</p> <pre><code>export EOZILLA_USERNAME=\"polly\"\nexport EOZILLA_PASSWORD= \"1234\"\n</code></pre> <p>set, you no longer need to pass <code>username</code> and <code>password</code>:</p> <pre><code>from cuiman import Client\n\nclient = Client(\n    api_url=\"https://anolis.api.org/process-api/v1\", \n    auth_type=\"basic\"\n)\n</code></pre>"},{"location":"cuiman/configuration/#configuration-object","title":"Configuration Object","text":"<pre><code>from cuiman import Client, ClientConfig\n\nconfig = ClientConfig(\n    api_url=\"https://anolis.api.org/process-api/v1\", \n    auth_type=\"basic\",\n    username=\"polly\",\n    password=\"1234\",\n)\n\nclient = Client(config=config)\n</code></pre>"},{"location":"cuiman/configuration/#keyword-arguments","title":"Keyword Arguments","text":"<p>Pass configuration settings as keyword arguments  directly to the client constructor:</p> <pre><code>from cuiman import Client\n\nclient = Client(\n    api_url=\"https://anolis.api.org/process-api/v1\", \n    auth_type=\"basic\",\n    username=\"polly\",\n    password=\"1234\",\n)\n</code></pre>"},{"location":"cuiman/configuration/#using-the-cli","title":"Using the CLI","text":"<p>Before using the CLI, you should configure it using the <code>cuiman configure</code> command. </p> <p>You can override settings anytime from environment variables or by using  the <code>--config/-c &lt;file&gt;</code> option supported by most CLI commands.</p>"},{"location":"cuiman/configuration/#basic-settings","title":"Basic Settings","text":"<p>The most important configuration setting is <code>api_url</code> which provides the  base URL to the OGC API - Processes.</p> <p>By default, <code>cuiman</code> assumes the service the API URL is pointing to  does not perform any authorisation on the incoming requests - which  is rarely the case. Therefore, the client need to be configured with  respect to some service-specific authorisation method.</p>"},{"location":"cuiman/configuration/#authentication-settings","title":"Authentication Settings","text":"<p>The <code>cuiman</code> package allows for a limited set of client authentication types. The authentication type is provided by the <code>auth_type</code> configuration setting.</p>"},{"location":"cuiman/configuration/#auth-type-none","title":"Auth type <code>none</code>","text":"<p>The authentication type <code>none</code> means, the server doesn't require any  client authentication. This is usually the case only for development  environments.</p> <pre><code>config = ClientConfig(api_url=\"...\", auth_type=\"none\")\n</code></pre>"},{"location":"cuiman/configuration/#auth-type-basic","title":"Auth type <code>basic</code>","text":"<p>Basic HTTP authentication is quite common for simple and older processing services.  It requires <code>username</code> and <code>password</code>.</p> <pre><code>config = ClientConfig(\n    api_url=\"...\", \n    auth_type=\"basic\", \n    username=\"...\", \n    password=\"...\",\n)\n</code></pre>"},{"location":"cuiman/configuration/#auth-type-token","title":"Auth type <code>token</code>","text":"<p>Authentication via API access tokens is widely used. <code>cuiman</code> supports bearer tokens (as used by OAuth 2.0) as well as custom headers.</p> <p>Note that <code>cuiman</code> currently only supports permanent access tokens. We have not yet implemented support for volatile access tokens, as used in the OAuth 2.0 Refresh Token Flow. </p> <pre><code>config = ClientConfig(\n    api_url=\"...\", \n    auth_type=\"token\", \n    use_bearer=True,\n)\n</code></pre> <p>With custom header:</p> <pre><code>config = ClientConfig(\n    api_url=\"...\", \n    auth_type=\"token\", \n    use_bearer=False, \n    token_header=\"X-Auth-Token\",  # Default\n)\n</code></pre>"},{"location":"cuiman/configuration/#auth-type-login","title":"Auth type <code>login</code>","text":"<p>The authorisation type <code>login</code> represents a standard enterprise scenario, where  an access token is fetched from a server given user credentials. This is the case for, e.g., the OAuth 2.0 Client Credentials.</p> <p>Note that <code>cuiman</code> currently only supports permanent access tokens. We have not yet implemented support for short-lived access tokens that need to be refreshed once in a while as is the case for the OAuth 2.0 Refresh Token Flow. </p> <p>The authorisation type <code>login</code> requires configuration of a authorisation URL that is used to obtain the access token:</p> <pre><code>config = ClientConfig(\n    api_url=\"...\", \n    auth_type=\"login\",\n    auth_url=\"...\",\n    username=\"...\", \n    password=\"...\",\n    # See auth_type \"token\" above\n    use_bearer=True,\n)\n</code></pre>"},{"location":"cuiman/configuration/#auth-type-api-key","title":"Auth type <code>api-key</code>","text":"<p>The authorisation via API keys is also very common in SaaS scenarios. A simple API key <code>api_key</code> must be given, which is usually passed by  a request header named <code>X-API-Key</code>:</p> <p>| API Key Header | <code>X-API-Key: abc123</code> | Very common in SaaS</p> <pre><code>config = ClientConfig(\n    api_url=\"...\", \n    auth_type=\"api-key\",\n    api_key=\"...\",\n    api_key_header=\"X-API-Key\",  # default\n)\n</code></pre>"},{"location":"cuiman/customization/","title":"Cuiman Customization","text":"<p>Applications can create their own clients using <code>cuiman</code> under the hood.  For this, an application can customize the <code>cuiman</code> configuration and its default values.</p> <p>This is best explained by an example. In the following we explain  the client customization by a hypothetic processing system \"Anolis\" that should get its own <code>anolis-client</code>.</p> <p>The <code>cuiman</code> API allows for the following customizations:</p> <ol> <li>The <code>cuiman.ClientConfig</code> is a     pydantic Settings    class. It can be used as base class and then configured with a custom     <code>pydantic_settings.SettingsConfigDict</code> instance.</li> <li>Some <code>cuiman.ClientConfig</code> class attributes in can be overridden       to initialize custom default values.</li> <li>Applications can create their own CLI instance with custom settings.</li> </ol>"},{"location":"cuiman/customization/#api-customisation","title":"API customisation","text":"<p>In a module <code>src/anolis_client/api.py</code>:</p> <pre><code>from pathlib import Path\nfrom pydantic_settings import SettingsConfigDict\nfrom cuiman.api import AsyncClient, Client, ClientConfig, ClientError\n\n# Custom configuration class\nclass AnolisClientConfig(ClientConfig):\n  model_config = SettingsConfigDict(\n      env_prefix=\"ANOLIS_\",\n      env_file=\".env\",\n      extra=\"allow\",  # base ClientConfig uses \"forbid\"\n  )\n\n# Custom configuration defaults\nClientConfig.default_path = Path(\"~\").expanduser() / \".anolis-client\"\nClientConfig.default_config = AnolisClientConfig(\n    api_url=\"https://anolis.api.org/process-api/v1\",\n    auth_url=\"https://anolis.api.org/auth/login\",\n    auth_type=\"login\",\n    use_bearer=True,\n)\n</code></pre>"},{"location":"cuiman/customization/#cli-customisation","title":"CLI customisation","text":"<p>In a module <code>src/anolis_client/cli.py</code>:</p> <pre><code>from importlib import import_module\nfrom cuiman.cli import new_cli\nfrom anolis_client import __version__ as version\n\n# Force pre-configuration of Anolis configuration\nimport_module(\"anolis_client.api\")\n\ncli = new_cli(\n    name=\"anolis-client\",\n    summary=\"Client for the Anolis processing service.\",\n    version=version,\n)\n\nif __name__ == \"__main__\":  # pragma: no cover\n    cli()\n</code></pre>"},{"location":"cuiman/introduction/","title":"Cuiman Overview","text":"<p>The Eozilla Cuiman tool provides a client for servers compliant with the  OGC API - Processes, Part 1.</p> <p>It comprises the following interfaces:</p> <ul> <li>Cuiman Python API</li> <li>Cuiman GUI</li> <li>Cuiman CLI</li> </ul>"},{"location":"hooks/notebooks_json_output/","title":"Notebooks json output","text":"In\u00a0[\u00a0]: Copied! <pre>import html\nimport json\nimport shutil\nfrom pathlib import Path\n</pre> import html import json import shutil from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import nbformat as nbf\n</pre> import nbformat as nbf In\u00a0[\u00a0]: Copied! <pre>def on_pre_build(config):\n    \"\"\"\n    Runs the updates once before the build of the documentation\n\n    References:\n    - mkdocs hooks: https://www.mkdocs.org/user-guide/configuration/?#hooks\n    - mkdocs events: https://www.mkdocs.org/dev-guide/plugins/#on_pre_build\n\n    Args:\n     - config: global MkDocsConfig Object\n    \"\"\"\n    source = Path.cwd() / \"notebooks\"\n    destination = Path.cwd() / \"docs/notebooks\"\n\n    _update_files_in_docs(source, destination)\n    print(f\"[hooks] Updated notebooks: {source} to {destination}\")\n\n    for ipynb in destination.rglob(\"*.ipynb\"):\n        if _patch_notebook(ipynb):\n            print(f\"[hooks] Patched: {ipynb}\")\n</pre> def on_pre_build(config):     \"\"\"     Runs the updates once before the build of the documentation      References:     - mkdocs hooks: https://www.mkdocs.org/user-guide/configuration/?#hooks     - mkdocs events: https://www.mkdocs.org/dev-guide/plugins/#on_pre_build      Args:      - config: global MkDocsConfig Object     \"\"\"     source = Path.cwd() / \"notebooks\"     destination = Path.cwd() / \"docs/notebooks\"      _update_files_in_docs(source, destination)     print(f\"[hooks] Updated notebooks: {source} to {destination}\")      for ipynb in destination.rglob(\"*.ipynb\"):         if _patch_notebook(ipynb):             print(f\"[hooks] Patched: {ipynb}\") In\u00a0[\u00a0]: Copied! <pre>def _patch_notebook(path: Path):\n    \"\"\"\n    Changes the output type of Jupyter notebook cells from\n    `json/application` to `text/html` to make the output readable\n    in mkdocs documentation\n\n    Args:\n        - path: Path to notebooks in docs/\n\n    Returns:\n        - boolean indicator to report if notebook patching was done\n    \"\"\"\n    nb = nbf.read(path, as_version=4)\n    changed = False\n    for cell in nb.cells:\n        for out in cell.get(\"outputs\", []):\n            data = out.get(\"data\", {})\n            if isinstance(data, dict) and \"application/json\" in data:\n                pretty = html.escape(json.dumps(data[\"application/json\"],\n                                                indent=2,\n                                                ensure_ascii=False))\n                data[\"text/html\"] = f\"&lt;pre&gt;&lt;code class='text-json'&gt;{pretty}&lt;/code&gt;&lt;/pre&gt;\"\n                changed = True\n    if changed:\n        nbf.write(nb, path)\n    return changed\n</pre> def _patch_notebook(path: Path):     \"\"\"     Changes the output type of Jupyter notebook cells from     `json/application` to `text/html` to make the output readable     in mkdocs documentation      Args:         - path: Path to notebooks in docs/      Returns:         - boolean indicator to report if notebook patching was done     \"\"\"     nb = nbf.read(path, as_version=4)     changed = False     for cell in nb.cells:         for out in cell.get(\"outputs\", []):             data = out.get(\"data\", {})             if isinstance(data, dict) and \"application/json\" in data:                 pretty = html.escape(json.dumps(data[\"application/json\"],                                                 indent=2,                                                 ensure_ascii=False))                 data[\"text/html\"] = f\"<pre><code>{pretty}</code></pre>\"                 changed = True     if changed:         nbf.write(nb, path)     return changed In\u00a0[\u00a0]: Copied! <pre>def _update_files_in_docs(source: Path, destination: Path):\n    \"\"\"\n    Adds notebooks to docs/notebooks\n\n    Args:\n        - source: Path to original notebooks\n        - destination: Path to copy original notebooks to prepare for and add to\n        mkdocs documentation\n    \"\"\"\n    shutil.copytree(source, destination, dirs_exist_ok=True)\n</pre> def _update_files_in_docs(source: Path, destination: Path):     \"\"\"     Adds notebooks to docs/notebooks      Args:         - source: Path to original notebooks         - destination: Path to copy original notebooks to prepare for and add to         mkdocs documentation     \"\"\"     shutil.copytree(source, destination, dirs_exist_ok=True)"},{"location":"notebooks/","title":"Index","text":"<p>Into this folder the notebooks from eozilla/notebooks will be copied for the generation of the documentation. This happens on each build with the help of the mkdocs hook <code>docs/hooks/notebooks_json_output.py</code>.</p>"},{"location":"notebooks/cuiman-api-airflow/","title":"Airflow","text":"In\u00a0[1]: Copied! <pre>from cuiman import Client\nfrom gavicore.models import ProcessRequest\n</pre> from cuiman import Client from gavicore.models import ProcessRequest In\u00a0[3]: Copied! <pre>client = Client()\nclient\n</pre> client = Client() client Out[3]: <pre><code>{\n  \"api_key\": null,\n  \"api_key_header\": \"X-API-Key\",\n  \"api_url\": \"http://127.0.0.1:8008/\",\n  \"auth_type\": \"none\",\n  \"auth_url\": null,\n  \"password\": null,\n  \"token\": null,\n  \"token_header\": \"X-Auth-Token\",\n  \"use_bearer\": false,\n  \"username\": null\n}</code></pre> In\u00a0[4]: Copied! <pre>client.get_capabilities()\n</pre> client.get_capabilities() Out[4]: <pre><code>{\n  \"description\": \"Local test server implementing the OGC API - Processes 1.0 Standard\",\n  \"links\": [\n    {\n      \"href\": \"http://127.0.0.1:8008/\",\n      \"hreflang\": \"en\",\n      \"rel\": \"self\",\n      \"title\": \"get_capabilities\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/openapi.json\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"openapi\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/docs\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"swagger_ui_html\",\n      \"type\": \"text/html\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/docs/oauth2-redirect\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"swagger_ui_redirect\",\n      \"type\": \"text/html\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/redoc\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"redoc_html\",\n      \"type\": \"text/html\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_capabilities\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/conformance\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_conformance\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/processes\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_processes\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/processes/{processID}\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_process\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/processes/{processID}/execution\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"execute_process\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_jobs\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs/{jobId}\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_job\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs/{jobId}\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"dismiss_job\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs/{jobId}/results\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_job_results\",\n      \"type\": \"application/json\"\n    }\n  ],\n  \"title\": \"Eozilla API Server (local dummy for testing)\"\n}</code></pre> In\u00a0[5]: Copied! <pre>client.get_conformance()\n</pre> client.get_conformance() Out[5]: <pre><code>{\n  \"conformsTo\": [\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/core\",\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/ogc-process-description\",\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/json\",\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/oas30\",\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/job-list\",\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/dismiss\"\n  ]\n}</code></pre> In\u00a0[6]: Copied! <pre>client.get_processes()\n</pre> client.get_processes() Out[6]: <pre><code>{\n  \"links\": [\n    {\n      \"href\": \"http://127.0.0.1:8008/processes\",\n      \"hreflang\": \"en\",\n      \"rel\": \"self\",\n      \"title\": \"get_processes\",\n      \"type\": \"application/json\"\n    }\n  ],\n  \"processes\": [\n    {\n      \"description\": \"Sleeps for `duration` seconds. Fails on purpose if `fail` is `True`. Returns the effective amount of sleep in seconds.\",\n      \"id\": \"sleep_a_while\",\n      \"title\": \"Sleep Processor\",\n      \"version\": \"0.0.0\"\n    },\n    {\n      \"description\": \"Returns the list of prime numbers between a `min_val` and `max_val`.\",\n      \"id\": \"primes_between\",\n      \"title\": \"Prime Processor\",\n      \"version\": \"0.0.0\"\n    },\n    {\n      \"description\": \"Simulate a set scene images slices for testing. Creates an xarray dataset with `periodicity` time slices and writes it as Zarr into a temporary location. Requires installed `dask`, `xarray`, and `zarr` packages.\",\n      \"id\": \"simulate_scene\",\n      \"title\": \"Generate scene for testing\",\n      \"version\": \"0.0.0\"\n    },\n    {\n      \"id\": \"return_base_model\",\n      \"title\": \"BaseModel Test\",\n      \"version\": \"0.0.0\"\n    },\n    {\n      \"description\": \"This workflow currently just tests the execution orchestration of steps defined in it.\",\n      \"id\": \"test_workflow\",\n      \"version\": \"0.0.0\"\n    }\n  ]\n}</code></pre> In\u00a0[7]: Copied! <pre>client.get_process(process_id=\"sleep_a_while\")\n</pre> client.get_process(process_id=\"sleep_a_while\") Out[7]: <pre><code>{\n  \"description\": \"Sleeps for `duration` seconds. Fails on purpose if `fail` is `True`. Returns the effective amount of sleep in seconds.\",\n  \"id\": \"sleep_a_while\",\n  \"inputs\": {\n    \"duration\": {\n      \"minOccurs\": 0,\n      \"schema\": {\n        \"default\": 10,\n        \"type\": \"number\"\n      },\n      \"title\": \"Duration\"\n    },\n    \"fail\": {\n      \"minOccurs\": 0,\n      \"schema\": {\n        \"default\": false,\n        \"type\": \"boolean\"\n      },\n      \"title\": \"Fail\"\n    }\n  },\n  \"outputs\": {\n    \"return_value\": {\n      \"schema\": {\n        \"type\": \"number\"\n      },\n      \"title\": \"Return Value\"\n    }\n  },\n  \"title\": \"Sleep Processor\",\n  \"version\": \"0.0.0\"\n}</code></pre> In\u00a0[11]: Copied! <pre>client.get_process(process_id=\"test_workflow\")\n</pre> client.get_process(process_id=\"test_workflow\") Out[11]: <pre><code>{\n  \"description\": \"This workflow currently just tests the execution orchestration of steps defined in it.\",\n  \"id\": \"test_workflow\",\n  \"inputs\": {\n    \"id\": {\n      \"minOccurs\": 0,\n      \"schema\": {\n        \"default\": \"hithere\",\n        \"type\": \"string\"\n      },\n      \"title\": \"main input\"\n    },\n    \"id2\": {\n      \"minOccurs\": 0,\n      \"schema\": {\n        \"default\": \"watchadoing\",\n        \"type\": \"string\"\n      },\n      \"title\": \"inbput for fifth step\"\n    }\n  },\n  \"outputs\": {\n    \"final\": {\n      \"schema\": {\n        \"type\": \"string\"\n      },\n      \"title\": \"Final output\"\n    }\n  },\n  \"version\": \"0.0.0\"\n}</code></pre> In\u00a0[12]: Copied! <pre>client.get_jobs()\n</pre> client.get_jobs() Out[12]: <pre><code>{\n  \"jobs\": [],\n  \"links\": [\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs\",\n      \"hreflang\": \"en\",\n      \"rel\": \"self\",\n      \"title\": \"get_jobs\",\n      \"type\": \"application/json\"\n    }\n  ]\n}</code></pre> In\u00a0[13]: Copied! <pre>client.execute_process(process_id=\"primes_between\", request=ProcessRequest())\n</pre> client.execute_process(process_id=\"primes_between\", request=ProcessRequest()) Out[13]: <pre><code>{\n  \"created\": \"2026-01-16T16:24:55.904198Z\",\n  \"finished\": \"2026-01-16T16:24:55.904769Z\",\n  \"jobID\": \"job_0\",\n  \"message\": \"Done\",\n  \"processID\": \"primes_between\",\n  \"started\": \"2026-01-16T16:24:55.904421Z\",\n  \"status\": \"successful\",\n  \"type\": \"process\",\n  \"updated\": \"2026-01-16T16:24:55.904749Z\"\n}</code></pre> In\u00a0[14]: Copied! <pre>client.execute_process(process_id=\"test_workflow\", request=ProcessRequest(inputs={\"id\": \"eozilla-is-amazing\"}))\n</pre> client.execute_process(process_id=\"test_workflow\", request=ProcessRequest(inputs={\"id\": \"eozilla-is-amazing\"})) Out[14]: <pre><code>{\n  \"created\": \"2026-01-16T16:24:57.856501Z\",\n  \"jobID\": \"job_1\",\n  \"processID\": \"test_workflow\",\n  \"status\": \"accepted\",\n  \"type\": \"process\"\n}</code></pre> In\u00a0[15]: Copied! <pre>client.execute_process(process_id=\"sleep_a_while\", request=ProcessRequest())\n</pre> client.execute_process(process_id=\"sleep_a_while\", request=ProcessRequest()) Out[15]: <pre><code>{\n  \"created\": \"2026-01-16T16:24:58.660290Z\",\n  \"jobID\": \"job_2\",\n  \"processID\": \"sleep_a_while\",\n  \"status\": \"accepted\",\n  \"type\": \"process\"\n}</code></pre> In\u00a0[16]: Copied! <pre>client.get_jobs()\n</pre> client.get_jobs() Out[16]: <pre><code>{\n  \"jobs\": [\n    {\n      \"created\": \"2026-01-16T16:24:55.904198Z\",\n      \"finished\": \"2026-01-16T16:24:55.904769Z\",\n      \"jobID\": \"job_0\",\n      \"message\": \"Done\",\n      \"processID\": \"primes_between\",\n      \"started\": \"2026-01-16T16:24:55.904421Z\",\n      \"status\": \"successful\",\n      \"type\": \"process\",\n      \"updated\": \"2026-01-16T16:24:55.904749Z\"\n    },\n    {\n      \"created\": \"2026-01-16T16:24:57.856501Z\",\n      \"finished\": \"2026-01-16T16:24:57.857276Z\",\n      \"jobID\": \"job_1\",\n      \"processID\": \"test_workflow\",\n      \"started\": \"2026-01-16T16:24:57.856873Z\",\n      \"status\": \"successful\",\n      \"type\": \"process\"\n    },\n    {\n      \"created\": \"2026-01-16T16:24:58.660290Z\",\n      \"jobID\": \"job_2\",\n      \"processID\": \"sleep_a_while\",\n      \"progress\": 15,\n      \"started\": \"2026-01-16T16:24:58.660735Z\",\n      \"status\": \"running\",\n      \"type\": \"process\",\n      \"updated\": \"2026-01-16T16:25:00.162586Z\"\n    }\n  ],\n  \"links\": [\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs\",\n      \"hreflang\": \"en\",\n      \"rel\": \"self\",\n      \"title\": \"get_jobs\",\n      \"type\": \"application/json\"\n    }\n  ]\n}</code></pre> In\u00a0[17]: Copied! <pre>client.get_job_results(\"job_0\")\n</pre> client.get_job_results(\"job_0\") Out[17]: <pre><code>{\n  \"return_value\": [\n    2,\n    3,\n    5,\n    7,\n    11,\n    13,\n    17,\n    19,\n    23,\n    29,\n    31,\n    37,\n    41,\n    43,\n    47,\n    53,\n    59,\n    61,\n    67,\n    71,\n    73,\n    79,\n    83,\n    89,\n    97\n  ]\n}</code></pre> In\u00a0[18]: Copied! <pre>client.get_job_results(\"job_1\")\n</pre> client.get_job_results(\"job_1\") Out[18]: <pre><code>{\n  \"final\": \"eozilla-is-amazingeozilla-is-amazing\"\n}</code></pre> In\u00a0[19]: Copied! <pre>client.get_job_results(\"job_2\")\n</pre> client.get_job_results(\"job_2\") Out[19]: <pre><code>{\n  \"return_value\": 10.110539436340332\n}</code></pre> In\u00a0[21]: Copied! <pre>for job in client.get_jobs().jobs:\n    client.dismiss_job(job.jobID)\n</pre> for job in client.get_jobs().jobs:     client.dismiss_job(job.jobID)"},{"location":"notebooks/cuiman-api-airflow/#airflow","title":"Airflow\u00b6","text":"<p>This section demonstrates the use of Apache Airflow as backend.</p> <p>Start by running a local Airflow instance with some generated test DAGs:</p> <pre><code>commandline\ncd eozilla-airflow\npixi install\npixi run airflow standalone\n</code></pre> <p>Then run the wraptile gateway server with the local Airflow instance (assuming the local Airflow webserver runs on http://localhost:8080):</p> <pre><code>commandline\npixi shell\nwraptile run -- wraptile.services.airflow:service --airflow-password=a8e7f4bb230\n</code></pre> <p>Get the airflow user password from <code>eozilla-airflow/.airflow/simple_auth_manager_passwords.json.generated</code>.</p>"},{"location":"notebooks/cuiman-api/","title":"Cuiman Python API usage","text":"In\u00a0[1]: Copied! <pre>from cuiman import Client\nfrom gavicore.models import ProcessRequest\n</pre> from cuiman import Client from gavicore.models import ProcessRequest In\u00a0[2]: Copied! <pre>client = Client()\nclient\n</pre> client = Client() client Out[2]: <pre><code>{\n  \"api_key\": null,\n  \"api_key_header\": \"X-API-Key\",\n  \"api_url\": \"http://127.0.0.1:8008/\",\n  \"auth_type\": \"basic\",\n  \"auth_url\": null,\n  \"password\": \"gfds\",\n  \"token\": null,\n  \"token_header\": \"X-Auth-Token\",\n  \"use_bearer\": false,\n  \"username\": \"Norman\"\n}</code></pre> In\u00a0[3]: Copied! <pre>client.get_capabilities()\n</pre> client.get_capabilities() Out[3]: <pre><code>{\n  \"description\": \"Local test server implementing the OGC API - Processes 1.0 Standard\",\n  \"links\": [\n    {\n      \"href\": \"http://127.0.0.1:8008/\",\n      \"hreflang\": \"en\",\n      \"rel\": \"self\",\n      \"title\": \"get_capabilities\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/openapi.json\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"openapi\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/docs\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"swagger_ui_html\",\n      \"type\": \"text/html\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/docs/oauth2-redirect\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"swagger_ui_redirect\",\n      \"type\": \"text/html\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/redoc\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"redoc_html\",\n      \"type\": \"text/html\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_capabilities\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/conformance\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_conformance\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/processes\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_processes\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/processes/{processID}\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_process\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/processes/{processID}/execution\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"execute_process\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_jobs\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs/{jobId}\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_job\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs/{jobId}\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"dismiss_job\",\n      \"type\": \"application/json\"\n    },\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs/{jobId}/results\",\n      \"hreflang\": \"en\",\n      \"rel\": \"service\",\n      \"title\": \"get_job_results\",\n      \"type\": \"application/json\"\n    }\n  ],\n  \"title\": \"Eozilla API Server (local dummy for testing)\"\n}</code></pre> In\u00a0[4]: Copied! <pre>client.get_conformance()\n</pre> client.get_conformance() Out[4]: <pre><code>{\n  \"conformsTo\": [\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/core\",\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/ogc-process-description\",\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/json\",\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/oas30\",\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/job-list\",\n    \"http://www.opengis.net/spec/ogcapi-processes-1/1.0/conf/dismiss\"\n  ]\n}</code></pre> In\u00a0[5]: Copied! <pre>client.get_processes()\n</pre> client.get_processes() Out[5]: <pre><code>{\n  \"links\": [\n    {\n      \"href\": \"http://127.0.0.1:8008/processes\",\n      \"hreflang\": \"en\",\n      \"rel\": \"self\",\n      \"title\": \"get_processes\",\n      \"type\": \"application/json\"\n    }\n  ],\n  \"processes\": [\n    {\n      \"description\": \"Sleeps for `duration` seconds. Fails on purpose if `fail` is `True`. Returns the effective amount of sleep in seconds.\",\n      \"id\": \"sleep_a_while\",\n      \"title\": \"Sleep Processor\",\n      \"version\": \"0.0.0\"\n    },\n    {\n      \"description\": \"Returns the list of prime numbers between a `min_val` and `max_val`.\",\n      \"id\": \"primes_between\",\n      \"title\": \"Prime Processor\",\n      \"version\": \"0.0.0\"\n    },\n    {\n      \"description\": \"Simulate a set scene images slices for testing. Creates an xarray dataset with `periodicity` time slices and writes it as Zarr into a temporary location. Requires installed `dask`, `xarray`, and `zarr` packages.\",\n      \"id\": \"simulate_scene\",\n      \"title\": \"Generate scene for testing\",\n      \"version\": \"0.0.0\"\n    },\n    {\n      \"id\": \"return_base_model\",\n      \"title\": \"BaseModel Test\",\n      \"version\": \"0.0.0\"\n    },\n    {\n      \"description\": \"This is a workflow with several steps and defined dependencies that execute sequentially.\",\n      \"id\": \"process_pipeline\",\n      \"title\": \"A Big Workflow\",\n      \"version\": \"0.0.0\"\n    }\n  ]\n}</code></pre> In\u00a0[6]: Copied! <pre>client.get_process(process_id=\"sleep_a_while\")\n</pre> client.get_process(process_id=\"sleep_a_while\") Out[6]: <pre><code>{\n  \"description\": \"Sleeps for `duration` seconds. Fails on purpose if `fail` is `True`. Returns the effective amount of sleep in seconds.\",\n  \"id\": \"sleep_a_while\",\n  \"inputs\": {\n    \"duration\": {\n      \"minOccurs\": 0,\n      \"schema\": {\n        \"default\": 10,\n        \"type\": \"number\"\n      },\n      \"title\": \"Duration\"\n    },\n    \"fail\": {\n      \"minOccurs\": 0,\n      \"schema\": {\n        \"default\": false,\n        \"type\": \"boolean\"\n      },\n      \"title\": \"Fail\"\n    }\n  },\n  \"outputs\": {\n    \"return_value\": {\n      \"schema\": {\n        \"type\": \"number\"\n      },\n      \"title\": \"Return Value\"\n    }\n  },\n  \"title\": \"Sleep Processor\",\n  \"version\": \"0.0.0\"\n}</code></pre> In\u00a0[7]: Copied! <pre>client.get_jobs()\n</pre> client.get_jobs() Out[7]: <pre><code>{\n  \"jobs\": [],\n  \"links\": [\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs\",\n      \"hreflang\": \"en\",\n      \"rel\": \"self\",\n      \"title\": \"get_jobs\",\n      \"type\": \"application/json\"\n    }\n  ]\n}</code></pre> In\u00a0[8]: Copied! <pre>client.execute_process(process_id=\"sleep_a_while\", request=ProcessRequest(inputs={\"duration\":2}))\n</pre> client.execute_process(process_id=\"sleep_a_while\", request=ProcessRequest(inputs={\"duration\":2})) Out[8]: <pre><code>{\n  \"created\": \"2026-02-12T16:13:30.682487Z\",\n  \"jobID\": \"job_0\",\n  \"processID\": \"sleep_a_while\",\n  \"progress\": 0,\n  \"started\": \"2026-02-12T16:13:30.683002Z\",\n  \"status\": \"running\",\n  \"type\": \"process\",\n  \"updated\": \"2026-02-12T16:13:30.683152Z\"\n}</code></pre> In\u00a0[9]: Copied! <pre>client.execute_process(process_id=\"sleep_a_while\", request=ProcessRequest(inputs={\"fail\": True}))\n</pre> client.execute_process(process_id=\"sleep_a_while\", request=ProcessRequest(inputs={\"fail\": True})) Out[9]: <pre><code>{\n  \"created\": \"2026-02-12T16:13:30.693029Z\",\n  \"jobID\": \"job_1\",\n  \"processID\": \"sleep_a_while\",\n  \"progress\": 0,\n  \"started\": \"2026-02-12T16:13:30.693375Z\",\n  \"status\": \"running\",\n  \"type\": \"process\",\n  \"updated\": \"2026-02-12T16:13:30.693446Z\"\n}</code></pre> In\u00a0[10]: Copied! <pre>client.execute_process(process_id=\"primes_between\", request={})\n</pre> client.execute_process(process_id=\"primes_between\", request={}) Out[10]: <pre><code>{\n  \"created\": \"2026-02-12T16:13:30.702482Z\",\n  \"finished\": \"2026-02-12T16:13:30.703101Z\",\n  \"jobID\": \"job_2\",\n  \"message\": \"Done\",\n  \"processID\": \"primes_between\",\n  \"started\": \"2026-02-12T16:13:30.702895Z\",\n  \"status\": \"successful\",\n  \"type\": \"process\",\n  \"updated\": \"2026-02-12T16:13:30.703050Z\"\n}</code></pre> In\u00a0[11]: Copied! <pre>client.get_process(process_id=\"process_pipeline\")\n</pre> client.get_process(process_id=\"process_pipeline\") Out[11]: <pre><code>{\n  \"description\": \"This is a workflow with several steps and defined dependencies that execute sequentially.\",\n  \"id\": \"process_pipeline\",\n  \"inputs\": {\n    \"id\": {\n      \"schema\": {\n        \"type\": \"string\"\n      },\n      \"title\": \"main input\"\n    }\n  },\n  \"outputs\": {\n    \"final\": {\n      \"schema\": {\n        \"items\": {\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"maxItems\": 2,\n          \"minItems\": 2,\n          \"type\": \"array\"\n        },\n        \"maxItems\": 2,\n        \"minItems\": 2,\n        \"type\": \"array\"\n      },\n      \"title\": \"Final output\"\n    }\n  },\n  \"title\": \"A Big Workflow\",\n  \"version\": \"0.0.0\"\n}</code></pre> In\u00a0[12]: Copied! <pre>client.execute_process(process_id=\"process_pipeline\", request=ProcessRequest(inputs={\"id\": \"eozilla-is-wow\"}))\n</pre> client.execute_process(process_id=\"process_pipeline\", request=ProcessRequest(inputs={\"id\": \"eozilla-is-wow\"})) Out[12]: <pre><code>{\n  \"created\": \"2026-02-12T16:13:30.722516Z\",\n  \"jobID\": \"job_3\",\n  \"processID\": \"process_pipeline\",\n  \"status\": \"accepted\",\n  \"type\": \"process\"\n}</code></pre> In\u00a0[13]: Copied! <pre>client.get_jobs()\n</pre> client.get_jobs() Out[13]: <pre><code>{\n  \"jobs\": [\n    {\n      \"created\": \"2026-02-12T16:13:30.682487Z\",\n      \"jobID\": \"job_0\",\n      \"processID\": \"sleep_a_while\",\n      \"progress\": 2,\n      \"started\": \"2026-02-12T16:13:30.683002Z\",\n      \"status\": \"running\",\n      \"type\": \"process\",\n      \"updated\": \"2026-02-12T16:13:30.724402Z\"\n    },\n    {\n      \"created\": \"2026-02-12T16:13:30.693029Z\",\n      \"jobID\": \"job_1\",\n      \"processID\": \"sleep_a_while\",\n      \"progress\": 0,\n      \"started\": \"2026-02-12T16:13:30.693375Z\",\n      \"status\": \"running\",\n      \"type\": \"process\",\n      \"updated\": \"2026-02-12T16:13:30.693446Z\"\n    },\n    {\n      \"created\": \"2026-02-12T16:13:30.702482Z\",\n      \"finished\": \"2026-02-12T16:13:30.703101Z\",\n      \"jobID\": \"job_2\",\n      \"message\": \"Done\",\n      \"processID\": \"primes_between\",\n      \"started\": \"2026-02-12T16:13:30.702895Z\",\n      \"status\": \"successful\",\n      \"type\": \"process\",\n      \"updated\": \"2026-02-12T16:13:30.703050Z\"\n    },\n    {\n      \"created\": \"2026-02-12T16:13:30.722516Z\",\n      \"finished\": \"2026-02-12T16:13:30.723774Z\",\n      \"jobID\": \"job_3\",\n      \"processID\": \"process_pipeline\",\n      \"started\": \"2026-02-12T16:13:30.722979Z\",\n      \"status\": \"successful\",\n      \"type\": \"process\"\n    }\n  ],\n  \"links\": [\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs\",\n      \"hreflang\": \"en\",\n      \"rel\": \"self\",\n      \"title\": \"get_jobs\",\n      \"type\": \"application/json\"\n    }\n  ]\n}</code></pre> In\u00a0[14]: Copied! <pre>client.get_job(\"job_1\")\n</pre> client.get_job(\"job_1\") Out[14]: <pre><code>{\n  \"created\": \"2026-02-12T16:13:30.693029Z\",\n  \"jobID\": \"job_1\",\n  \"processID\": \"sleep_a_while\",\n  \"progress\": 0,\n  \"started\": \"2026-02-12T16:13:30.693375Z\",\n  \"status\": \"running\",\n  \"type\": \"process\",\n  \"updated\": \"2026-02-12T16:13:30.693446Z\"\n}</code></pre> In\u00a0[15]: Copied! <pre>client.get_job_results(\"job_3\")\n</pre> client.get_job_results(\"job_3\") Out[15]: <pre><code>{\n  \"final\": [\n    [\n      \"eozilla-is-wow_read_preprocessed_feature_mean\",\n      \"resampled_from=eozilla-is-wow\"\n    ],\n    \"eozilla-is-wow_read_preprocessed_feature_mean\"\n  ]\n}</code></pre> In\u00a0[16]: Copied! <pre>client.get_job_results(\"job_2\")\n</pre> client.get_job_results(\"job_2\") Out[16]: <pre><code>{\n  \"return_value\": [\n    2,\n    3,\n    5,\n    7,\n    11,\n    13,\n    17,\n    19,\n    23,\n    29,\n    31,\n    37,\n    41,\n    43,\n    47,\n    53,\n    59,\n    61,\n    67,\n    71,\n    73,\n    79,\n    83,\n    89,\n    97\n  ]\n}</code></pre> In\u00a0[17]: Copied! <pre>for job in client.get_jobs().jobs:\n    client.dismiss_job(job.jobID)\n</pre> for job in client.get_jobs().jobs:     client.dismiss_job(job.jobID) In\u00a0[18]: Copied! <pre>client.get_jobs()\n</pre> client.get_jobs() Out[18]: <pre><code>{\n  \"jobs\": [\n    {\n      \"created\": \"2026-02-12T16:13:30.682487Z\",\n      \"jobID\": \"job_0\",\n      \"processID\": \"sleep_a_while\",\n      \"progress\": 4,\n      \"started\": \"2026-02-12T16:13:30.683002Z\",\n      \"status\": \"running\",\n      \"type\": \"process\",\n      \"updated\": \"2026-02-12T16:13:30.765438Z\"\n    },\n    {\n      \"created\": \"2026-02-12T16:13:30.693029Z\",\n      \"jobID\": \"job_1\",\n      \"processID\": \"sleep_a_while\",\n      \"progress\": 0,\n      \"started\": \"2026-02-12T16:13:30.693375Z\",\n      \"status\": \"running\",\n      \"type\": \"process\",\n      \"updated\": \"2026-02-12T16:13:30.693446Z\"\n    }\n  ],\n  \"links\": [\n    {\n      \"href\": \"http://127.0.0.1:8008/jobs\",\n      \"hreflang\": \"en\",\n      \"rel\": \"self\",\n      \"title\": \"get_jobs\",\n      \"type\": \"application/json\"\n    }\n  ]\n}</code></pre>"},{"location":"notebooks/cuiman-api/#cuiman-python-api-usage","title":"Cuiman Python API usage\u00b6","text":"<p>The Cuiman Python API client allows for</p> <ul> <li><code>client.get_processes()</code>: listing existing processes,</li> <li><code>client.get_process()</code>: get the details about a process,</li> <li><code>client.execute_process()</code>: executing a given process execution request,</li> <li><code>client.get_jobs()</code>: observing the jobs resulting from a process execution,</li> <li><code>client.get_job()</code>: getting a job's details,</li> <li><code>client.get_job_result()</code>: getting a job's result, and finally</li> <li><code>client.dismiss_job()</code>: cancelling a job.</li> </ul> <p>In the following, we visit all the features by example.</p> <p>The client expects a running server that conforms to the OGC API - Process: Part 1, Version 1.0. If you don't have one available, you can also run the project's server with a test configuration:</p> <pre>wraptile run -- wraptile.services.local.testing:service\n</pre>"},{"location":"notebooks/cuiman-cli/","title":"Cuiman CLI usage","text":"In\u00a0[1]: Copied! <pre> !cuiman --help\n</pre>  !cuiman --help <pre>                                                                               \n Usage: cuiman [OPTIONS] COMMAND [ARGS]...                                     \n                                                                               \n The `cuiman` tool is a shell client for any web services  compliant with OGC  \n API - Processes, Part 1: Core Standard.                                       \n                                                                               \n `cuiman` can be used to get the available processes, get process              \n details, execute processes, and manage the jobs originating from the latter.  \n It                                                                            \n herewith resembles the core functionality of the OGC API - Processes, Part 1. \n For details see https://ogcapi.ogc.org/processes/.                            \n                                                                               \n You can use shorter command name aliases, e.g., use command name `vr`         \n for `validate-request`, or `lp` for `list-processes`.                         \n                                                                               \n The tool's exit codes are as follows:                                         \n                                                                               \n * `0` - normal exit                                                           \n * `1` - user errors, argument errors                                          \n * `2` - remote API errors                                                     \n * `3` - local network transport errors                                        \n                                                                               \n If the `--traceback` flag is set, the original Python exception traceback     \n will be shown and the exit code will always be `1`.                           \n Otherwise, only the error message is shown.                                   \n                                                                               \n+- Options -------------------------------------------------------------------+\n| --version                     Show version and exit.                        |\n| --traceback,--tb              Show server exception traceback, if any.      |\n| --install-completion          Install completion for the current shell.     |\n| --show-completion             Show completion for the current shell, to     |\n|                               copy it or customize the installation.        |\n| --help                        Show this message and exit.                   |\n+-----------------------------------------------------------------------------+\n+- Commands ------------------------------------------------------------------+\n| configure          Configure the client tool.                               |\n| list-processes     List available processes.                                |\n| get-process        Get process details.                                     |\n| create-request     Create an execution request (template) for a given       |\n|                    process.                                                 |\n| validate-request   Validate a process execution request.                    |\n| execute-process    Execute a process in asynchronous mode.                  |\n| list-jobs          List all jobs.                                           |\n| get-job            Get job details.                                         |\n| dismiss-job        Cancel a running or delete a finished job.               |\n| get-job-results    Get job results.                                         |\n+-----------------------------------------------------------------------------+\n\n</pre> In\u00a0[2]: Copied! <pre> !cuiman configure --api-url http://127.0.0.1:8008 -a none\n</pre>  !cuiman configure --api-url http://127.0.0.1:8008 -a none <pre>Client configuration written to C:\\Users\\Norman\\.eozilla\\config\n</pre> In\u00a0[3]: Copied! <pre>!cuiman list-processes\n</pre> !cuiman list-processes <pre>links:\n- href: http://127.0.0.1:8008/processes\n  hreflang: en\n  rel: self\n  title: get_processes\n  type: application/json\nprocesses:\n- description: Sleeps for `duration` seconds. Fails on purpose if `fail` is `True`.\n    Returns the effective amount of sleep in seconds.\n  id: sleep_a_while\n  title: Sleep Processor\n  version: 0.0.0\n- description: Returns the list of prime numbers between a `min_val` and `max_val`.\n  id: primes_between\n  title: Prime Processor\n  version: 0.0.0\n- description: Simulate a set scene images slices for testing. Creates an xarray dataset\n    with `periodicity` time slices and writes it as Zarr into a temporary location.\n    Requires installed `dask`, `xarray`, and `zarr` packages.\n  id: simulate_scene\n  title: Generate scene for testing\n  version: 0.0.0\n- id: return_base_model\n  title: BaseModel Test\n  version: 0.0.0\n- description: This is a workflow with several steps and defined dependencies that\n    execute sequentially.\n  id: process_pipeline\n  title: A Big Workflow\n  version: 0.0.0\n\n</pre> In\u00a0[4]: Copied! <pre>!cuiman get-process primes_between\n</pre> !cuiman get-process primes_between <pre>description: Returns the list of prime numbers between a `min_val` and `max_val`.\nid: primes_between\ninputs:\n  max_val:\n    minOccurs: 0\n    schema:\n      default: 100\n      maximum: 100.0\n      type: integer\n    title: Max Val\n  min_val:\n    minOccurs: 0\n    schema:\n      default: 0\n      minimum: 0.0\n      type: integer\n    title: Min Val\noutputs:\n  return_value:\n    schema:\n      items:\n        type: integer\n      type: array\n    title: Return Value\ntitle: Prime Processor\nversion: 0.0.0\n\n</pre> In\u00a0[5]: Copied! <pre>!cuiman get-process process_pipeline\n</pre> !cuiman get-process process_pipeline <pre>description: This is a workflow with several steps and defined dependencies that execute\n  sequentially.\nid: process_pipeline\ninputs:\n  id:\n    schema:\n      type: string\n    title: main input\noutputs:\n  final:\n    schema:\n      items:\n        items:\n          type: string\n        maxItems: 2\n        minItems: 2\n        type: array\n      maxItems: 2\n      minItems: 2\n      type: array\n    title: Final output\ntitle: A Big Workflow\nversion: 0.0.0\n\n</pre> In\u00a0[6]: Copied! <pre>!cuiman execute-process primes_between -i min_val=10 -i max_val=80\n</pre> !cuiman execute-process primes_between -i min_val=10 -i max_val=80 <pre>created: '2026-02-12T16:29:38.462252Z'\nfinished: '2026-02-12T16:29:38.462780Z'\njobID: job_0\nmessage: Done\nprocessID: primes_between\nstarted: '2026-02-12T16:29:38.462625Z'\nstatus: successful\ntype: process\nupdated: '2026-02-12T16:29:38.462754Z'\n\n</pre> In\u00a0[7]: Copied! <pre>!cuiman execute-process process_pipeline -i id=\"eozilla-is-cool\"\n</pre> !cuiman execute-process process_pipeline -i id=\"eozilla-is-cool\" <pre>created: '2026-02-12T16:29:39.405144Z'\njobID: job_1\nprocessID: process_pipeline\nstatus: accepted\ntype: process\n\n</pre> In\u00a0[8]: Copied! <pre>!cuiman list-jobs\n</pre> !cuiman list-jobs <pre>jobs:\n- created: '2026-02-12T16:29:38.462252Z'\n  finished: '2026-02-12T16:29:38.462780Z'\n  jobID: job_0\n  message: Done\n  processID: primes_between\n  started: '2026-02-12T16:29:38.462625Z'\n  status: successful\n  type: process\n  updated: '2026-02-12T16:29:38.462754Z'\n- created: '2026-02-12T16:29:39.405144Z'\n  finished: '2026-02-12T16:29:39.406486Z'\n  jobID: job_1\n  processID: process_pipeline\n  started: '2026-02-12T16:29:39.405636Z'\n  status: successful\n  type: process\nlinks:\n- href: http://127.0.0.1:8008/jobs\n  hreflang: en\n  rel: self\n  title: get_jobs\n  type: application/json\n\n</pre> In\u00a0[9]: Copied! <pre>!cuiman get-job job_0\n</pre> !cuiman get-job job_0 <pre>created: '2026-02-12T16:29:38.462252Z'\nfinished: '2026-02-12T16:29:38.462780Z'\njobID: job_0\nmessage: Done\nprocessID: primes_between\nstarted: '2026-02-12T16:29:38.462625Z'\nstatus: successful\ntype: process\nupdated: '2026-02-12T16:29:38.462754Z'\n\n</pre> In\u00a0[10]: Copied! <pre>!cuiman get-job-results job_0\n</pre> !cuiman get-job-results job_0 <pre>return_value:\n- 11\n- 13\n- 17\n- 19\n- 23\n- 29\n- 31\n- 37\n- 41\n- 43\n- 47\n- 53\n- 59\n- 61\n- 67\n- 71\n- 73\n- 79\n\n</pre> In\u00a0[11]: Copied! <pre>!cuiman get-job job_1\n</pre> !cuiman get-job job_1 <pre>created: '2026-02-12T16:29:39.405144Z'\nfinished: '2026-02-12T16:29:39.406486Z'\njobID: job_1\nprocessID: process_pipeline\nstarted: '2026-02-12T16:29:39.405636Z'\nstatus: successful\ntype: process\n\n</pre> In\u00a0[12]: Copied! <pre>!cuiman get-job-results job_1\n</pre> !cuiman get-job-results job_1 <pre>final:\n- - eozilla-is-cool_read_preprocessed_feature_mean\n  - resampled_from=eozilla-is-cool\n- eozilla-is-cool_read_preprocessed_feature_mean\n\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/cuiman-cli/#cuiman-cli-usage","title":"Cuiman CLI usage\u00b6","text":"<p>Similar to the Cuiman Python API client, the CLI client provides the following capabilities:</p> <ul> <li><code>cuiman list-processes</code>: list existing processes,</li> <li><code>cuiman get-process</code>: get the details about a process,</li> <li><code>cuiman validate-request</code>: validate a given process execution request,</li> <li><code>cuiman execute-process</code>: execute a given process execution request,</li> <li><code>cuiman list-jobs</code>: list the jobs resulting from process executions, and finally</li> <li><code>cuiman get-job</code>: get a job's details,</li> <li><code>cuiman get-job-results</code>: get a successful job's results, and finally</li> <li><code>cuiman dismiss-job</code>: cancel a successful job.</li> </ul> <p>In the following, we visit all the features by example.</p> <p>The client expects a running server that conforms to the OGC API - Process: Part 1, Version 1.0. If you don't have one available, you can also run the project's server with a test configuration:</p> <pre>wraptile run -- wraptile.services.local.testing:service\n</pre>"},{"location":"notebooks/cuiman-gui/","title":"Cuiman GUI usage","text":"In\u00a0[1]: Copied! <pre>from cuiman.gui import Client\n</pre> from cuiman.gui import Client In\u00a0[2]: Copied! <pre>client = Client(api_url=\"http://localhost:8008/\", auth_type=\"none\")\n#client\n</pre> client = Client(api_url=\"http://localhost:8008/\", auth_type=\"none\") #client In\u00a0[3]: Copied! <pre>client.show()\n</pre> client.show() Out[3]: In\u00a0[9]: Copied! <pre>_request\n</pre> _request Out[9]: <pre><code>{\n  \"dotpath\": true,\n  \"inputs\": {\n    \"bbox\": [\n      5.873292,\n      52.495491,\n      13.519776,\n      55.140582\n    ],\n    \"end_date\": \"2025-02-01\",\n    \"output_path\": \"test.zarr\",\n    \"periodicity\": 1,\n    \"resolution\": 0.5,\n    \"start_date\": \"2025-01-01\",\n    \"var_names\": \"a, b, c\"\n  },\n  \"outputs\": {\n    \"return_value\": {\n      \"format\": {\n        \"mediaType\": \"application/json\"\n      },\n      \"transmissionMode\": \"reference\"\n    }\n  },\n  \"process_id\": \"simulate_scene\"\n}</code></pre> In\u00a0[10]: Copied! <pre>_results\n</pre> _results Out[10]: <pre><code>{\n  \"return_value\": {\n    \"href\": \"file:///C:/Users/Norman/Projects/eozilla/notebooks/test.zarr\",\n    \"hreflang\": null,\n    \"rel\": null,\n    \"title\": null,\n    \"type\": \"application/zarr\"\n  }\n}</code></pre> In\u00a0[7]: Copied! <pre>client.show_jobs()\n</pre> client.show_jobs() Out[7]: In\u00a0[11]: Copied! <pre>client.show_job(\"job_1\")\n</pre> client.show_job(\"job_1\") Out[11]: In\u00a0[12]: Copied! <pre>_results\n</pre> _results Out[12]: <pre><code>{\n  \"return_value\": {\n    \"href\": \"file:///C:/Users/Norman/Projects/eozilla/notebooks/test.zarr\",\n    \"hreflang\": null,\n    \"rel\": null,\n    \"title\": null,\n    \"type\": \"application/zarr\"\n  }\n}</code></pre> In\u00a0[13]: Copied! <pre>import xarray as xr\nxr.open_dataset(_results[\"return_value\"][\"href\"])\n</pre> import xarray as xr xr.open_dataset(_results[\"return_value\"][\"href\"]) Out[13]: <pre>&lt;xarray.Dataset&gt; Size: 56kB\nDimensions:  (time: 31, lat: 5, lon: 15)\nCoordinates:\n  * time     (time) datetime64[ns] 248B 2025-01-01 2025-01-02 ... 2025-01-31\n  * lat      (lat) float64 40B 52.75 53.28 53.82 54.35 54.89\n  * lon      (lon) float64 120B 6.123 6.634 7.144 7.655 ... 12.25 12.76 13.27\nData variables:\n    a        (time, lat, lon) float64 19kB ...\n    b        (time, lat, lon) float64 19kB ...\n    c        (time, lat, lon) float64 19kB ...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 31</li><li>lat: 5</li><li>lon: 15</li></ul></li><li>Coordinates: (3)<ul><li>time(time)datetime64[ns]2025-01-01 ... 2025-01-31<pre>array(['2025-01-01T00:00:00.000000000', '2025-01-02T00:00:00.000000000',\n       '2025-01-03T00:00:00.000000000', '2025-01-04T00:00:00.000000000',\n       '2025-01-05T00:00:00.000000000', '2025-01-06T00:00:00.000000000',\n       '2025-01-07T00:00:00.000000000', '2025-01-08T00:00:00.000000000',\n       '2025-01-09T00:00:00.000000000', '2025-01-10T00:00:00.000000000',\n       '2025-01-11T00:00:00.000000000', '2025-01-12T00:00:00.000000000',\n       '2025-01-13T00:00:00.000000000', '2025-01-14T00:00:00.000000000',\n       '2025-01-15T00:00:00.000000000', '2025-01-16T00:00:00.000000000',\n       '2025-01-17T00:00:00.000000000', '2025-01-18T00:00:00.000000000',\n       '2025-01-19T00:00:00.000000000', '2025-01-20T00:00:00.000000000',\n       '2025-01-21T00:00:00.000000000', '2025-01-22T00:00:00.000000000',\n       '2025-01-23T00:00:00.000000000', '2025-01-24T00:00:00.000000000',\n       '2025-01-25T00:00:00.000000000', '2025-01-26T00:00:00.000000000',\n       '2025-01-27T00:00:00.000000000', '2025-01-28T00:00:00.000000000',\n       '2025-01-29T00:00:00.000000000', '2025-01-30T00:00:00.000000000',\n       '2025-01-31T00:00:00.000000000'], dtype='datetime64[ns]')</pre></li><li>lat(lat)float6452.75 53.28 53.82 54.35 54.89<pre>array([52.745491, 53.281764, 53.818037, 54.354309, 54.890582])</pre></li><li>lon(lon)float646.123 6.634 7.144 ... 12.76 13.27<pre>array([ 6.123292,  6.633755,  7.144218,  7.654681,  8.165145,  8.675608,\n        9.186071,  9.696534, 10.206997, 10.71746 , 11.227923, 11.738387,\n       12.24885 , 12.759313, 13.269776])</pre></li></ul></li><li>Data variables: (3)<ul><li>a(time, lat, lon)float64...<pre>[2325 values with dtype=float64]</pre></li><li>b(time, lat, lon)float64...<pre>[2325 values with dtype=float64]</pre></li><li>c(time, lat, lon)float64...<pre>[2325 values with dtype=float64]</pre></li></ul></li></ul> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/cuiman-gui/#cuiman-gui-usage","title":"Cuiman GUI usage\u00b6","text":"<p>The Cuiman GUI client extends the Python API client by adding dedicated GUI-widgets for specific features:</p> <ul> <li><code>client.show()</code>: execute a given process execution request,</li> <li><code>client.show_jobs()</code>: show all jobs resulting from process execution,</li> <li><code>client.show_job()</code>: show the details of a specific job.</li> </ul> <p>Apart from that, they share the same interface. In the following, we visit all the features by example.</p> <p>The client expects a running server that conforms to the OGC API - Process: Part 1, Version 1.0. If you don't have one available, you can also run the project's server with a test configuration:</p> <pre>wraptile run -- wraptile.services.local.testing:service\n</pre>"},{"location":"procodile/api/","title":"Procodile API","text":"<p>The Procodile Python API is provided by the <code>procodile</code> package.</p> <p>options: show_source: false heading_level: 3</p> <p>options: show_source: false heading_level: 3</p> <p>options: show_source: false heading_level: 3</p> <p>options: show_source: false heading_level: 3</p> <p>options: show_source: false heading_level: 3</p>"},{"location":"procodile/api/#procodile.ProcessRegistry","title":"<code>procodile.ProcessRegistry</code>","text":"<p>               Bases: <code>Mapping[str, Process]</code></p> <p>A registry for processes.</p> <p>Processes are Python functions with extra metadata and can be extended to create <code>workflows</code> using <code>steps</code> decorator.</p> <p>A Workflow consists of one or more Python functions with metadata, designed to execute sequentially by resolving dependencies and passing outputs to downstream steps.</p> <p>This class provides a read-only mapping from unique identifiers to facade-like Process instances. While the user interacts with these processes, the registry internally manages full [Workflow][procodile.workflow.Workflow] instances.</p> <p>The internal Workflow objects hold the source-of-truth metadata required for dependency resolution and execution, while the exposed Process objects serve as the public interface for client interaction.</p> Source code in <code>procodile\\src\\procodile\\registry.py</code> <pre><code>class ProcessRegistry(Mapping[str, Process]):\n    \"\"\"\n    A registry for processes.\n\n    Processes are Python functions with extra metadata and can be extended\n    to create `workflows` using `steps` decorator.\n\n    A Workflow consists of one or more Python functions with metadata,\n    designed to execute sequentially by resolving dependencies and\n    passing outputs to downstream steps.\n\n    This class provides a read-only mapping from unique identifiers to\n    facade-like [Process][procodile.process.Process] instances. While the\n    user interacts with these processes, the registry internally\n    manages full [Workflow][procodile.workflow.Workflow] instances.\n\n    The internal Workflow objects hold the source-of-truth metadata required\n    for dependency resolution and execution, while the exposed Process\n    objects serve as the public interface for client interaction.\n    \"\"\"\n\n    def __init__(self):\n        self._workflows: dict[str, Workflow] = {}\n\n    # --- Overriding Mapping interface ---\n\n    def __getitem__(self, workflow_id: str) -&gt; Process:\n        return self._as_process(self._workflows[workflow_id])\n\n    def __iter__(self):\n        return iter(self._workflows)\n\n    def __len__(self) -&gt; int:\n        return len(self._workflows)\n\n    @staticmethod\n    @functools.lru_cache\n    def _as_process(workflow: Workflow) -&gt; Process:\n        \"\"\"This is the facade process object that is returned when the client wants\n        to see what processes are available and is also used to run the actual\n        workflow.\"\"\"\n\n        main = next(iter(workflow.registry.main.values()))\n\n        projected: Process = deepcopy(main)\n\n        # Steps exist -&gt; last step defines outputs\n        if workflow.registry.steps:\n            order, _ = workflow.execution_order\n            last_step_id = order[-2]  # because the step before that is the actual\n            # user defined last step.\n            last_step = workflow.registry.steps[last_step_id][\"step\"]\n            projected.description.outputs = last_step.description.outputs\n\n        # Update the function of the Process exposed to be `workflow.run` so\n        # that it executes the main and the steps after that in order.\n        projected.function = workflow.run\n\n        return projected\n\n    # --- Public API ---\n\n    # noinspection PyShadowingBuiltins\n    def main(\n        self,\n        function: Callable | None = None,\n        /,\n        *,\n        id: Optional[str] = None,\n        version: Optional[str] = None,\n        title: Optional[str] = None,\n        description: Optional[str] = None,\n        inputs: Optional[dict[str, FieldInfo | InputDescription]] = None,\n        outputs: Optional[dict[str, FieldInfo | OutputDescription]] = None,\n        inputs_arg: str | bool = False,\n    ) -&gt; Callable[[Callable], Workflow] | Callable:\n        \"\"\"\n        A decorator that can be applied to a user function in order to\n        register it as a process in this registry.\n\n        Note:\n\n            - Use `main` decorator to express a process that comprises multiple steps\n              that require a reference to the main entry point.\n\n            - Use `process` decorator to express a process that has no steps,\n              hence requires no reference to a main step.\n\n        The decorator can be used with or without parameters.\n\n        Args:\n            function: The decorated function that is passed automatically since\n                `process()` is a decorator function.\n            id: Optional process identifier. Must be unique within the registry.\n                If not provided, the fully qualified function name will be used.\n            version: Optional version identifier. If not provided, `\"0.0.0\"`\n                will be used.\n            title: Optional, short process title.\n            description: Optional, detailed description of the process. If not\n                provided, the function's docstring, if any, will be used.\n            inputs: Optional mapping from function argument names\n                to [`pydantic.Field`](https://docs.pydantic.dev/latest/concepts/fields/)\n                or [`InputDescription`][gavicore.models.InputDescription] instances.\n                The preferred way is to annotate the arguments directly\n                as described in [The Annotated Pattern](https://docs.pydantic.dev/latest/concepts/fields/#the-annotated-pattern).\n                Use `InputDescription` instances to pass extra information that cannot\n                be represented by a `pydantic.Field`, e.g., `additionalParameters` or `keywords`.\n            outputs: Mapping from output names to\n                [`pydantic.Field`](https://docs.pydantic.dev/latest/concepts/fields/)\n                or [`OutputDescription`][gavicore.models.InputDescription] instances.\n                Required, if you have multiple outputs returned as a\n                dictionary. In this case, the function must return a typed `tuple` and\n                output names refer to the items of the tuple in given order.\n            inputs_arg: Specifies the use of an _inputs argument_. An inputs argument\n                is a container for the actual process inputs. If specified, it must\n                be the only function argument (besides an optional job context\n                argument) and must be a subclass of `pydantic.BaseModel`.\n                If `inputs_arg` is `True` the only argument will be the input argument,\n                if `inputs_arg` is a `str` it must be the name of the only argument.\n        \"\"\"\n\n        def register_workflow(fn: Callable) -&gt; Workflow:\n            # noinspection PyUnresolvedReferences\n            f_name = f\"{fn.__module__}:{fn.__qualname__}\"\n            workflow_id = id or f_name\n            workflow = Workflow(\n                fn,\n                workflow_id=workflow_id,\n                id=id,\n                version=version,\n                title=title,\n                description=description,\n                inputs=inputs,\n                outputs=outputs,\n                inputs_arg=inputs_arg,\n            )\n            self._workflows[workflow_id] = workflow\n            return workflow\n\n        if function is None:\n            return register_workflow\n        return register_workflow(function)\n\n    # alias for main, when users need to define just process without any steps\n    process = main\n\n    # --- Internal API ---\n\n    def get_workflow(self, workflow_id: str) -&gt; Workflow:\n        return self._workflows[workflow_id]\n\n    def workflows(self) -&gt; dict[str, Workflow]:\n        return self._workflows\n</code></pre>"},{"location":"procodile/api/#procodile.ProcessRegistry.main","title":"<code>main(function=None, /, *, id=None, version=None, title=None, description=None, inputs=None, outputs=None, inputs_arg=False)</code>","text":"<p>A decorator that can be applied to a user function in order to register it as a process in this registry.</p> <p>Note:</p> <pre><code>- Use `main` decorator to express a process that comprises multiple steps\n  that require a reference to the main entry point.\n\n- Use `process` decorator to express a process that has no steps,\n  hence requires no reference to a main step.\n</code></pre> <p>The decorator can be used with or without parameters.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>Callable | None</code> <p>The decorated function that is passed automatically since <code>process()</code> is a decorator function.</p> <code>None</code> <code>id</code> <code>Optional[str]</code> <p>Optional process identifier. Must be unique within the registry. If not provided, the fully qualified function name will be used.</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Optional version identifier. If not provided, <code>\"0.0.0\"</code> will be used.</p> <code>None</code> <code>title</code> <code>Optional[str]</code> <p>Optional, short process title.</p> <code>None</code> <code>description</code> <code>Optional[str]</code> <p>Optional, detailed description of the process. If not provided, the function's docstring, if any, will be used.</p> <code>None</code> <code>inputs</code> <code>Optional[dict[str, FieldInfo | InputDescription]]</code> <p>Optional mapping from function argument names to <code>pydantic.Field</code> or [<code>InputDescription</code>][gavicore.models.InputDescription] instances. The preferred way is to annotate the arguments directly as described in The Annotated Pattern. Use <code>InputDescription</code> instances to pass extra information that cannot be represented by a <code>pydantic.Field</code>, e.g., <code>additionalParameters</code> or <code>keywords</code>.</p> <code>None</code> <code>outputs</code> <code>Optional[dict[str, FieldInfo | OutputDescription]]</code> <p>Mapping from output names to <code>pydantic.Field</code> or [<code>OutputDescription</code>][gavicore.models.InputDescription] instances. Required, if you have multiple outputs returned as a dictionary. In this case, the function must return a typed <code>tuple</code> and output names refer to the items of the tuple in given order.</p> <code>None</code> <code>inputs_arg</code> <code>str | bool</code> <p>Specifies the use of an inputs argument. An inputs argument is a container for the actual process inputs. If specified, it must be the only function argument (besides an optional job context argument) and must be a subclass of <code>pydantic.BaseModel</code>. If <code>inputs_arg</code> is <code>True</code> the only argument will be the input argument, if <code>inputs_arg</code> is a <code>str</code> it must be the name of the only argument.</p> <code>False</code> Source code in <code>procodile\\src\\procodile\\registry.py</code> <pre><code>def main(\n    self,\n    function: Callable | None = None,\n    /,\n    *,\n    id: Optional[str] = None,\n    version: Optional[str] = None,\n    title: Optional[str] = None,\n    description: Optional[str] = None,\n    inputs: Optional[dict[str, FieldInfo | InputDescription]] = None,\n    outputs: Optional[dict[str, FieldInfo | OutputDescription]] = None,\n    inputs_arg: str | bool = False,\n) -&gt; Callable[[Callable], Workflow] | Callable:\n    \"\"\"\n    A decorator that can be applied to a user function in order to\n    register it as a process in this registry.\n\n    Note:\n\n        - Use `main` decorator to express a process that comprises multiple steps\n          that require a reference to the main entry point.\n\n        - Use `process` decorator to express a process that has no steps,\n          hence requires no reference to a main step.\n\n    The decorator can be used with or without parameters.\n\n    Args:\n        function: The decorated function that is passed automatically since\n            `process()` is a decorator function.\n        id: Optional process identifier. Must be unique within the registry.\n            If not provided, the fully qualified function name will be used.\n        version: Optional version identifier. If not provided, `\"0.0.0\"`\n            will be used.\n        title: Optional, short process title.\n        description: Optional, detailed description of the process. If not\n            provided, the function's docstring, if any, will be used.\n        inputs: Optional mapping from function argument names\n            to [`pydantic.Field`](https://docs.pydantic.dev/latest/concepts/fields/)\n            or [`InputDescription`][gavicore.models.InputDescription] instances.\n            The preferred way is to annotate the arguments directly\n            as described in [The Annotated Pattern](https://docs.pydantic.dev/latest/concepts/fields/#the-annotated-pattern).\n            Use `InputDescription` instances to pass extra information that cannot\n            be represented by a `pydantic.Field`, e.g., `additionalParameters` or `keywords`.\n        outputs: Mapping from output names to\n            [`pydantic.Field`](https://docs.pydantic.dev/latest/concepts/fields/)\n            or [`OutputDescription`][gavicore.models.InputDescription] instances.\n            Required, if you have multiple outputs returned as a\n            dictionary. In this case, the function must return a typed `tuple` and\n            output names refer to the items of the tuple in given order.\n        inputs_arg: Specifies the use of an _inputs argument_. An inputs argument\n            is a container for the actual process inputs. If specified, it must\n            be the only function argument (besides an optional job context\n            argument) and must be a subclass of `pydantic.BaseModel`.\n            If `inputs_arg` is `True` the only argument will be the input argument,\n            if `inputs_arg` is a `str` it must be the name of the only argument.\n    \"\"\"\n\n    def register_workflow(fn: Callable) -&gt; Workflow:\n        # noinspection PyUnresolvedReferences\n        f_name = f\"{fn.__module__}:{fn.__qualname__}\"\n        workflow_id = id or f_name\n        workflow = Workflow(\n            fn,\n            workflow_id=workflow_id,\n            id=id,\n            version=version,\n            title=title,\n            description=description,\n            inputs=inputs,\n            outputs=outputs,\n            inputs_arg=inputs_arg,\n        )\n        self._workflows[workflow_id] = workflow\n        return workflow\n\n    if function is None:\n        return register_workflow\n    return register_workflow(function)\n</code></pre>"},{"location":"procodile/api/#procodile.Process","title":"<code>procodile.Process</code>  <code>dataclass</code>","text":"<p>A process comprises a process description and executable code in form of a Python function.</p> <p>Instances of this class are be managed by the ProcessRegistry.</p> <p>Attributes:</p> Name Type Description <code>function</code> <code>Callable</code> <p>The user's Python function.</p> <code>signature</code> <code>Signature</code> <p>The signature of <code>function</code>.</p> <code>job_ctx_arg</code> <code>str | None</code> <p>Names of <code>function</code> arguments of type <code>JobContext</code>.</p> <code>model_class</code> <code>type[BaseModel]</code> <p>Pydantic model class for the arguments of <code>function</code>.</p> <code>description</code> <code>ProcessDescription</code> <p>Process description modeled after OGC API - Processes - Part 1: Core.</p> Source code in <code>procodile\\src\\procodile\\process.py</code> <pre><code>@dataclass\nclass Process:\n    \"\"\"\n    A process comprises a process description and executable code\n    in form of a Python function.\n\n    Instances of this class are be managed by the\n    [ProcessRegistry][procodile.ProcessRegistry].\n\n    Attributes:\n        function: The user's Python function.\n        signature: The signature of `function`.\n        job_ctx_arg: Names of `function` arguments of type `JobContext`.\n        model_class: Pydantic model class for the arguments of `function`.\n        description: Process description modeled after\n            [OGC API - Processes - Part 1: Core](https://docs.ogc.org/is/18-062r2/18-062r2.html#toc37).\n    \"\"\"\n\n    function: Callable\n    signature: inspect.Signature\n    model_class: type[BaseModel]\n    description: ProcessDescription\n    # names of special arguments\n    inputs_arg: str | None\n    job_ctx_arg: str | None\n\n    # noinspection PyShadowingBuiltins\n    @classmethod\n    def create(\n        cls,\n        function: Callable,\n        id: Optional[str] = None,\n        version: Optional[str] = None,\n        title: Optional[str] = None,\n        description: Optional[str] = None,\n        inputs: Optional[dict[str, FieldInfo | InputDescription]] = None,\n        outputs: Optional[dict[str, FieldInfo | OutputDescription]] = None,\n        inputs_arg: str | bool = False,\n    ) -&gt; \"Process\":\n        \"\"\"Create a new instance of this dataclass.\n\n        Called by the `process_registry.main()` and by the `your_function.step()`\n        decorator, where `your_function` is the function decorated with `main()`.\n\n        Not intended to be used by clients.\n\n        Args:\n            function: The decorated function that is passed automatically since\n                `process()` is a decorator function.\n            id: Optional process identifier. Must be unique within the registry.\n                If not provided, the fully qualified function name will be used.\n            version: Optional version identifier. If not provided, `\"0.0.0\"`\n                will be used.\n            title: Optional, short process title.\n            description: Optional, detailed description of the process. If not\n                provided, the function's docstring, if any, will be used.\n            inputs: Optional mapping from function argument names\n                to [`pydantic.Field`](https://docs.pydantic.dev/latest/concepts/fields/)\n                or [`InputDescription`][gavicore.models.InputDescription] instances.\n                The preferred way is to annotate the arguments directly\n                as described in [The Annotated Pattern](https://docs.pydantic.dev/latest/concepts/fields/#the-annotated-pattern).\n                Use `InputDescription` instances to pass extra information that cannot\n                be represented by a `pydantic.Field`, e.g., `additionalParameters` or `keywords`.\n            outputs: Mapping from output names to\n                [`pydantic.Field`](https://docs.pydantic.dev/latest/concepts/fields/)\n                or [`OutputDescription`][gavicore.models.InputDescription] instances.\n                Required, if you have multiple outputs returned as a\n                dictionary. In this case, the function must return a typed `tuple` and\n                output names refer to the items of the tuple in given order.\n            inputs_arg: Specifies the use of an _inputs argument_. An inputs argument\n                is a container for the actual process inputs. If specified, it must\n                be the only function argument (besides an optional job context\n                argument) and must be a subclass of `pydantic.BaseModel`.\n                If `inputs_arg` is `True` the only argument will be the input argument,\n                if `inputs_arg` is a `str` it must be the name of the only argument.\n\n        \"\"\"\n        if not inspect.isfunction(function):\n            raise TypeError(\"function argument must be callable\")\n        fn_name = f\"{function.__module__}:{function.__qualname__}\"\n        id = id or fn_name\n        version = version or \"0.0.0\"\n        description = description or inspect.getdoc(function)\n        signature = inspect.signature(function)\n        input_descriptions, model_class, input_arg_, job_ctx_arg = _parse_inputs(\n            fn_name, signature, inputs, inputs_arg\n        )\n        output_descriptions = _parse_outputs(\n            fn_name, signature.return_annotation, outputs\n        )\n        return Process(\n            function=function,\n            signature=signature,\n            model_class=model_class,\n            description=ProcessDescription(\n                id=id,\n                version=version,\n                title=title,\n                description=description,\n                inputs=input_descriptions,\n                outputs=output_descriptions,\n                # Note, we may later add the following:\n                # metadata=metadata,\n                # keywords=keywords,\n                # links=links,\n                # outputTransmission=output_transmission,\n                # jobControlOptions=job_control_options,\n            ),\n            inputs_arg=input_arg_,\n            job_ctx_arg=job_ctx_arg,\n        )\n</code></pre>"},{"location":"procodile/api/#procodile.Process.create","title":"<code>create(function, id=None, version=None, title=None, description=None, inputs=None, outputs=None, inputs_arg=False)</code>  <code>classmethod</code>","text":"<p>Create a new instance of this dataclass.</p> <p>Called by the <code>process_registry.main()</code> and by the <code>your_function.step()</code> decorator, where <code>your_function</code> is the function decorated with <code>main()</code>.</p> <p>Not intended to be used by clients.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>Callable</code> <p>The decorated function that is passed automatically since <code>process()</code> is a decorator function.</p> required <code>id</code> <code>Optional[str]</code> <p>Optional process identifier. Must be unique within the registry. If not provided, the fully qualified function name will be used.</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Optional version identifier. If not provided, <code>\"0.0.0\"</code> will be used.</p> <code>None</code> <code>title</code> <code>Optional[str]</code> <p>Optional, short process title.</p> <code>None</code> <code>description</code> <code>Optional[str]</code> <p>Optional, detailed description of the process. If not provided, the function's docstring, if any, will be used.</p> <code>None</code> <code>inputs</code> <code>Optional[dict[str, FieldInfo | InputDescription]]</code> <p>Optional mapping from function argument names to <code>pydantic.Field</code> or [<code>InputDescription</code>][gavicore.models.InputDescription] instances. The preferred way is to annotate the arguments directly as described in The Annotated Pattern. Use <code>InputDescription</code> instances to pass extra information that cannot be represented by a <code>pydantic.Field</code>, e.g., <code>additionalParameters</code> or <code>keywords</code>.</p> <code>None</code> <code>outputs</code> <code>Optional[dict[str, FieldInfo | OutputDescription]]</code> <p>Mapping from output names to <code>pydantic.Field</code> or [<code>OutputDescription</code>][gavicore.models.InputDescription] instances. Required, if you have multiple outputs returned as a dictionary. In this case, the function must return a typed <code>tuple</code> and output names refer to the items of the tuple in given order.</p> <code>None</code> <code>inputs_arg</code> <code>str | bool</code> <p>Specifies the use of an inputs argument. An inputs argument is a container for the actual process inputs. If specified, it must be the only function argument (besides an optional job context argument) and must be a subclass of <code>pydantic.BaseModel</code>. If <code>inputs_arg</code> is <code>True</code> the only argument will be the input argument, if <code>inputs_arg</code> is a <code>str</code> it must be the name of the only argument.</p> <code>False</code> Source code in <code>procodile\\src\\procodile\\process.py</code> <pre><code>@classmethod\ndef create(\n    cls,\n    function: Callable,\n    id: Optional[str] = None,\n    version: Optional[str] = None,\n    title: Optional[str] = None,\n    description: Optional[str] = None,\n    inputs: Optional[dict[str, FieldInfo | InputDescription]] = None,\n    outputs: Optional[dict[str, FieldInfo | OutputDescription]] = None,\n    inputs_arg: str | bool = False,\n) -&gt; \"Process\":\n    \"\"\"Create a new instance of this dataclass.\n\n    Called by the `process_registry.main()` and by the `your_function.step()`\n    decorator, where `your_function` is the function decorated with `main()`.\n\n    Not intended to be used by clients.\n\n    Args:\n        function: The decorated function that is passed automatically since\n            `process()` is a decorator function.\n        id: Optional process identifier. Must be unique within the registry.\n            If not provided, the fully qualified function name will be used.\n        version: Optional version identifier. If not provided, `\"0.0.0\"`\n            will be used.\n        title: Optional, short process title.\n        description: Optional, detailed description of the process. If not\n            provided, the function's docstring, if any, will be used.\n        inputs: Optional mapping from function argument names\n            to [`pydantic.Field`](https://docs.pydantic.dev/latest/concepts/fields/)\n            or [`InputDescription`][gavicore.models.InputDescription] instances.\n            The preferred way is to annotate the arguments directly\n            as described in [The Annotated Pattern](https://docs.pydantic.dev/latest/concepts/fields/#the-annotated-pattern).\n            Use `InputDescription` instances to pass extra information that cannot\n            be represented by a `pydantic.Field`, e.g., `additionalParameters` or `keywords`.\n        outputs: Mapping from output names to\n            [`pydantic.Field`](https://docs.pydantic.dev/latest/concepts/fields/)\n            or [`OutputDescription`][gavicore.models.InputDescription] instances.\n            Required, if you have multiple outputs returned as a\n            dictionary. In this case, the function must return a typed `tuple` and\n            output names refer to the items of the tuple in given order.\n        inputs_arg: Specifies the use of an _inputs argument_. An inputs argument\n            is a container for the actual process inputs. If specified, it must\n            be the only function argument (besides an optional job context\n            argument) and must be a subclass of `pydantic.BaseModel`.\n            If `inputs_arg` is `True` the only argument will be the input argument,\n            if `inputs_arg` is a `str` it must be the name of the only argument.\n\n    \"\"\"\n    if not inspect.isfunction(function):\n        raise TypeError(\"function argument must be callable\")\n    fn_name = f\"{function.__module__}:{function.__qualname__}\"\n    id = id or fn_name\n    version = version or \"0.0.0\"\n    description = description or inspect.getdoc(function)\n    signature = inspect.signature(function)\n    input_descriptions, model_class, input_arg_, job_ctx_arg = _parse_inputs(\n        fn_name, signature, inputs, inputs_arg\n    )\n    output_descriptions = _parse_outputs(\n        fn_name, signature.return_annotation, outputs\n    )\n    return Process(\n        function=function,\n        signature=signature,\n        model_class=model_class,\n        description=ProcessDescription(\n            id=id,\n            version=version,\n            title=title,\n            description=description,\n            inputs=input_descriptions,\n            outputs=output_descriptions,\n            # Note, we may later add the following:\n            # metadata=metadata,\n            # keywords=keywords,\n            # links=links,\n            # outputTransmission=output_transmission,\n            # jobControlOptions=job_control_options,\n        ),\n        inputs_arg=input_arg_,\n        job_ctx_arg=job_ctx_arg,\n    )\n</code></pre>"},{"location":"procodile/api/#gavicore.models.ProcessRequest","title":"<code>gavicore.models.ProcessRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>gavicore\\src\\gavicore\\models.py</code> <pre><code>class ProcessRequest(BaseModel):\n    inputs: Optional[dict[str, Any]] = None\n    outputs: Optional[dict[str, Output]] = None\n    response: Optional[ResponseType] = ResponseType.raw\n    subscriber: Optional[Subscriber] = None\n</code></pre>"},{"location":"procodile/api/#gavicore.models.Subscriber","title":"<code>gavicore.models.Subscriber</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Optional URIs for callbacks for this job.</p> <p>Support for this parameter is not required and the parameter may be removed from the API definition, if conformance class 'callback' is not listed in the conformance declaration under <code>/conformance</code>.</p> Source code in <code>gavicore\\src\\gavicore\\models.py</code> <pre><code>class Subscriber(BaseModel):\n    \"\"\"\n    Optional URIs for callbacks for this job.\n\n    Support for this parameter is not required and the parameter may be\n    removed from the API definition, if conformance class **'callback'**\n    is not listed in the conformance declaration under `/conformance`.\n    \"\"\"\n\n    successUri: Optional[AnyUrl] = None\n    inProgressUri: Optional[AnyUrl] = None\n    failedUri: Optional[AnyUrl] = None\n</code></pre>"},{"location":"procodile/api/#gavicore.models.Output","title":"<code>gavicore.models.Output</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>gavicore\\src\\gavicore\\models.py</code> <pre><code>class Output(BaseModel):\n    format: Optional[Format] = None\n    transmissionMode: Optional[TransmissionMode] = TransmissionMode.value\n</code></pre>"},{"location":"procodile/api/#gavicore.util.request.ExecutionRequest","title":"<code>gavicore.util.request.ExecutionRequest</code>","text":"<p>               Bases: <code>ProcessRequest</code></p> <p>Process execution request. Extends ProcessRequest</p> <ul> <li>to allow the process identifier being part of the request,</li> <li>to allow creating nested object values for input names with dots.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>process_id</code> <p>Process identifier</p> required <code>dotpath</code> <p>Whether dots in input names should be used to create nested object values. Defaults to <code>False</code>.</p> required <code>inputs</code> <p>Optional process inputs given as key-value mapping. Values may be of any JSON-serializable type accepted by the given process.</p> required <code>outputs</code> <p>Optional process outputs given as key-value mapping. Values are of type Output supported by the given process.</p> required <code>subscriber</code> <p>Optional subscriber of type Subscriber comprising callback URLs that are informed about process status changes while the processing takes place.</p> required Source code in <code>gavicore\\src\\gavicore\\util\\request.py</code> <pre><code>class ExecutionRequest(ProcessRequest):\n    \"\"\"\n    Process execution request.\n    Extends [ProcessRequest][gavicore.models.ProcessRequest]\n\n    - to allow the process identifier being part of the request,\n    - to allow creating nested object values for input names with dots.\n\n    Args:\n        process_id: Process identifier\n        dotpath: Whether dots in input names should be used to create\n            nested object values. Defaults to `False`.\n        inputs: Optional process inputs given as key-value mapping.\n            Values may be of any JSON-serializable type accepted by\n            the given process.\n        outputs: Optional process outputs given as key-value mapping.\n            Values are of type [Output][gavicore.models.Output]\n            supported by the given process.\n        subscriber: Optional subscriber of type\n            [Subscriber][gavicore.models.Subscriber] comprising callback\n            URLs that are informed about process status changes\n            while the processing takes place.\n    \"\"\"\n\n    process_id: Annotated[str, Field(title=\"Process identifier\", min_length=1)]\n    dotpath: Annotated[\n        bool, Field(title=\"Whether to encode nested input values using dots ('.').\")\n    ] = False\n\n    def to_process_request(self) -&gt; ProcessRequest:\n        \"\"\"\n        Convert this execution request into a process request as used by the\n        `execute-process` operation.\n        \"\"\"\n        inputs = self.inputs\n        if inputs and self.dotpath:\n            inputs = nest_dict(inputs)\n        return ProcessRequest(\n            inputs=inputs,\n            outputs=self.outputs,\n            response=self.response,\n            subscriber=self.subscriber,\n        )\n\n    @classmethod\n    def create(\n        cls,\n        process_id: str | None = None,\n        dotpath: bool = False,\n        request_path: str | None = None,\n        inputs: list[str] | None = None,\n        subscribers: list[str] | None = None,\n    ) -&gt; \"ExecutionRequest\":\n        \"\"\"\n        A factory method to create an execution request.\n\n        The method is intended to support CLI implementations parsing user inputs\n        and creating validated execution requests.\n\n        Args:\n            process_id: Process identifier\n            dotpath: Whether dots in input names should be used to create\n                nested object values. Defaults to `False`.\n            request_path: Local path to a file that contains an execution request\n                in YAML or JSON format.\n            inputs: Optional process inputs given as a list of \"&lt;key&gt;=&lt;value&gt;\" strings.\n            subscribers: Optional subscribers given as a list of\n                \"&lt;event&gt;=&lt;url&gt;\" strings.\n\n        Return:\n            A validated execution request of type `ExecutionRequest`.\n\n        Raise:\n            ValueError: if a validation error occurs.\n        \"\"\"\n        request_dict, _ = _read_execution_request(request_path)\n        if process_id:\n            request_dict[\"process_id\"] = process_id\n        if dotpath:\n            request_dict[\"dotpath\"] = dotpath\n        inputs_dict = _parse_inputs(inputs)\n        if inputs_dict:\n            request_dict[\"inputs\"] = dict(request_dict.get(\"inputs\") or {})\n            request_dict[\"inputs\"].update(inputs_dict)\n        subscriber_dict = _parse_subscribers(subscribers)\n        if subscriber_dict:\n            request_dict[\"subscriber\"] = dict(request_dict.get(\"subscriber\") or {})\n            request_dict[\"subscriber\"].update(subscriber_dict)\n        try:\n            return ExecutionRequest(**request_dict)\n        except pydantic.ValidationError as e:\n            raise ValueError(f\"Execution request is invalid: {e}\") from e\n\n    @classmethod\n    def from_process_description(\n        cls,\n        process_description: ProcessDescription,\n        dotpath: bool = False,\n    ) -&gt; \"ExecutionRequest\":\n        \"\"\"\n        Create an execution request from the given process description.\n\n        Args:\n            process_description: The process description\n            dotpath: Whether to allow for dot-separated input\n                names for nested object values\n\n        Returns:\n            The execution requests populated with default values.\n        \"\"\"\n        return _from_process_description(process_description, dotpath)\n</code></pre>"},{"location":"procodile/api/#gavicore.util.request.ExecutionRequest.to_process_request","title":"<code>to_process_request()</code>","text":"<p>Convert this execution request into a process request as used by the <code>execute-process</code> operation.</p> Source code in <code>gavicore\\src\\gavicore\\util\\request.py</code> <pre><code>def to_process_request(self) -&gt; ProcessRequest:\n    \"\"\"\n    Convert this execution request into a process request as used by the\n    `execute-process` operation.\n    \"\"\"\n    inputs = self.inputs\n    if inputs and self.dotpath:\n        inputs = nest_dict(inputs)\n    return ProcessRequest(\n        inputs=inputs,\n        outputs=self.outputs,\n        response=self.response,\n        subscriber=self.subscriber,\n    )\n</code></pre>"},{"location":"procodile/api/#gavicore.util.request.ExecutionRequest.create","title":"<code>create(process_id=None, dotpath=False, request_path=None, inputs=None, subscribers=None)</code>  <code>classmethod</code>","text":"<p>A factory method to create an execution request.</p> <p>The method is intended to support CLI implementations parsing user inputs and creating validated execution requests.</p> <p>Parameters:</p> Name Type Description Default <code>process_id</code> <code>str | None</code> <p>Process identifier</p> <code>None</code> <code>dotpath</code> <code>bool</code> <p>Whether dots in input names should be used to create nested object values. Defaults to <code>False</code>.</p> <code>False</code> <code>request_path</code> <code>str | None</code> <p>Local path to a file that contains an execution request in YAML or JSON format.</p> <code>None</code> <code>inputs</code> <code>list[str] | None</code> <p>Optional process inputs given as a list of \"=\" strings. <code>None</code> <code>subscribers</code> <code>list[str] | None</code> <p>Optional subscribers given as a list of \"=\" strings. <code>None</code> Return <p>A validated execution request of type <code>ExecutionRequest</code>.</p> Raise <p>ValueError: if a validation error occurs.</p> Source code in <code>gavicore\\src\\gavicore\\util\\request.py</code> <pre><code>@classmethod\ndef create(\n    cls,\n    process_id: str | None = None,\n    dotpath: bool = False,\n    request_path: str | None = None,\n    inputs: list[str] | None = None,\n    subscribers: list[str] | None = None,\n) -&gt; \"ExecutionRequest\":\n    \"\"\"\n    A factory method to create an execution request.\n\n    The method is intended to support CLI implementations parsing user inputs\n    and creating validated execution requests.\n\n    Args:\n        process_id: Process identifier\n        dotpath: Whether dots in input names should be used to create\n            nested object values. Defaults to `False`.\n        request_path: Local path to a file that contains an execution request\n            in YAML or JSON format.\n        inputs: Optional process inputs given as a list of \"&lt;key&gt;=&lt;value&gt;\" strings.\n        subscribers: Optional subscribers given as a list of\n            \"&lt;event&gt;=&lt;url&gt;\" strings.\n\n    Return:\n        A validated execution request of type `ExecutionRequest`.\n\n    Raise:\n        ValueError: if a validation error occurs.\n    \"\"\"\n    request_dict, _ = _read_execution_request(request_path)\n    if process_id:\n        request_dict[\"process_id\"] = process_id\n    if dotpath:\n        request_dict[\"dotpath\"] = dotpath\n    inputs_dict = _parse_inputs(inputs)\n    if inputs_dict:\n        request_dict[\"inputs\"] = dict(request_dict.get(\"inputs\") or {})\n        request_dict[\"inputs\"].update(inputs_dict)\n    subscriber_dict = _parse_subscribers(subscribers)\n    if subscriber_dict:\n        request_dict[\"subscriber\"] = dict(request_dict.get(\"subscriber\") or {})\n        request_dict[\"subscriber\"].update(subscriber_dict)\n    try:\n        return ExecutionRequest(**request_dict)\n    except pydantic.ValidationError as e:\n        raise ValueError(f\"Execution request is invalid: {e}\") from e\n</code></pre> <p>options: show_source: false heading_level: 3</p> <p>options: show_source: false heading_level: 3</p> <p>options: show_source: false heading_level: 3</p> <p>options: show_source: false heading_level: 3</p>"},{"location":"procodile/api/#gavicore.util.request.ExecutionRequest.from_process_description","title":"<code>from_process_description(process_description, dotpath=False)</code>  <code>classmethod</code>","text":"<p>Create an execution request from the given process description.</p> <p>Parameters:</p> Name Type Description Default <code>process_description</code> <code>ProcessDescription</code> <p>The process description</p> required <code>dotpath</code> <code>bool</code> <p>Whether to allow for dot-separated input names for nested object values</p> <code>False</code> <p>Returns:</p> Type Description <code>ExecutionRequest</code> <p>The execution requests populated with default values.</p> Source code in <code>gavicore\\src\\gavicore\\util\\request.py</code> <pre><code>@classmethod\ndef from_process_description(\n    cls,\n    process_description: ProcessDescription,\n    dotpath: bool = False,\n) -&gt; \"ExecutionRequest\":\n    \"\"\"\n    Create an execution request from the given process description.\n\n    Args:\n        process_description: The process description\n        dotpath: Whether to allow for dot-separated input\n            names for nested object values\n\n    Returns:\n        The execution requests populated with default values.\n    \"\"\"\n    return _from_process_description(process_description, dotpath)\n</code></pre>"},{"location":"procodile/api/#procodile.JobContext","title":"<code>procodile.JobContext</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Report process progress and check for task cancellation.</p> <p>A process function can retrieve the current job context</p> <ol> <li>via JobContext.get() from    within a process function, or</li> <li>as a function argument of type JobContext.</li> </ol> Source code in <code>procodile\\src\\procodile\\job.py</code> <pre><code>class JobContext(ABC):\n    \"\"\"\n    Report process progress and check for task cancellation.\n\n    A process function can retrieve the current job context\n\n    1. via [JobContext.get()][procodile.JobContext.get] from\n       within a process function, or\n    2. as a function argument of type [JobContext][procodile.JobContext].\n    \"\"\"\n\n    @classmethod\n    def get(cls) -&gt; \"JobContext\":\n        \"\"\"\n        Get the current job context.\n\n        Returns the current job context that can be used by\n        process functions to report job progress in percent\n        or via messages and to check whether cancellation\n        has been requested.\n        This function is intended to be called from within\n        a process function executed as a job. If called as a usual\n        Python function (without a job serving as context), the\n        returned context will have no-op methods only.\n\n        Returns:\n            An instance of the current job context.\n        \"\"\"\n        frame = inspect.currentframe()\n        try:\n            while frame:\n                job_context = frame.f_locals.get(\"__job_context__\")\n                if isinstance(job_context, JobContext):\n                    return job_context\n                frame = frame.f_back\n        finally:\n            # Always free alive frame-references\n            del frame\n        # noinspection PyUnreachableCode\n        warnings.warn(\n            \"cannot determine current job context; using non-functional dummy\",\n            stacklevel=2,\n        )\n        return NullJobContext()\n\n    @abstractmethod\n    def report_progress(\n        self,\n        progress: Optional[int] = None,\n        message: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Report task progress.\n\n        Args:\n            progress: Progress in percent.\n            message: Detail progress message.\n\n        Raises:\n            JobCancellationException: if an attempt has been made\n                to cancel this job.\n        \"\"\"\n\n    @abstractmethod\n    def is_cancelled(self) -&gt; bool:\n        \"\"\"Test whether an attempt has been made to cancel this job.\n        It may still be running though.\n\n        Returns:\n            `True` if so, `False` otherwise.\n        \"\"\"\n\n    @abstractmethod\n    def check_cancelled(self) -&gt; None:\n        \"\"\"Raise a `JobCancellationException`, if\n        an attempt has been made to cancel this job.\n        \"\"\"\n</code></pre>"},{"location":"procodile/api/#procodile.JobContext.get","title":"<code>get()</code>  <code>classmethod</code>","text":"<p>Get the current job context.</p> <p>Returns the current job context that can be used by process functions to report job progress in percent or via messages and to check whether cancellation has been requested. This function is intended to be called from within a process function executed as a job. If called as a usual Python function (without a job serving as context), the returned context will have no-op methods only.</p> <p>Returns:</p> Type Description <code>JobContext</code> <p>An instance of the current job context.</p> Source code in <code>procodile\\src\\procodile\\job.py</code> <pre><code>@classmethod\ndef get(cls) -&gt; \"JobContext\":\n    \"\"\"\n    Get the current job context.\n\n    Returns the current job context that can be used by\n    process functions to report job progress in percent\n    or via messages and to check whether cancellation\n    has been requested.\n    This function is intended to be called from within\n    a process function executed as a job. If called as a usual\n    Python function (without a job serving as context), the\n    returned context will have no-op methods only.\n\n    Returns:\n        An instance of the current job context.\n    \"\"\"\n    frame = inspect.currentframe()\n    try:\n        while frame:\n            job_context = frame.f_locals.get(\"__job_context__\")\n            if isinstance(job_context, JobContext):\n                return job_context\n            frame = frame.f_back\n    finally:\n        # Always free alive frame-references\n        del frame\n    # noinspection PyUnreachableCode\n    warnings.warn(\n        \"cannot determine current job context; using non-functional dummy\",\n        stacklevel=2,\n    )\n    return NullJobContext()\n</code></pre>"},{"location":"procodile/api/#procodile.JobContext.report_progress","title":"<code>report_progress(progress=None, message=None)</code>  <code>abstractmethod</code>","text":"<p>Report task progress.</p> <p>Parameters:</p> Name Type Description Default <code>progress</code> <code>Optional[int]</code> <p>Progress in percent.</p> <code>None</code> <code>message</code> <code>Optional[str]</code> <p>Detail progress message.</p> <code>None</code> <p>Raises:</p> Type Description <code>JobCancellationException</code> <p>if an attempt has been made to cancel this job.</p> Source code in <code>procodile\\src\\procodile\\job.py</code> <pre><code>@abstractmethod\ndef report_progress(\n    self,\n    progress: Optional[int] = None,\n    message: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Report task progress.\n\n    Args:\n        progress: Progress in percent.\n        message: Detail progress message.\n\n    Raises:\n        JobCancellationException: if an attempt has been made\n            to cancel this job.\n    \"\"\"\n</code></pre>"},{"location":"procodile/api/#procodile.JobContext.is_cancelled","title":"<code>is_cancelled()</code>  <code>abstractmethod</code>","text":"<p>Test whether an attempt has been made to cancel this job. It may still be running though.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if so, <code>False</code> otherwise.</p> Source code in <code>procodile\\src\\procodile\\job.py</code> <pre><code>@abstractmethod\ndef is_cancelled(self) -&gt; bool:\n    \"\"\"Test whether an attempt has been made to cancel this job.\n    It may still be running though.\n\n    Returns:\n        `True` if so, `False` otherwise.\n    \"\"\"\n</code></pre>"},{"location":"procodile/api/#procodile.JobContext.check_cancelled","title":"<code>check_cancelled()</code>  <code>abstractmethod</code>","text":"<p>Raise a <code>JobCancellationException</code>, if an attempt has been made to cancel this job.</p> Source code in <code>procodile\\src\\procodile\\job.py</code> <pre><code>@abstractmethod\ndef check_cancelled(self) -&gt; None:\n    \"\"\"Raise a `JobCancellationException`, if\n    an attempt has been made to cancel this job.\n    \"\"\"\n</code></pre>"},{"location":"procodile/api/#procodile.JobCancelledException","title":"<code>procodile.JobCancelledException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised if a job's cancellation has been requested.</p> Source code in <code>procodile\\src\\procodile\\job.py</code> <pre><code>class JobCancelledException(Exception):\n    \"\"\"Raised if a job's cancellation has been requested.\"\"\"\n</code></pre>"},{"location":"procodile/api/#procodile.cli.new_cli","title":"<code>procodile.cli.new_cli(registry, name, version, help=None, summary=None, context=None)</code>","text":"<p>Get the CLI instance configured to use the process registry that is given either by</p> <ul> <li>a reference of the form \"path.to.module:attribute\",</li> <li>or process registry instance,</li> <li>or as a no-arg process registry getter function.</li> </ul> <p>The process registry is usually a singleton in your application.</p> <p>The context object <code>obj</code> of the returned CLI object will be of type <code>dict</code> and will contain a process registry getter function using the key <code>get_process_registry</code>.</p> <p>The function must be called before any CLI command or callback has been invoked. Otherwise, the provided <code>get_process_registry</code> getter will not be recognized and all commands that require the process registry will fail with an <code>AssertionError</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the CLI application.</p> required <code>registry</code> <code>Union[str, ProcessRegistry, Callable[[], ProcessRegistry]]</code> <p>A registry reference string, or a registry instance, or a no-arg function that returns a registry instance.</p> required <code>help</code> <code>str | None</code> <p>Optional CLI application help text. If not provided, the default <code>cuiman</code> help text will be used.</p> <code>None</code> <code>summary</code> <code>str | None</code> <p>A one-sentence human-readable description of the tool that will be used by the default help text. Hence, used only, if <code>help</code> is not provided. Should end with a dot '.'.</p> <code>None</code> <code>version</code> <code>str</code> <p>Optional version string. If not provided, the <code>cuiman</code> version will be used.</p> required <code>context</code> <code>dict[str, Any] | None</code> <p>Additional context values that will be registered with the CLI and can be accessed by commands that you add to the returned <code>typer.Typer</code> instance.</p> <code>None</code> Return <p>a <code>typer.Typer</code> instance</p> Source code in <code>procodile\\src\\procodile\\cli\\cli.py</code> <pre><code>def new_cli(\n    registry: Union[\n        str,\n        \"ProcessRegistry\",\n        Callable[[], \"ProcessRegistry\"],\n    ],\n    name: str,\n    version: str,\n    help: str | None = None,\n    summary: str | None = None,\n    context: dict[str, Any] | None = None,\n) -&gt; typer.Typer:\n    \"\"\"\n    Get the CLI instance configured to use the process registry\n    that is given either by\n\n    - a reference of the form \"path.to.module:attribute\",\n    - or process registry instance,\n    - or as a no-arg process registry getter function.\n\n    The process registry is usually a singleton in your application.\n\n    The context object `obj` of the returned CLI object\n    will be of type `dict` and will contain\n    a process registry getter function using the key\n    `get_process_registry`.\n\n    The function must be called before any CLI command or\n    callback has been invoked. Otherwise, the provided\n    `get_process_registry` getter will not be recognized and\n    all commands that require the process registry will\n    fail with an `AssertionError`.\n\n    Args:\n        name: The name of the CLI application.\n        registry: A registry reference string,\n            or a registry instance, or a no-arg\n            function that returns a registry instance.\n        help: Optional CLI application help text. If not provided, the default\n            `cuiman` help text will be used.\n        summary: A one-sentence human-readable description of the tool that\n            will be used by the default help text. Hence, used only,\n            if `help` is not provided. Should end with a dot '.'.\n        version: Optional version string. If not provided, the\n            `cuiman` version will be used.\n        context: Additional context values that will be registered with the CLI\n            and can be accessed by commands that you add to the\n            returned `typer.Typer` instance.\n\n    Return:\n        a `typer.Typer` instance\n    \"\"\"\n    assert bool(registry), \"registry argument must be provided\"\n    assert bool(name), \"name argument must be provided\"\n    assert bool(version), \"version argument must be provided\"\n\n    t = typer.Typer(\n        cls=AliasedGroup,\n        name=name,\n        help=(\n            help\n            or DEFAULT_HELP.format(summary=summary or DEFAULT_SUMMARY.format(name=name))\n        ),\n        add_completion=False,\n        invoke_without_command=True,\n        context_settings={\n            \"obj\": {\n                PROCESS_REGISTRY_GETTER_KEY: _parse_process_registry_getter(registry),\n                **(context or {}),\n            },\n        },\n    )\n\n    @t.callback()\n    def main(\n        version_: Annotated[\n            bool, typer.Option(\"--version\", help=\"Show version and exit.\")\n        ] = False,\n    ):\n        if version_:\n            from procodile import __version__ as procodile_version\n\n            typer.echo(f\"{version} (procodile {procodile_version})\")\n            return\n\n    @t.command(\"execute-process\")\n    def execute_process(\n        ctx: typer.Context,\n        process_id: Annotated[Optional[str], PROCESS_ID_ARGUMENT] = None,\n        dotpath: Annotated[bool, DOT_PATH_OPTION] = False,\n        request_inputs: Annotated[Optional[list[str]], REQUEST_INPUT_OPTION] = None,\n        request_subscribers: Annotated[\n            Optional[list[str]], REQUEST_SUBSCRIBER_OPTION\n        ] = None,\n        request_file: Annotated[Optional[str], REQUEST_FILE_OPTION] = None,\n    ):\n        \"\"\"\n        Execute a process.\n\n        The process request to be submitted may be read from a file given\n        by `--request`, or from `stdin`, or from the `process_id` argument\n        with zero, one, or more `--input` (or `-i`) options.\n\n        The `process_id` argument and any given `--input` options will override\n        settings with the same name found in the given request file or `stdin`,\n        if any.\n        \"\"\"\n        from procodile import ExecutionRequest, Job\n\n        registry = _get_process_registry(ctx)\n        execution_request = ExecutionRequest.create(\n            process_id=process_id,\n            dotpath=dotpath,\n            inputs=request_inputs,\n            subscribers=request_subscribers,\n            request_path=request_file,\n        )\n        process_id_ = execution_request.process_id\n        process = registry.get(process_id_)\n        if process is None:\n            raise click.ClickException(f\"Process {process_id_!r} not found.\")\n\n        job = Job.create(process, request=execution_request.to_process_request())\n        job_results = job.run()\n        if job_results is not None:\n            typer.echo(job_results.model_dump_json(indent=2))\n        else:\n            typer.echo(job.job_info.model_dump_json(indent=2))\n\n    @t.command(\"list-processes\", help=\"List all processes.\")\n    def list_processes(ctx: typer.Context):\n        registry = _get_process_registry(ctx)\n        typer.echo(\n            json.dumps(\n                {\n                    k: v.description.model_dump(\n                        mode=\"json\",\n                        by_alias=True,\n                        exclude_none=True,\n                        exclude_defaults=True,\n                        exclude_unset=True,\n                        exclude={\"inputs\", \"outputs\"},\n                    )\n                    for k, v in registry.items()\n                },\n                indent=2,\n            )\n        )\n\n    @t.command(\"get-process\", help=\"Get details of a process.\")\n    def get_process(\n        ctx: typer.Context,\n        process_id: Annotated[str, PROCESS_ID_ARGUMENT],\n    ):\n        import json\n\n        registry = _get_process_registry(ctx)\n        process = registry.get(process_id)\n        if process is None:\n            raise click.ClickException(f\"Process {process_id!r} not found.\")\n\n        typer.echo(\n            json.dumps(\n                process.description.model_dump(\n                    mode=\"json\",\n                    by_alias=True,\n                    exclude_defaults=True,\n                    exclude_none=True,\n                    exclude_unset=True,\n                ),\n                indent=2,\n            )\n        )\n\n    return t\n</code></pre>"},{"location":"procodile/cli/","title":"Procodile-Example CLI","text":"<p>This is the CLI of the Eozilla Procodile example.</p> <p>You can use shorter command name aliases, e.g., use command name <code>ep</code> for <code>execute-process</code>, or <code>lp</code> for <code>list-processes</code>.</p> <p>Usage:</p> <pre><code>$ procodile-example [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--version</code>: Show version and exit.</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>execute-process</code>: Execute a process.</li> <li><code>list-processes</code>: List all processes.</li> <li><code>get-process</code>: Get details of a process.</li> </ul>"},{"location":"procodile/cli/#procodile-example-execute-process","title":"<code>procodile-example execute-process</code>","text":"<p>Execute a process.</p> <p>The process request to be submitted may be read from a file given by <code>--request</code>, or from <code>stdin</code>, or from the <code>process_id</code> argument with zero, one, or more <code>--input</code> (or <code>-i</code>) options.</p> <p>The <code>process_id</code> argument and any given <code>--input</code> options will override settings with the same name found in the given request file or <code>stdin</code>, if any.</p> <p>Usage:</p> <pre><code>$ procodile-example execute-process [OPTIONS] [PROCESS_ID]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[PROCESS_ID]</code>: Process identifier.</li> </ul> <p>Options:</p> <ul> <li><code>-d, --dotpath</code>: Input names use dot-path notion to encode nested values, e.g., <code>-i scene.colors.bg=red</code>.</li> <li><code>-i, --input [NAME=VALUE]...</code>: Process input value.</li> <li><code>-s, --subscriber [NAME=URL]...</code>: Process subscriber URL.</li> <li><code>-r, --request PATH</code>: Execution request file. Use <code>-</code> to read from &lt;stdin&gt;.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"procodile/cli/#procodile-example-list-processes","title":"<code>procodile-example list-processes</code>","text":"<p>List all processes.</p> <p>Usage:</p> <pre><code>$ procodile-example list-processes [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"procodile/cli/#procodile-example-get-process","title":"<code>procodile-example get-process</code>","text":"<p>Get details of a process.</p> <p>Usage:</p> <pre><code>$ procodile-example get-process [OPTIONS] PROCESS_ID\n</code></pre> <p>Arguments:</p> <ul> <li><code>PROCESS_ID</code>: Process identifier.  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"procodile/introduction/","title":"Procodile Introduction","text":"<p>Eozilla Procodile is a simple Python framework that facilitates publishing of your Python functions as OGC processes,  e.g., via the Eozilla Wraptile server.</p> <p>To serve this purpose, it enables the following:</p> <ul> <li>Registering your workflows comprising an entry-point (main) and   steps implemented as Python functions.</li> <li>Querying and executing the workflow entry points via a dedicated Python API   and CLI.</li> <li>Using YAML and JSON formats based on the interfaces and models   defined by OGC API - Processes.</li> </ul> <p>Herewith it allows later application packaging by  Eozilla Appligator.</p> <p>Processor packages developed using the provided CLI can later on be used to generate Docker images, Airflow DAGs, and optionally OGC Application Packages.</p>"},{"location":"procodile/usage/","title":"Procodile Usage","text":""},{"location":"procodile/usage/#installation","title":"Installation","text":"<p>Eozilla Procodile is distributed by the light-weight Python package <code>procodile</code>. Depending on your package manager, use one of the following:</p> <pre><code>pypi install procodile\n</code></pre> <pre><code>conda install procodile\n</code></pre> <pre><code>pixi add procodile\n</code></pre>"},{"location":"procodile/usage/#api-overview","title":"API Overview","text":"<p>The package <code>procodile</code> comprises just a few handy top-level components:</p> <ul> <li>class <code>ProcessRegistry</code> - to register your   Python functions as processes in a central collection. Each process consists   of one or more Python functions with explicitly defined dependencies.   Internally, these functions are represented as <code>Workflow</code> objects and   orchestrated according to their dependency graph.   From the perspective of a Python API user, each workflow is represented as a   <code>Process</code>, abstracting away the implementation details of a workflow and its   step execution dependencies.</li> <li>class <code>ExcecutionRequest</code> - used to   programmatically execute your processes from Python code, for example in   a unit test or in a custom application.</li> <li>class <code>JobContext</code> - used inside your process   implementations to report progress or check for client-side cancellation.</li> <li>function <code>new_cli()</code> - creates a CLI for the   processes in the registry.</li> </ul>"},{"location":"procodile/usage/#development-recipe","title":"Development Recipe","text":"<p>Framework usage is simple, it is a 3-step process:</p> <ol> <li>Populate process registry with process(es) derived from your Python functions.</li> <li>Define a CLI instance from that process registry.</li> <li>Define an entry point script for the CLI instance, so you can run your package    as an application.</li> </ol> <p>The steps are explained in more detail in the following.</p>"},{"location":"procodile/usage/#1-populate-process-registry","title":"1. Populate process registry","text":"<p>First, you'll create a process registry object of type <code>ProcessRegistry</code>. For each process you plan to expose you implement a workflow that comprises a single or multiple Python functions:</p> <ul> <li>To define a entry point to the process, write a Python function and decorate it    with <code>@registry.main</code>. This registers the function as an exposed,    executable process.</li> <li>This entry point supports both simple processes (using only <code>main</code>)    and multi-step workflows (using <code>main</code> with additional <code>steps</code>).</li> <li>To do this, add steps using the <code>@your_function.step</code> decorator, where    <code>your_function</code> is the function decorated with <code>@registry.main</code>.</li> </ul> <p>Each step is registered as part of the workflow and enables more complex,    structured execution logic.</p> <p>Please see  documentation to learn more about it.</p> <p>The <code>ctx</code> object of type JobContext can be used to report progress and to check for job cancellation. You can get the job context inside the function body via <code>JobContext.get()</code> or declare it as a function argument of type <code>JobContext</code>.</p> <p>Process inputs, such as the arguments <code>path</code> or <code>factor</code> above, can be further specified by <code>pydantic.Field</code> annotations. Field annotations for an argument can be provided via the <code>inputs</code> dictionary passed to the [<code>main</code>][procodile.WorkflowRegsitry.main] or  [<code>process</code>][procodile.WorkflowRegsitry.process] and [<code>step</code>][procodile.Workflow.step] decorators, or preferably as part of the type declaration using the Python <code>Annotated</code> special form. An example for the latter is <code>factor: Annotated[float, Field(title=\"Scaling factor\", gt=0., le=10.)] = 1.0</code>.</p> <p>Use <code>main</code> decorator to express a process that comprises multiple steps that  require a reference to the main entry point.</p> <p>Use <code>process</code> decorator to express a process that has no steps, hence requires  no reference to a main step. </p> <p>This is purely for semantic reasons, in fact, the <code>process</code> decorator is an  alias for <code>main</code> decorator.</p> <p>Should your process have many arguments, you may consider defining them elsewhere in a dedicated pydantic Model derived from <code>pydantic.BaseModel</code>, pass it as single parameter to your function, and pass <code>inputs_arg=True</code> to the <code>@process</code> decorator. Now the generated process description will report the class' fields as inputs rather than the model class as single input. Conceptually:</p> <pre><code>from typing import Annotated\n\nfrom pydantic import BaseModel, Field\nfrom procodile import JobContext, ProcessRegistry\n\n\nclass ArgsModel(BaseModel):\n    # Required positional arguments\n    arg1: Annotated[Type1, Field(..., **Specs1]\n    arg2: Annotated[Type2, Field(..., **Specs2]\n    # ...\n    # Optional keyword arguments\n    kwarg1: Annotated[Type1, Field(..., Specs1] = Default1\n    kwarg2: Annotated[Type2, Field(..., Specs2] = Default2\n    # ...\n\n    registry = ProcessRegistry()\n\n@registry.process(inputs_arg=True)\ndef my_func(args: ArgsModel) -&gt; MyResult:\n    ...\n</code></pre>"},{"location":"procodile/usage/#2-define-cli-instance","title":"2. Define CLI instance","text":"<p>In a second step you define an instance of a common process CLI and pass it a reference to your registry instance. In <code>my_app/cli.py</code>:</p> <pre><code>from procodile.cli import new_cli\n\n# The CLI with a basic set of commands.\n# The `cli` is a Typer application of type `typer.Typer()`,\n# so can use the instance to register your own commands.\ncli = new_cli(registry=\"my_app.processes:registry\", name=\"my-app\", version=\"0.5.0\")\n</code></pre> <p>You could also pass the imported registry directly, but using a reference string defers importing the registry instance until it is needed. This makes the CLI much faster if it is just called with the <code>--help</code> option and hence no importing of yet unused libraries takes place.</p>"},{"location":"procodile/usage/#3-define-entry-point-script","title":"3. Define entry point script","text":"<p>In a last step you expose the CLI as an entry point script of your package. In your <code>pyproject.toml</code>:</p> <pre><code>[project.scripts]\nmy-app = \"my_app.cli:cli\"\n</code></pre> <p>After installing <code>my_app</code> in a Python environment using <code>pip</code> or <code>pixi</code> you can run your CLI as an executable and <code>my-app --help</code> will output:</p> <p></p>"},{"location":"procodile/usage/#usage-example","title":"Usage Example","text":""},{"location":"procodile/usage/#example-project-setup","title":"Example project setup","text":"<p>An application example that can serve as a starting point is provided in the workspace procodile-example. Please check out its <code>README.md</code> to install and run it.</p> <p>The application's primary user interface is its simple, generated CLI (you can extend it, if you like). For the above application example the CLI tool is named <code>procodile-example</code>.</p>"},{"location":"procodile/usage/#getting-process-information","title":"Getting process information","text":"<p>Use <code>list-processes</code> (or short <code>lp</code>) subcommand to list the published processes, and use <code>get-process</code> (or short <code>gp</code>) to get the details like the inputs of your your process. The command <code>procodile-example gp primes_between</code> will give you the input specs of the published process <code>primes_between</code>:</p> <pre><code>{\n  \"title\": \"Prime Generator\",\n  \"description\": \"Computes the list of prime numbers within an integer value range.\",\n  \"id\": \"primes_between\",\n  \"version\": \"0.0.0\",\n  \"inputs\": {\n    \"min_val\": {\n      \"title\": \"Minimum value of search range\",\n      \"minOccurs\": 0,\n      \"schema\": {\n        \"minimum\": 0.0,\n        \"type\": \"integer\",\n        \"default\": 0\n      }\n    },\n    \"max_val\": {\n      \"title\": \"Maximum value of search range\",\n      \"minOccurs\": 0,\n      \"schema\": {\n        \"minimum\": 0.0,\n        \"type\": \"integer\",\n        \"default\": 100\n      }\n    }\n  },\n  \"outputs\": {\n    \"return_value\": {\n      \"title\": \"Return Value\",\n      \"schema\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"integer\"\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"procodile/usage/#executing-a-process","title":"Executing a process","text":"<p>To execute your processes, see help for the <code>execute-process</code> (or short <code>ep</code>) subcommand:</p> <p></p>"},{"location":"procodile/usage/#execution-request-files","title":"Execution request files","text":"<p>For larger or complex sets of input parameters it is recommended to use a execution request file in JSON or YAML format. The structure is simple, for example:</p> <pre><code>{\n    \"process_id\": \"primes_between\",\n    \"inputs\": {\n      \"min_val\": 100,\n      \"max_val\": 200\n    }\n}\n</code></pre> <p>The process request file format in detail:</p> <ul> <li><code>process_id</code>: Process identifier</li> <li><code>dotpath</code>: Whether dots in input names should be used to create   nested object values. Defaults to <code>False</code>.</li> <li><code>inputs</code>: Optional process inputs given as key-value mapping.   Values may be of any JSON-serializable type accepted by   the given process.</li> <li><code>outputs</code>: Optional process outputs given as key-value mapping.   Values are of type Output   and should be supported by the given process.</li> <li><code>subscriber</code>: Optional object comprising callback   URLs that are informed about process status changes   while the processing takes place. The URLs are <code>successUri</code>,   <code>inProgressUri</code>, and <code>failedUri</code> and none is required.   See also Subscriber.</li> </ul>"},{"location":"procodile/workflow-dev/","title":"Workflow Development","text":"<p>A workflow defines how multiple python functions are connected and executed together. Each workflow has exactly one main process and any number of dependent steps. Steps may consume outputs from the main process or from other steps.</p> <p>Workflows are acyclic and are executed in topological order based on declared dependencies.</p> <p>From an OGC API \u2013 Processes (Part 3 draft) perspective:</p> <ul> <li>A workflow behaves like a single process by exposing itself as a process.</li> <li>Internally, it is a directed acyclic graph (DAG) of sub-processes</li> <li>Each workflow step is itself a valid process</li> <li>Outputs from one step may be consumed as inputs by another step</li> </ul> <p>Workflows allow complex execution graphs to be expressed declaratively while remaining compliant with the OGC process model.</p>"},{"location":"procodile/workflow-dev/#conceptual-model-ogc-alignment","title":"Conceptual Model (OGC Alignment)","text":"Concept Meaning Workflow A directed, acyclic graph of processes with a single main entry point and a single output, where all data dependencies are explicitly declared. Main step The primary entrypoint declared using <code>registry.main()</code> Step A sub-process within the workflow, defined using <code>your_process.step()</code> where <code>your_process</code> is the python function decorated with <code>registry.main()</code> Dependency A data relationship between process inputs and outputs Execution order A topologically sorted process graph <p>A workflow must:</p> <ul> <li>Define exactly one main entrypoint</li> <li>Define exactly one output step</li> <li>Contain no cycles</li> <li>Explicitly declare all inter-process dependencies</li> </ul>"},{"location":"procodile/workflow-dev/#workflowregistry-conceptual-overview","title":"WorkflowRegistry \u2014 Conceptual Overview","text":""},{"location":"procodile/workflow-dev/#motivation","title":"Motivation","text":"<p>OGC API \u2013 Processes Part 3 (draft) introduces the concept of workflows, where a process execution request may reference other processes as inputs (\u201cnested processes\u201d). This enables clients to define ad-hoc workflows dynamically at execution time.</p> <p>This framework (<code>procodile</code>) takes a complementary approach:</p> <pre><code>Instead of defining workflows dynamically in JSON at execution time, workflows \nare authored declaratively in Python, registered once, and then exposed as \nstandard OGC processes.\n</code></pre> <p>Internally, workflows are represented as structured Python objects (<code>Workflow</code>) that capture:</p> <ul> <li>step definitions</li> <li>input bindings (<code>FromMain</code>, <code>FromStep</code>)</li> <li>execution order</li> <li>execution logic (<code>workflow.run</code>)</li> </ul> Aspect OGC Nested Processes Procodile Workflow Framework Definition order Leaf-first Root-first Representation Nested JSON Explicit DAG Primary use Ad-hoc execution Deployment &amp; reuse Identity Execution-scoped Stable process ID Execution model Tree evaluation DAG execution <p>Both models describe the same execution semantics</p> <p>The framework is the inverse authoring model of nested processes</p> <p>Future support for nested execution requests can be added without changing the internal model</p>"},{"location":"procodile/workflow-dev/#why-workflows-are-exposed-as-processes","title":"Why Workflows are exposed as Processes","text":"<p>OGC API \u2013 Processes is fundamentally process-centric:</p> <ul> <li>Clients discover <code>/processes</code></li> <li>Clients execute <code>/processes/{id}/execution</code></li> </ul> <p>There is no separate \u201cworkflow\u201d resource in Part 1 or Part 3.</p> <p>Therefore:</p> <pre><code>A workflow must be represented as a process in order to be OGC-compliant.\n</code></pre> <p>The <code>ProcessRegistry</code> provides this abstraction by projecting workflows into processes.</p> <p><code>ProcessRegistry</code> is a mapping-like registry that:</p> <ul> <li>stores internal <code>Workflow</code> objects</li> <li>exposes them externally as <code>Process</code> objects</li> </ul>"},{"location":"procodile/workflow-dev/#future-compatibility-with-nested-execution-requests","title":"Future Compatibility with Nested Execution Requests","text":"<p>Although workflows are currently authored as Python objects, the internal representation already contains everything needed to support OGC Part 3 nested execution requests in the future.</p> <p>A future extension may:</p> <ul> <li>accept nested execution JSON</li> <li>translate it into an internal workflow DAG</li> <li>execute it using the same runtime</li> <li>or deploy it as a persistent workflow</li> </ul> <p>In that scenario:</p> <ul> <li>nested execution becomes an alternative front door</li> <li>the internal execution model remains unchanged</li> </ul> <p>This ensures forward compatibility with the OGC API \u2013 Processes Part 3 draft.</p>"},{"location":"procodile/workflow-dev/#creating-a-workflow","title":"Creating a Workflow","text":"<p>Workflows are created through a <code>WorkflowRegistry</code>.</p> <pre><code>from procodile import ProcessRegistry\n\nregistry = ProcessRegistry()\n</code></pre> <p>Each workflow is uniquely identified by its <code>id</code>.</p>"},{"location":"procodile/workflow-dev/#defining-the-main-step","title":"Defining the Main Step","text":"<p>The main step represents the workflow\u2019s external interface. It is the only step that receives user-supplied inputs.</p> <p>Every workflow must define exactly one main step.</p> <p>For e.g.,</p> <pre><code>@registry.main(\n    id=\"main_step\",\n    inputs={\n        \"id\": Field(title=\"Main input\"),\n    },\n    outputs={\n        \"a\": Field(title=\"Main output\"),\n    },\n)\ndef main_step(id: str) -&gt; str:\n    return id.upper()\n</code></pre>"},{"location":"procodile/workflow-dev/#defining-workflow-steps-sub-processes","title":"Defining Workflow Steps (Sub-Processes)","text":"<p>Workflow steps are defined using the <code>@main_step.step</code> decorator.</p> <p>Each step is a process that may depend on:</p> <ul> <li>Outputs from the main step</li> <li>Outputs from other workflow steps</li> </ul> <pre><code>@main_step.step(id=\"second_step\")\ndef second_step(id: str) -&gt; str:\n    return id[::-1]\n</code></pre>"},{"location":"procodile/workflow-dev/#declaring-dependencies","title":"Declaring Dependencies","text":"<p>Dependencies are either declared</p> <ul> <li>using <code>typing.Annotated</code> in type annotations of your function argument declarations or</li> <li>using <code>pydantic.Field</code> in the decorator's <code>inputs</code> and <code>outputs</code> values.</li> </ul>"},{"location":"procodile/workflow-dev/#from-the-main-step","title":"From the Main Step","text":"<p>Use <code>FromMain</code> to reference outputs of the main step.</p> <pre><code>from typing import Annotated\nfrom procodile import FromMain\n\n@main_step.step(id=\"use_main\")\ndef use_main(\n    id: Annotated[str, FromMain(output=\"a\")]\n) -&gt; str:\n    return id\n</code></pre> <p>or</p> <pre><code>from typing import Annotated\nfrom procodile import FromMain\nfrom pydantic import Field\n\n@main_step.step(\n    id=\"use_main\",\n    inputs={\n        \"id\": Field(title=\"main input\")\n    },\n)\ndef use_main(\n    id: str\n) -&gt; str:\n    return id\n</code></pre> <ul> <li><code>output</code> refers to a named output of the main step.</li> <li><code>\"return_value\"</code> may be used when the main step has no explicit outputs defined.</li> </ul>"},{"location":"procodile/workflow-dev/#from-another-step","title":"From Another Step","text":"<p>Use <code>FromStep</code> to reference outputs from another workflow step.</p> <pre><code>from procodile import FromStep\n\n@main_step.step(id=\"use_step\")\ndef use_step(\n    value: Annotated[str, FromStep(step_id=\"second_step\", output=\"return_value\")]\n) -&gt; str:\n    return value\n</code></pre> <p>or</p> <pre><code>from procodile import FromStep\n\n@main_step.step(id=\"use_step\", \n               inputs={\n                   FromStep(step_id=\"second_step\", output=\"return_value\")\n               }\n)\ndef use_step(\n    value: str\n) -&gt; str:\n    return value\n</code></pre> <ul> <li><code>step_id</code> must refer to an existing workflow step.</li> <li><code>output</code> must match one of the step\u2019s outputs or <code>\"return_value\"</code>.</li> </ul>"},{"location":"procodile/workflow-dev/#mixing-dependencies-and-inputs","title":"Mixing Dependencies and Inputs","text":"<p>A step may mix dependencies and normal inputs.</p> <pre><code>from procodile import FromStep, FromMain\n\n@main_step.step(id=\"mixed_step\")\ndef mixed_step(\n    a: Annotated[str, FromMain(output=\"a\")],\n    b: Annotated[str, FromStep(step_id=\"second_step\", output=\"return_value\")],\n) -&gt; str:\n    return f\"{a}:{b}\"\n</code></pre> <p>or</p> <pre><code>from procodile import FromStep, FromMain\n\n@main_step.step(\n    id=\"mixed_step\",\n    inputs={\n        \"a\": FromMain(output=\"a\"),\n        \"b\": FromStep(step_id=\"second_step\", output=\"return_value\")\n    }\n)\ndef mixed_step(\n    a: str,\n    b: str\n) -&gt; str:\n    return f\"{a}:{b}\"\n</code></pre>"},{"location":"procodile/workflow-dev/#declaring-outputs-for-steps","title":"Declaring Outputs for Steps","text":"<p>Steps may declare explicit outputs.</p> <pre><code>@main_step.step(\n    id=\"final_step\",\n    outputs={\n        \"result\": Field(title=\"Final result\"),\n    },\n)\ndef final_step(\n    value: Annotated[str, FromStep(step_id=\"mixed_step\", output=\"return_value\")]\n) -&gt; str:\n    return value\n</code></pre> <p>If no outputs are declared, the return value is exposed as  <code>\"return_value\"</code>.</p>"},{"location":"procodile/workflow-dev/#output-resolution-rules","title":"Output Resolution Rules","text":"<p>Workflow execution follows strict output normalization rules. These rules apply uniformly to main and step processes.</p>"},{"location":"procodile/workflow-dev/#1-no-output-specification","title":"1. No output specification","text":"<pre><code>{\"return_value\": result}\n</code></pre>"},{"location":"procodile/workflow-dev/#2-tuple-return-value","title":"2. Tuple return value","text":"<ul> <li>Values are mapped positionally to output names</li> <li>Output names must be defined in the output specification</li> </ul>"},{"location":"procodile/workflow-dev/#3-dictionary-return-value","title":"3. Dictionary return value","text":"<ul> <li>Keys are mapped directly to output names</li> <li>All keys must exist in the output specification</li> </ul>"},{"location":"procodile/workflow-dev/#4-single-scalar-value","title":"4. Single scalar value","text":"<ul> <li>Treated as a single output</li> <li>Exposed as \"return_value\" unless outputs are explicitly defined</li> </ul>"},{"location":"procodile/workflow-dev/#examples","title":"Examples","text":"<pre><code># No outputs declared\nreturn 42\n# \u2192 {\"return_value\": 42}\n\n# No outputs declared\nreturn (1, 2)\n# \u2192 {\"return_value\": (1, 2)}\n\n# Declared outputs: (\"a\", \"b\")\nreturn (1, 2)\n# \u2192 {\"a\": 1, \"b\": 2}\n\n# Declared outputs: (\"a\", \"b\")\nreturn {\"a\": 1, \"b\": 2}\n# \u2192 {\"a\": 1, \"b\": 2}\n\n# Declared outputs: (\"c\")\nreturn {\"a\": 1, \"b\": 2}\n# \u2192 {\"c\":{\"a\": 1, \"b\": 2}}\n</code></pre>"},{"location":"procodile/workflow-dev/#dependency-validation","title":"Dependency Validation","text":"<p>Dependencies are validated at workflow construction time:</p> <ul> <li>Exactly one main step</li> <li>Exactly one output step (leaf step) -&gt; this returns the final output</li> <li>Referenced steps must exist</li> <li>Referenced outputs must exist</li> <li>Cyclic dependencies are rejected</li> </ul> <p>Errors are raised immediately if the workflow is invalid.</p>"},{"location":"procodile/workflow-dev/#execution-order","title":"Execution Order","text":"<p>Execution order is automatically derived using topological sorting.</p> <p>To ensure seamless integration with orchestrating engines (such as Apache Airflow or local runners), the system automatically appends a final step (<code>procodile.workflow.FINAL_STEP_ID</code>) to every user-created workflow.</p> <p>The final step serves as a standardized exit point for data. By maintaining a consistent final node, orchestrators can reliably extract the workflow's output without needing to parse unique or variable step names defined by the user.</p> <p>Important: The final step node is a passthrough entity. It does not perform any data transformations, computations, or logic. Its sole responsibility is to receive the output from the preceding step and expose it via a standardized key.</p>"},{"location":"procodile/workflow-dev/#visualizing-the-workflow","title":"Visualizing the Workflow","text":"<p>Workflows can be visualized as a directed graph.</p> <pre><code>dot = workflow.visualize_workflow()\n</code></pre> <p>This returns a Graphviz DOT representation similar to this:</p> <pre><code>digraph pipeline {\n    rankdir=LR;\n    \"main_step\";\n    \"second_step\";\n    \"main_step\" -&gt; \"second_step\";\n}\n</code></pre>"},{"location":"wraptile/cli/","title":"Wraptile CLI","text":"<p><code>wraptile</code> is a web server made for wrapping workflow  orchestration systems providing an API compliant with the OGC API - Processes, Part 1: Core Standard (https://ogcapi.ogc.org/processes/).</p> <p>The SERVICE argument may be followed by a <code>--</code> to pass one or more  service-specific arguments and options.</p> <p>Note that the service arguments may also be given by the  environment variable <code>EOZILLA_SERVICE</code>.</p> <p>Usage:</p> <pre><code>$ wraptile [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--version</code>: Show version and exit.</li> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>run</code>: Run server in production mode.</li> <li><code>dev</code>: Run server in development mode.</li> </ul>"},{"location":"wraptile/cli/#wraptile-run","title":"<code>wraptile run</code>","text":"<p>Run server in production mode.</p> <p>Usage:</p> <pre><code>$ wraptile run [OPTIONS] [SERVICE [-- SERVICE-OPTIONS]]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[SERVICE [-- SERVICE-OPTIONS]]</code>: Service instance optionally followed by <code>--</code> to pass service-specific arguments and options. SERVICE should have the form <code>path.to.module:service</code>.  [env var: EOZILLA_SERVICE]</li> </ul> <p>Options:</p> <ul> <li><code>--host TEXT</code>: Host address.  [env var: EOZILLA_SERVER_HOST; default: 127.0.0.1]</li> <li><code>--port INTEGER</code>: Port number.  [env var: EOZILLA_SERVER_PORT; default: 8008]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"wraptile/cli/#wraptile-dev","title":"<code>wraptile dev</code>","text":"<p>Run server in development mode.</p> <p>Usage:</p> <pre><code>$ wraptile dev [OPTIONS] [SERVICE [-- SERVICE-OPTIONS]]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[SERVICE [-- SERVICE-OPTIONS]]</code>: Service instance optionally followed by <code>--</code> to pass service-specific arguments and options. SERVICE should have the form <code>path.to.module:service</code>.  [env var: EOZILLA_SERVICE]</li> </ul> <p>Options:</p> <ul> <li><code>--host TEXT</code>: Host address.  [env var: EOZILLA_SERVER_HOST; default: 127.0.0.1]</li> <li><code>--port INTEGER</code>: Port number.  [env var: EOZILLA_SERVER_PORT; default: 8008]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"wraptile/customization/","title":"Wraptile Customization","text":"<p>Applications can create their own servers using <code>wraptile</code> under the hood.  For this, an application can customize the <code>wraptile</code> configuration and its default values.</p> <p>This is best explained by an example. In the following we explain  the client customization by a hypothetic processing system \"Anolis\" that should get its own <code>anolis-server</code>.</p> <p>The <code>wraptile</code> API currently just allows for customizing the CLI:</p>"},{"location":"wraptile/customization/#cli-customisation","title":"CLI customisation","text":"<p>In a module <code>src/anolis_server/cli.py</code>:</p> <pre><code>from wraptile.cli import new_cli\nfrom anolis_server import __version__ as version\n\ncli = new_cli(\n    name=\"anolis-server\", \n    summary=\"Server providing the Anolis processing service.\",\n    version=version\n)\n\n__all__ = [\"cli\"]\n\nif __name__ == \"__main__\":  # pragma: no cover\n    cli()    \n</code></pre>"},{"location":"wraptile/introduction/","title":"Wraptile Introduction","text":"<p>Eozilla Wraptile is a server made for wrapping workflow orchestration  systems with a unified restful API that should be almost compliant with the OGC API - Processes.</p> <p>Wraptile can currently be run with a local execution service or with Airflow.</p>"},{"location":"wraptile/usage/","title":"Wraptile Usage","text":""},{"location":"wraptile/usage/#local-execution-service","title":"Local execution service","text":"<p>Running Wraptile with a local service:</p> <pre><code>pixi shell\nwraptile run -- wraptile.services.local.testing:service --processes --max-workers=5\n</code></pre> <p>The possible options are</p> <ul> <li><code>--processes</code> /  <code>--no-processes</code>: Whether to use processes or threads, defaults   to threads.</li> <li><code>--max-workers=INTEGER</code>: Maximum number of processes or threads, defaults to 3.</li> </ul>"},{"location":"wraptile/usage/#airflow-service","title":"Airflow service","text":"<p>Start by running a local Airflow instance with some test DAGs: <pre><code>cd eozilla-airflow\npixi install\npixi run airflow standalone\n</code></pre></p> <p>Then run the Wraptile server with the local Airflow instance (assuming the local Airflow webserver runs on http://localhost:8080):</p> <pre><code>pixi shell\nwraptile run -- wraptile.services.airflow:service --airflow-password=a8e7f4bb230\n</code></pre> <p>The possible options are</p> <ul> <li><code>--airflow-base-url=TEXT</code>: The base URL of the Airflow web API, defaults to    <code>http://localhost:8080</code>. </li> <li><code>--airflow-username=TEXT</code>: The Airflow username, defaults to <code>admin</code>. </li> <li><code>--airflow-password=TEXT</code>: The Airflow password.    For an Airflow installation with the simple Auth manager, use the one from   <code>.airflow/simple_auth_manager_passwords.json.generated</code>.</li> </ul>"}]}